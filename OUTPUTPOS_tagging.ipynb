{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u8E5ItNgIpB"
      },
      "source": [
        "Uncomment and execute in Colab Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om_Ab2NNgIpF",
        "outputId": "3da3c2fb-6295-44de-bfef-3a342c7526ad"
      },
      "outputs": [],
      "source": [
        "# execute this cell when loading the notebook for the first time\n",
        "# ! pip install gensim==4.2.0\n",
        "# ! pip install keras==2.8.0\n",
        "\n",
        "# ! git clone https://github.com/michele98/POS_tagging\n",
        "\n",
        "\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')\n",
        "\n",
        "# drive_folder = '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhmZ3YCHgIpG",
        "outputId": "66040ad5-76a7-4af0-c801-2fac3c5a343c"
      },
      "outputs": [],
      "source": [
        "# execute this cell each time the runtime is restarted\n",
        "\n",
        "# %cd -0\n",
        "# %cd POS_tagging\n",
        "\n",
        "# import os\n",
        "# os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUPCryODgIpG"
      },
      "source": [
        "Main Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "JK_zI4TwgIpH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "\n",
        "from zipfile import ZipFile\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('default')\n",
        "\n",
        "random_seed = 42\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)\n",
        "#os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k91cP9wWgIpH"
      },
      "source": [
        "# Create Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH2gBvrzgIpH"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbxohvOigIpI",
        "outputId": "5d447aba-e701-4c63-9c90-724573bcf2b9"
      },
      "outputs": [],
      "source": [
        "dataset_folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\")\n",
        "\n",
        "if not os.path.exists(dataset_folder):\n",
        "    os.makedirs(dataset_folder)\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
        "\n",
        "dataset_path = os.path.join(dataset_folder, \"data.zip\")\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    urllib.request.urlretrieve(url, dataset_path)\n",
        "    print(\"Successful download\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-lsMoB8gIpI"
      },
      "source": [
        "## Create Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "TE0cWkqOgIpI",
        "outputId": "bf70fa4e-28ce-41ad-d658-68b2ec199716"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataframe created.                                \n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-44c470ce-3b39-413f-8ba1-98bac399c822\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>(Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>(NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>(Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
              "      <td>(NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>(Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>(NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>(``, There, 's, no, question, that, some, of, ...</td>\n",
              "      <td>(``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>(Workers, described, ``, clouds, of, blue, dus...</td>\n",
              "      <td>(NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>198</td>\n",
              "      <td>(A, line-item, veto, is, a, procedure, that, w...</td>\n",
              "      <td>(DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>198</td>\n",
              "      <td>(Sen., Kennedy, said, in, a, separate, stateme...</td>\n",
              "      <td>(NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3911</th>\n",
              "      <td>199</td>\n",
              "      <td>(Trinity, Industries, Inc., said, it, reached,...</td>\n",
              "      <td>(NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3912</th>\n",
              "      <td>199</td>\n",
              "      <td>(Terms, were, n't, disclosed, .)</td>\n",
              "      <td>(NNS, VBD, RB, VBN, .)</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>199</td>\n",
              "      <td>(Trinity, said, it, plans, to, begin, delivery...</td>\n",
              "      <td>(NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3914 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44c470ce-3b39-413f-8ba1-98bac399c822')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44c470ce-3b39-413f-8ba1-98bac399c822 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44c470ce-3b39-413f-8ba1-98bac399c822');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      file_id                                               text  \\\n",
              "0           1  (Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1           1  (Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
              "2           2  (Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "3           3  (``, There, 's, no, question, that, some, of, ...   \n",
              "4           3  (Workers, described, ``, clouds, of, blue, dus...   \n",
              "...       ...                                                ...   \n",
              "3909      198  (A, line-item, veto, is, a, procedure, that, w...   \n",
              "3910      198  (Sen., Kennedy, said, in, a, separate, stateme...   \n",
              "3911      199  (Trinity, Industries, Inc., said, it, reached,...   \n",
              "3912      199                   (Terms, were, n't, disclosed, .)   \n",
              "3913      199  (Trinity, said, it, plans, to, begin, delivery...   \n",
              "\n",
              "                                                   tags  split  \n",
              "0     (NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  train  \n",
              "1     (NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  train  \n",
              "2     (NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  train  \n",
              "3     (``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...  train  \n",
              "4     (NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...  train  \n",
              "...                                                 ...    ...  \n",
              "3909  (DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...   test  \n",
              "3910  (NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...   test  \n",
              "3911  (NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...   test  \n",
              "3912                             (NNS, VBD, RB, VBN, .)   test  \n",
              "3913  (NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...   test  \n",
              "\n",
              "[3914 rows x 4 columns]"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_range = (1, 101)\n",
        "val_range = (101, 151)\n",
        "test_range = (151, 200)\n",
        "\n",
        "split_sentences = True\n",
        "\n",
        "dataframe_rows = []\n",
        "with ZipFile(dataset_path, 'r') as myzip:\n",
        "    for i, filename in enumerate(myzip.namelist()[1:]):\n",
        "        print(\"Extracting\", filename, end='\\r')\n",
        "\n",
        "        with myzip.open(filename) as myfile:\n",
        "            file_id = int(filename.split('.')[0][-4:])\n",
        "\n",
        "            split = 'train'\n",
        "            if file_id in range(*val_range):\n",
        "                split = 'val'\n",
        "            elif file_id in range(*test_range):\n",
        "                split = 'test'\n",
        "\n",
        "            content_string = myfile.read().decode('utf-8')\n",
        "            if split_sentences:\n",
        "                sentences = content_string.split('\\n\\n')\n",
        "            else:\n",
        "                sentences = [content_string]\n",
        "\n",
        "            for sentence in sentences:\n",
        "                content = sentence.split('\\n')\n",
        "                content = [line.split('\\t') for line in content if len(line.split('\\t')) == 3]\n",
        "\n",
        "                words, tags, _ = zip(*content)\n",
        "\n",
        "                dataframe_rows.append({'file_id': file_id,\n",
        "                                       'text': words,\n",
        "                                       'tags': tags,\n",
        "                                       'split': split\n",
        "                                       })\n",
        "\n",
        "df = pd.DataFrame(dataframe_rows).sort_values('file_id').reset_index(drop=True)\n",
        "print(\"Dataframe created.\".ljust(50))\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKeTNqw4gIpJ"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKryqoILgIpJ"
      },
      "source": [
        "Convert to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WL4B-3oOgIpJ",
        "outputId": "aa85e523-ae4f-4c23-daf0-4d9d904503e9"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bb2bce4e-83db-4565-b386-3e1dfc246f63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[pierre, vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>(NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[mr., vinken, is, chairman, of, elsevier, n.v....</td>\n",
              "      <td>(NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[rudolph, agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>(NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[``, there, 's, no, question, that, some, of, ...</td>\n",
              "      <td>(``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[workers, described, ``, clouds, of, blue, dus...</td>\n",
              "      <td>(NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>198</td>\n",
              "      <td>[a, line-item, veto, is, a, procedure, that, w...</td>\n",
              "      <td>(DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>198</td>\n",
              "      <td>[sen., kennedy, said, in, a, separate, stateme...</td>\n",
              "      <td>(NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3911</th>\n",
              "      <td>199</td>\n",
              "      <td>[trinity, industries, inc., said, it, reached,...</td>\n",
              "      <td>(NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3912</th>\n",
              "      <td>199</td>\n",
              "      <td>[terms, were, n't, disclosed, .]</td>\n",
              "      <td>(NNS, VBD, RB, VBN, .)</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>199</td>\n",
              "      <td>[trinity, said, it, plans, to, begin, delivery...</td>\n",
              "      <td>(NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3914 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb2bce4e-83db-4565-b386-3e1dfc246f63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb2bce4e-83db-4565-b386-3e1dfc246f63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb2bce4e-83db-4565-b386-3e1dfc246f63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      file_id                                               text  \\\n",
              "0           1  [pierre, vinken, ,, 61, years, old, ,, will, j...   \n",
              "1           1  [mr., vinken, is, chairman, of, elsevier, n.v....   \n",
              "2           2  [rudolph, agnew, ,, 55, years, old, and, forme...   \n",
              "3           3  [``, there, 's, no, question, that, some, of, ...   \n",
              "4           3  [workers, described, ``, clouds, of, blue, dus...   \n",
              "...       ...                                                ...   \n",
              "3909      198  [a, line-item, veto, is, a, procedure, that, w...   \n",
              "3910      198  [sen., kennedy, said, in, a, separate, stateme...   \n",
              "3911      199  [trinity, industries, inc., said, it, reached,...   \n",
              "3912      199                   [terms, were, n't, disclosed, .]   \n",
              "3913      199  [trinity, said, it, plans, to, begin, delivery...   \n",
              "\n",
              "                                                   tags  split  \n",
              "0     (NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  train  \n",
              "1     (NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  train  \n",
              "2     (NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  train  \n",
              "3     (``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...  train  \n",
              "4     (NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...  train  \n",
              "...                                                 ...    ...  \n",
              "3909  (DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...   test  \n",
              "3910  (NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...   test  \n",
              "3911  (NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...   test  \n",
              "3912                             (NNS, VBD, RB, VBN, .)   test  \n",
              "3913  (NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...   test  \n",
              "\n",
              "[3914 rows x 4 columns]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df['text'] = df['text'].apply(lambda l: [element.lower() for element in l])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dataset statistics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Number of sentences in documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longest document with most sentences is 118 with 185.\n",
            "mean sentence number in document is 19.67.\n",
            "std = 23.14.\n",
            "Lenghts of documents with more than 80 sentences:\n",
            "[135, 185]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"280.72497pt\" height=\"207.99625pt\" viewBox=\"0 0 280.72497 207.99625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-12-12T19:20:52.214249</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 207.99625 \nL 280.72497 207.99625 \nL 280.72497 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 36.465625 170.44 \nL 270.046181 170.44 \nL 270.046181 7.2 \nL 36.465625 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 36.609811 170.44 \nL 39.20515 170.44 \nL 39.20515 170.44 \nL 36.609811 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 39.493521 170.44 \nL 42.088861 170.44 \nL 42.088861 92.706667 \nL 39.493521 92.706667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 42.377232 170.44 \nL 44.972571 170.44 \nL 44.972571 53.84 \nL 42.377232 53.84 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 45.260942 170.44 \nL 47.856282 170.44 \nL 47.856282 34.406667 \nL 45.260942 34.406667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 48.144653 170.44 \nL 50.739992 170.44 \nL 50.739992 44.123333 \nL 48.144653 44.123333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 51.028363 170.44 \nL 53.623703 170.44 \nL 53.623703 63.556667 \nL 51.028363 63.556667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 53.912074 170.44 \nL 56.507413 170.44 \nL 56.507413 63.556667 \nL 53.912074 63.556667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 56.795784 170.44 \nL 59.391124 170.44 \nL 59.391124 63.556667 \nL 56.795784 63.556667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 59.679495 170.44 \nL 62.274835 170.44 \nL 62.274835 14.973333 \nL 59.679495 14.973333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 62.563206 170.44 \nL 65.158545 170.44 \nL 65.158545 92.706667 \nL 62.563206 92.706667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 65.446916 170.44 \nL 68.042256 170.44 \nL 68.042256 160.723333 \nL 65.446916 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 68.330627 170.44 \nL 70.925966 170.44 \nL 70.925966 141.29 \nL 68.330627 141.29 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 71.214337 170.44 \nL 73.809677 170.44 \nL 73.809677 141.29 \nL 71.214337 141.29 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 74.098048 170.44 \nL 76.693387 170.44 \nL 76.693387 151.006667 \nL 74.098048 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path d=\"M 76.981758 170.44 \nL 79.577098 170.44 \nL 79.577098 141.29 \nL 76.981758 141.29 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 79.865469 170.44 \nL 82.460808 170.44 \nL 82.460808 170.44 \nL 79.865469 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 82.74918 170.44 \nL 85.344519 170.44 \nL 85.344519 141.29 \nL 82.74918 141.29 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 85.63289 170.44 \nL 88.22823 170.44 \nL 88.22823 141.29 \nL 85.63289 141.29 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 88.516601 170.44 \nL 91.11194 170.44 \nL 91.11194 151.006667 \nL 88.516601 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path d=\"M 91.400311 170.44 \nL 93.995651 170.44 \nL 93.995651 131.573333 \nL 91.400311 131.573333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 94.284022 170.44 \nL 96.879361 170.44 \nL 96.879361 112.14 \nL 94.284022 112.14 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 97.167732 170.44 \nL 99.763072 170.44 \nL 99.763072 141.29 \nL 97.167732 141.29 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 100.051443 170.44 \nL 102.646782 170.44 \nL 102.646782 151.006667 \nL 100.051443 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 102.935153 170.44 \nL 105.530493 170.44 \nL 105.530493 160.723333 \nL 102.935153 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path d=\"M 105.818864 170.44 \nL 108.414204 170.44 \nL 108.414204 131.573333 \nL 105.818864 131.573333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 108.702575 170.44 \nL 111.297914 170.44 \nL 111.297914 141.29 \nL 108.702575 141.29 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 111.586285 170.44 \nL 114.181625 170.44 \nL 114.181625 170.44 \nL 111.586285 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path d=\"M 114.469996 170.44 \nL 117.065335 170.44 \nL 117.065335 151.006667 \nL 114.469996 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 117.353706 170.44 \nL 119.949046 170.44 \nL 119.949046 170.44 \nL 117.353706 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path d=\"M 120.237417 170.44 \nL 122.832756 170.44 \nL 122.832756 160.723333 \nL 120.237417 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 123.121127 170.44 \nL 125.716467 170.44 \nL 125.716467 160.723333 \nL 123.121127 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 126.004838 170.44 \nL 128.600177 170.44 \nL 128.600177 151.006667 \nL 126.004838 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_35\">\n    <path d=\"M 128.888549 170.44 \nL 131.483888 170.44 \nL 131.483888 151.006667 \nL 128.888549 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_36\">\n    <path d=\"M 131.772259 170.44 \nL 134.367599 170.44 \nL 134.367599 160.723333 \nL 131.772259 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_37\">\n    <path d=\"M 134.65597 170.44 \nL 137.251309 170.44 \nL 137.251309 160.723333 \nL 134.65597 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_38\">\n    <path d=\"M 137.53968 170.44 \nL 140.13502 170.44 \nL 140.13502 160.723333 \nL 137.53968 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_39\">\n    <path d=\"M 140.423391 170.44 \nL 143.01873 170.44 \nL 143.01873 151.006667 \nL 140.423391 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_40\">\n    <path d=\"M 143.307101 170.44 \nL 145.902441 170.44 \nL 145.902441 151.006667 \nL 143.307101 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_41\">\n    <path d=\"M 146.190812 170.44 \nL 148.786151 170.44 \nL 148.786151 151.006667 \nL 146.190812 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_42\">\n    <path d=\"M 149.074522 170.44 \nL 151.669862 170.44 \nL 151.669862 151.006667 \nL 149.074522 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_43\">\n    <path d=\"M 151.958233 170.44 \nL 154.553573 170.44 \nL 154.553573 160.723333 \nL 151.958233 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_44\">\n    <path d=\"M 154.841944 170.44 \nL 157.437283 170.44 \nL 157.437283 160.723333 \nL 154.841944 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_45\">\n    <path d=\"M 157.725654 170.44 \nL 160.320994 170.44 \nL 160.320994 151.006667 \nL 157.725654 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_46\">\n    <path d=\"M 160.609365 170.44 \nL 163.204704 170.44 \nL 163.204704 151.006667 \nL 160.609365 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_47\">\n    <path d=\"M 163.493075 170.44 \nL 166.088415 170.44 \nL 166.088415 151.006667 \nL 163.493075 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_48\">\n    <path d=\"M 166.376786 170.44 \nL 168.972125 170.44 \nL 168.972125 151.006667 \nL 166.376786 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_49\">\n    <path d=\"M 169.260496 170.44 \nL 171.855836 170.44 \nL 171.855836 160.723333 \nL 169.260496 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_50\">\n    <path d=\"M 172.144207 170.44 \nL 174.739546 170.44 \nL 174.739546 160.723333 \nL 172.144207 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_51\">\n    <path d=\"M 175.027918 170.44 \nL 177.623257 170.44 \nL 177.623257 170.44 \nL 175.027918 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_52\">\n    <path d=\"M 177.911628 170.44 \nL 180.506968 170.44 \nL 180.506968 160.723333 \nL 177.911628 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_53\">\n    <path d=\"M 180.795339 170.44 \nL 183.390678 170.44 \nL 183.390678 141.29 \nL 180.795339 141.29 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_54\">\n    <path d=\"M 183.679049 170.44 \nL 186.274389 170.44 \nL 186.274389 170.44 \nL 183.679049 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_55\">\n    <path d=\"M 186.56276 170.44 \nL 189.158099 170.44 \nL 189.158099 151.006667 \nL 186.56276 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_56\">\n    <path d=\"M 189.44647 170.44 \nL 192.04181 170.44 \nL 192.04181 170.44 \nL 189.44647 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_57\">\n    <path d=\"M 192.330181 170.44 \nL 194.92552 170.44 \nL 194.92552 151.006667 \nL 192.330181 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_58\">\n    <path d=\"M 195.213891 170.44 \nL 197.809231 170.44 \nL 197.809231 170.44 \nL 195.213891 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_59\">\n    <path d=\"M 198.097602 170.44 \nL 200.692942 170.44 \nL 200.692942 170.44 \nL 198.097602 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_60\">\n    <path d=\"M 200.981313 170.44 \nL 203.576652 170.44 \nL 203.576652 151.006667 \nL 200.981313 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_61\">\n    <path d=\"M 203.865023 170.44 \nL 206.460363 170.44 \nL 206.460363 160.723333 \nL 203.865023 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_62\">\n    <path d=\"M 206.748734 170.44 \nL 209.344073 170.44 \nL 209.344073 170.44 \nL 206.748734 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_63\">\n    <path d=\"M 209.632444 170.44 \nL 212.227784 170.44 \nL 212.227784 170.44 \nL 209.632444 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_64\">\n    <path d=\"M 212.516155 170.44 \nL 215.111494 170.44 \nL 215.111494 170.44 \nL 212.516155 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_65\">\n    <path d=\"M 215.399865 170.44 \nL 217.995205 170.44 \nL 217.995205 170.44 \nL 215.399865 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_66\">\n    <path d=\"M 218.283576 170.44 \nL 220.878915 170.44 \nL 220.878915 170.44 \nL 218.283576 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_67\">\n    <path d=\"M 221.167287 170.44 \nL 223.762626 170.44 \nL 223.762626 160.723333 \nL 221.167287 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_68\">\n    <path d=\"M 224.050997 170.44 \nL 226.646337 170.44 \nL 226.646337 141.29 \nL 224.050997 141.29 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_69\">\n    <path d=\"M 226.934708 170.44 \nL 229.530047 170.44 \nL 229.530047 170.44 \nL 226.934708 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_70\">\n    <path d=\"M 229.818418 170.44 \nL 232.413758 170.44 \nL 232.413758 170.44 \nL 229.818418 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_71\">\n    <path d=\"M 232.702129 170.44 \nL 235.297468 170.44 \nL 235.297468 170.44 \nL 232.702129 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_72\">\n    <path d=\"M 235.585839 170.44 \nL 238.181179 170.44 \nL 238.181179 160.723333 \nL 235.585839 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_73\">\n    <path d=\"M 238.46955 170.44 \nL 241.064889 170.44 \nL 241.064889 160.723333 \nL 238.46955 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_74\">\n    <path d=\"M 241.35326 170.44 \nL 243.9486 170.44 \nL 243.9486 160.723333 \nL 241.35326 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_75\">\n    <path d=\"M 244.236971 170.44 \nL 246.832311 170.44 \nL 246.832311 170.44 \nL 244.236971 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_76\">\n    <path d=\"M 247.120682 170.44 \nL 249.716021 170.44 \nL 249.716021 170.44 \nL 247.120682 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_77\">\n    <path d=\"M 250.004392 170.44 \nL 252.599732 170.44 \nL 252.599732 170.44 \nL 250.004392 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_78\">\n    <path d=\"M 252.888103 170.44 \nL 255.483442 170.44 \nL 255.483442 170.44 \nL 252.888103 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_79\">\n    <path d=\"M 255.771813 170.44 \nL 258.367153 170.44 \nL 258.367153 160.723333 \nL 255.771813 160.723333 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_80\">\n    <path d=\"M 258.655524 170.44 \nL 261.250863 170.44 \nL 261.250863 170.44 \nL 258.655524 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_81\">\n    <path d=\"M 261.539234 170.44 \nL 264.134574 170.44 \nL 264.134574 170.44 \nL 261.539234 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_82\">\n    <path d=\"M 264.422945 170.44 \nL 267.018284 170.44 \nL 267.018284 170.44 \nL 264.422945 170.44 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_83\">\n    <path d=\"M 267.306656 170.44 \nL 269.901995 170.44 \nL 269.901995 151.006667 \nL 267.306656 151.006667 \nz\n\" clip-path=\"url(#pb189f33007)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m7198f329de\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m7198f329de\" x=\"36.465625\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(33.284375 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m7198f329de\" x=\"94.139836\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 20 -->\n      <g transform=\"translate(87.777336 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m7198f329de\" x=\"151.814047\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 40 -->\n      <g transform=\"translate(145.451547 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m7198f329de\" x=\"209.488259\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 60 -->\n      <g transform=\"translate(203.125759 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m7198f329de\" x=\"267.16247\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 80 -->\n      <g transform=\"translate(260.79997 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-38\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_6\">\n     <!-- number of sentences in each document -->\n     <g transform=\"translate(53.647309 198.716563)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-62\" d=\"M 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\nM 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2969 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-66\" d=\"M 2375 4863 \nL 2375 4384 \nL 1825 4384 \nQ 1516 4384 1395 4259 \nQ 1275 4134 1275 3809 \nL 1275 3500 \nL 2222 3500 \nL 2222 3053 \nL 1275 3053 \nL 1275 0 \nL 697 0 \nL 697 3053 \nL 147 3053 \nL 147 3500 \nL 697 3500 \nL 697 3744 \nQ 697 4328 969 4595 \nQ 1241 4863 1831 4863 \nL 2375 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-6e\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"63.378906\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"126.757812\"/>\n      <use xlink:href=\"#DejaVuSans-62\" x=\"224.169922\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"287.646484\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"349.169922\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"390.283203\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"422.070312\"/>\n      <use xlink:href=\"#DejaVuSans-66\" x=\"483.251953\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"518.457031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"550.244141\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"602.34375\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"663.867188\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"727.246094\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"766.455078\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"827.978516\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"891.357422\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"946.337891\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"1007.861328\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"1059.960938\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"1091.748047\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"1119.53125\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"1182.910156\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"1214.697266\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"1276.220703\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"1337.5\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"1392.480469\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"1455.859375\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"1487.646484\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"1551.123047\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"1612.304688\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"1667.285156\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"1730.664062\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"1828.076172\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"1889.599609\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"1952.978516\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_6\">\n      <defs>\n       <path id=\"mfd7eb44ae7\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mfd7eb44ae7\" x=\"36.465625\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0.0 -->\n      <g transform=\"translate(13.5625 174.239219)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#mfd7eb44ae7\" x=\"36.465625\" y=\"146.148333\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 2.5 -->\n      <g transform=\"translate(13.5625 149.947552)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#mfd7eb44ae7\" x=\"36.465625\" y=\"121.856667\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 5.0 -->\n      <g transform=\"translate(13.5625 125.655885)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#mfd7eb44ae7\" x=\"36.465625\" y=\"97.565\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 7.5 -->\n      <g transform=\"translate(13.5625 101.364219)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#mfd7eb44ae7\" x=\"36.465625\" y=\"73.273333\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 10.0 -->\n      <g transform=\"translate(7.2 77.072552)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#mfd7eb44ae7\" x=\"36.465625\" y=\"48.981667\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 12.5 -->\n      <g transform=\"translate(7.2 52.780885)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mfd7eb44ae7\" x=\"36.465625\" y=\"24.69\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 15.0 -->\n      <g transform=\"translate(7.2 28.489219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_84\">\n    <path d=\"M 36.465625 170.44 \nL 36.465625 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_85\">\n    <path d=\"M 270.046181 170.44 \nL 270.046181 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_86\">\n    <path d=\"M 36.465625 170.44 \nL 270.046181 170.44 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_87\">\n    <path d=\"M 36.465625 7.2 \nL 270.046181 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pb189f33007\">\n   <rect x=\"36.465625\" y=\"7.2\" width=\"233.580556\" height=\"163.24\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ids = df['file_id'].unique()\n",
        "sentences_in_documents = np.array([len(df.loc[df['file_id']==id]) for id in ids])\n",
        "\n",
        "print(f\"Longest document with most sentences is {ids[np.argmax(sentences_in_documents)]} with {np.max(sentences_in_documents)}.\")\n",
        "print(f\"mean sentence number in document is {np.mean(sentences_in_documents):.2f}.\")\n",
        "print(f\"std = {np.std(sentences_in_documents):.2f}.\")\n",
        "\n",
        "m = 80\n",
        "print(f\"Lenghts of documents with more than {m} sentences:\")\n",
        "print(sorted(sentences_in_documents[np.where(sentences_in_documents>m)]))\n",
        "\n",
        "w, h, dpi = 800, 600, 200\n",
        "fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
        "\n",
        "ax.hist(np.where(sentences_in_documents<=m, sentences_in_documents, m+1), bins=np.arange(m+2), rwidth=0.9)\n",
        "ax.set_xlabel('number of sentences in each document')\n",
        "ax.set_xlim(0, m+1)\n",
        "\n",
        "fig.tight_layout()\n",
        "fig.savefig('sentences_in_documents.pdf')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Document lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longest document is 118 with 4534 words.\n",
            "mean document length is 472.78.\n",
            "std = 553.59.\n",
            "Lenghts of documents with more than 2500 words:\n",
            "[2900, 4534]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"280.123669pt\" height=\"207.99625pt\" viewBox=\"0 0 280.123669 207.99625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-12-12T19:21:03.876045</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 207.99625 \nL 280.123669 207.99625 \nL 280.123669 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 170.44 \nL 269.529615 170.44 \nL 269.529615 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 27.391547 170.44 \nL 35.789399 170.44 \nL 35.789399 14.973333 \nL 27.391547 14.973333 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 36.722494 170.44 \nL 45.120346 170.44 \nL 45.120346 46.066667 \nL 36.722494 46.066667 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 46.053441 170.44 \nL 54.451293 170.44 \nL 54.451293 108.253333 \nL 46.053441 108.253333 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 55.384388 170.44 \nL 63.78224 170.44 \nL 63.78224 136.237333 \nL 55.384388 136.237333 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 64.715334 170.44 \nL 73.113186 170.44 \nL 73.113186 148.674667 \nL 64.715334 148.674667 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 74.046281 170.44 \nL 82.444133 170.44 \nL 82.444133 123.8 \nL 74.046281 123.8 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 83.377228 170.44 \nL 91.77508 170.44 \nL 91.77508 151.784 \nL 83.377228 151.784 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 92.708175 170.44 \nL 101.106027 170.44 \nL 101.106027 154.893333 \nL 92.708175 154.893333 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 102.039121 170.44 \nL 110.436973 170.44 \nL 110.436973 151.784 \nL 102.039121 151.784 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 111.370068 170.44 \nL 119.76792 170.44 \nL 119.76792 130.018667 \nL 111.370068 130.018667 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 120.701015 170.44 \nL 129.098867 170.44 \nL 129.098867 148.674667 \nL 120.701015 148.674667 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 130.031962 170.44 \nL 138.429814 170.44 \nL 138.429814 161.112 \nL 130.031962 161.112 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 139.362908 170.44 \nL 147.76076 170.44 \nL 147.76076 164.221333 \nL 139.362908 164.221333 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 148.693855 170.44 \nL 157.091707 170.44 \nL 157.091707 161.112 \nL 148.693855 161.112 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path d=\"M 158.024802 170.44 \nL 166.422654 170.44 \nL 166.422654 167.330667 \nL 158.024802 167.330667 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 167.355749 170.44 \nL 175.753601 170.44 \nL 175.753601 164.221333 \nL 167.355749 164.221333 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 176.686695 170.44 \nL 185.084547 170.44 \nL 185.084547 161.112 \nL 176.686695 161.112 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 186.017642 170.44 \nL 194.415494 170.44 \nL 194.415494 167.330667 \nL 186.017642 167.330667 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 195.348589 170.44 \nL 203.746441 170.44 \nL 203.746441 164.221333 \nL 195.348589 164.221333 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path d=\"M 204.679536 170.44 \nL 213.077388 170.44 \nL 213.077388 170.44 \nL 204.679536 170.44 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 214.010482 170.44 \nL 222.408334 170.44 \nL 222.408334 170.44 \nL 214.010482 170.44 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 223.341429 170.44 \nL 231.739281 170.44 \nL 231.739281 170.44 \nL 223.341429 170.44 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 232.672376 170.44 \nL 241.070228 170.44 \nL 241.070228 170.44 \nL 232.672376 170.44 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 242.003322 170.44 \nL 250.401175 170.44 \nL 250.401175 170.44 \nL 242.003322 170.44 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path d=\"M 251.334269 170.44 \nL 259.732121 170.44 \nL 259.732121 170.44 \nL 251.334269 170.44 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 260.665216 170.44 \nL 269.063068 170.44 \nL 269.063068 164.221333 \nL 260.665216 164.221333 \nz\n\" clip-path=\"url(#p96d23ef59e)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m2f43535502\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m2f43535502\" x=\"26.925\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(23.74375 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m2f43535502\" x=\"73.579734\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 500 -->\n      <g transform=\"translate(64.035984 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m2f43535502\" x=\"120.234467\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 1000 -->\n      <g transform=\"translate(107.509467 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m2f43535502\" x=\"166.889201\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 1500 -->\n      <g transform=\"translate(154.164201 185.038437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m2f43535502\" x=\"213.543935\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 2000 -->\n      <g transform=\"translate(200.818935 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m2f43535502\" x=\"260.198669\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 2500 -->\n      <g transform=\"translate(247.473669 185.038437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"190.869141\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_7\">\n     <!-- document length in words -->\n     <g transform=\"translate(82.842151 198.716563)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6d\" d=\"M 3328 2828 \nQ 3544 3216 3844 3400 \nQ 4144 3584 4550 3584 \nQ 5097 3584 5394 3201 \nQ 5691 2819 5691 2113 \nL 5691 0 \nL 5113 0 \nL 5113 2094 \nQ 5113 2597 4934 2840 \nQ 4756 3084 4391 3084 \nQ 3944 3084 3684 2787 \nQ 3425 2491 3425 1978 \nL 3425 0 \nL 2847 0 \nL 2847 2094 \nQ 2847 2600 2669 2842 \nQ 2491 3084 2119 3084 \nQ 1678 3084 1418 2786 \nQ 1159 2488 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1356 3278 1631 3431 \nQ 1906 3584 2284 3584 \nQ 2666 3584 2933 3390 \nQ 3200 3197 3328 2828 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-77\" d=\"M 269 3500 \nL 844 3500 \nL 1563 769 \nL 2278 3500 \nL 2956 3500 \nL 3675 769 \nL 4391 3500 \nL 4966 3500 \nL 4050 0 \nL 3372 0 \nL 2619 2869 \nL 1863 0 \nL 1184 0 \nL 269 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-64\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"63.476562\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"124.658203\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"179.638672\"/>\n      <use xlink:href=\"#DejaVuSans-6d\" x=\"243.017578\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"340.429688\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"401.953125\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"465.332031\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"504.541016\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"536.328125\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"564.111328\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"625.634766\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"689.013672\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"752.490234\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"791.699219\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"855.078125\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"886.865234\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"914.648438\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"978.027344\"/>\n      <use xlink:href=\"#DejaVuSans-77\" x=\"1009.814453\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"1091.601562\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"1152.783203\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"1192.146484\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"1255.623047\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path id=\"m741d86ea19\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m741d86ea19\" x=\"26.925\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 174.239219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m741d86ea19\" x=\"26.925\" y=\"139.346667\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 143.145885)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m741d86ea19\" x=\"26.925\" y=\"108.253333\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 112.052552)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m741d86ea19\" x=\"26.925\" y=\"77.16\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 80.959219)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m741d86ea19\" x=\"26.925\" y=\"46.066667\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 40 -->\n      <g transform=\"translate(7.2 49.865885)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m741d86ea19\" x=\"26.925\" y=\"14.973333\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 50 -->\n      <g transform=\"translate(7.2 18.772552)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 26.925 170.44 \nL 26.925 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path d=\"M 269.529615 170.44 \nL 269.529615 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 26.925 170.44 \nL 269.529615 170.44 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path d=\"M 26.925 7.2 \nL 269.529615 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p96d23ef59e\">\n   <rect x=\"26.925\" y=\"7.2\" width=\"242.604615\" height=\"163.24\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "ids = df['file_id'].unique()\n",
        "document_lengths = [sum([len(df.loc[df['file_id']==doc_id]['text'][sentence_index]) for sentence_index in df.loc[df['file_id']==doc_id]['text'].index]) for doc_id in ids]\n",
        "document_lengths =  np.array(document_lengths)\n",
        "\n",
        "print(f\"Longest document is {ids[np.argmax(document_lengths)]} with {np.max(document_lengths)} words.\")\n",
        "print(f\"mean document length is {np.mean(document_lengths):.2f}.\")\n",
        "print(f\"std = {np.std(document_lengths):.2f}.\")\n",
        "\n",
        "m = 2500\n",
        "print(f\"Lenghts of documents with more than {m} words:\")\n",
        "print(sorted(document_lengths[np.where(document_lengths>m)]))\n",
        "\n",
        "w, h, dpi = 800, 600, 200\n",
        "fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
        "\n",
        "s=100\n",
        "ax.hist(np.where(document_lengths<=m, document_lengths, m+1), bins=np.arange(m+2*s, step=s), rwidth=0.9)\n",
        "ax.set_xlabel('document length in words')\n",
        "ax.set_xlim(0, m+s)\n",
        "\n",
        "fig.tight_layout()\n",
        "fig.savefig('document_lengths.pdf')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Sentence lengths"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 160,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Longest sentence has 249 words.\n",
            "mean sentence length is 24.04 words.\n",
            "std = 11.86.\n",
            "Lenghts of sentences longer than 60 words:\n",
            "[61, 62, 63, 63, 63, 64, 65, 66, 66, 67, 68, 70, 74, 75, 78, 81, 81, 89, 100, 111, 114, 249]\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"280.632639pt\" height=\"207.99625pt\" viewBox=\"0 0 280.632639 207.99625\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2022-12-12T19:21:07.459730</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.5.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 207.99625 \nL 280.632639 207.99625 \nL 280.632639 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 33.2875 170.44 \nL 270.966516 170.44 \nL 270.966516 7.2 \nL 33.2875 7.2 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 33.482319 170.44 \nL 36.989058 170.44 \nL 36.989058 170.44 \nL 33.482319 170.44 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 37.378696 170.44 \nL 40.885436 170.44 \nL 40.885436 169.468333 \nL 37.378696 169.468333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 41.275074 170.44 \nL 44.781813 170.44 \nL 44.781813 151.978333 \nL 41.275074 151.978333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 45.171451 170.44 \nL 48.67819 170.44 \nL 48.67819 160.723333 \nL 45.171451 160.723333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_7\">\n    <path d=\"M 49.067828 170.44 \nL 52.574568 170.44 \nL 52.574568 146.148333 \nL 49.067828 146.148333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_8\">\n    <path d=\"M 52.964205 170.44 \nL 56.470945 170.44 \nL 56.470945 134.488333 \nL 52.964205 134.488333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_9\">\n    <path d=\"M 56.860583 170.44 \nL 60.367322 170.44 \nL 60.367322 129.63 \nL 56.860583 129.63 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_10\">\n    <path d=\"M 60.75696 170.44 \nL 64.2637 170.44 \nL 64.2637 111.168333 \nL 60.75696 111.168333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_11\">\n    <path d=\"M 64.653337 170.44 \nL 68.160077 170.44 \nL 68.160077 123.8 \nL 64.653337 123.8 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_12\">\n    <path d=\"M 68.549715 170.44 \nL 72.056454 170.44 \nL 72.056454 92.706667 \nL 68.549715 92.706667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_13\">\n    <path d=\"M 72.446092 170.44 \nL 75.952832 170.44 \nL 75.952832 102.423333 \nL 72.446092 102.423333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_14\">\n    <path d=\"M 76.342469 170.44 \nL 79.849209 170.44 \nL 79.849209 97.565 \nL 76.342469 97.565 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_15\">\n    <path d=\"M 80.238847 170.44 \nL 83.745586 170.44 \nL 83.745586 73.273333 \nL 80.238847 73.273333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_16\">\n    <path d=\"M 84.135224 170.44 \nL 87.641964 170.44 \nL 87.641964 58.698333 \nL 84.135224 58.698333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_17\">\n    <path d=\"M 88.031601 170.44 \nL 91.538341 170.44 \nL 91.538341 56.755 \nL 88.031601 56.755 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_18\">\n    <path d=\"M 91.927979 170.44 \nL 95.434718 170.44 \nL 95.434718 51.896667 \nL 91.927979 51.896667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_19\">\n    <path d=\"M 95.824356 170.44 \nL 99.331096 170.44 \nL 99.331096 43.151667 \nL 95.824356 43.151667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_20\">\n    <path d=\"M 99.720733 170.44 \nL 103.227473 170.44 \nL 103.227473 59.67 \nL 99.720733 59.67 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_21\">\n    <path d=\"M 103.617111 170.44 \nL 107.12385 170.44 \nL 107.12385 32.463333 \nL 103.617111 32.463333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_22\">\n    <path d=\"M 107.513488 170.44 \nL 111.020227 170.44 \nL 111.020227 38.293333 \nL 107.513488 38.293333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_23\">\n    <path d=\"M 111.409865 170.44 \nL 114.916605 170.44 \nL 114.916605 14.973333 \nL 111.409865 14.973333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_24\">\n    <path d=\"M 115.306243 170.44 \nL 118.812982 170.44 \nL 118.812982 30.52 \nL 115.306243 30.52 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_25\">\n    <path d=\"M 119.20262 170.44 \nL 122.709359 170.44 \nL 122.709359 18.86 \nL 119.20262 18.86 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_26\">\n    <path d=\"M 123.098997 170.44 \nL 126.605737 170.44 \nL 126.605737 35.378333 \nL 123.098997 35.378333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_27\">\n    <path d=\"M 126.995374 170.44 \nL 130.502114 170.44 \nL 130.502114 27.605 \nL 126.995374 27.605 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_28\">\n    <path d=\"M 130.891752 170.44 \nL 134.398491 170.44 \nL 134.398491 42.18 \nL 130.891752 42.18 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_29\">\n    <path d=\"M 134.788129 170.44 \nL 138.294869 170.44 \nL 138.294869 39.265 \nL 134.788129 39.265 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_30\">\n    <path d=\"M 138.684506 170.44 \nL 142.191246 170.44 \nL 142.191246 48.981667 \nL 138.684506 48.981667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_31\">\n    <path d=\"M 142.580884 170.44 \nL 146.087623 170.44 \nL 146.087623 63.556667 \nL 142.580884 63.556667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_32\">\n    <path d=\"M 146.477261 170.44 \nL 149.984001 170.44 \nL 149.984001 56.755 \nL 146.477261 56.755 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_33\">\n    <path d=\"M 150.373638 170.44 \nL 153.880378 170.44 \nL 153.880378 70.358333 \nL 150.373638 70.358333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_34\">\n    <path d=\"M 154.270016 170.44 \nL 157.776755 170.44 \nL 157.776755 82.018333 \nL 154.270016 82.018333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_35\">\n    <path d=\"M 158.166393 170.44 \nL 161.673133 170.44 \nL 161.673133 84.933333 \nL 158.166393 84.933333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_36\">\n    <path d=\"M 162.06277 170.44 \nL 165.56951 170.44 \nL 165.56951 81.046667 \nL 162.06277 81.046667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_37\">\n    <path d=\"M 165.959148 170.44 \nL 169.465887 170.44 \nL 169.465887 85.905 \nL 165.959148 85.905 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_38\">\n    <path d=\"M 169.855525 170.44 \nL 173.362265 170.44 \nL 173.362265 89.791667 \nL 169.855525 89.791667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_39\">\n    <path d=\"M 173.751902 170.44 \nL 177.258642 170.44 \nL 177.258642 99.508333 \nL 173.751902 99.508333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_40\">\n    <path d=\"M 177.64828 170.44 \nL 181.155019 170.44 \nL 181.155019 110.196667 \nL 177.64828 110.196667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_41\">\n    <path d=\"M 181.544657 170.44 \nL 185.051397 170.44 \nL 185.051397 109.225 \nL 181.544657 109.225 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_42\">\n    <path d=\"M 185.441034 170.44 \nL 188.947774 170.44 \nL 188.947774 126.715 \nL 185.441034 126.715 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_43\">\n    <path d=\"M 189.337412 170.44 \nL 192.844151 170.44 \nL 192.844151 139.346667 \nL 189.337412 139.346667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_44\">\n    <path d=\"M 193.233789 170.44 \nL 196.740528 170.44 \nL 196.740528 145.176667 \nL 193.233789 145.176667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_45\">\n    <path d=\"M 197.130166 170.44 \nL 200.636906 170.44 \nL 200.636906 132.545 \nL 197.130166 132.545 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_46\">\n    <path d=\"M 201.026544 170.44 \nL 204.533283 170.44 \nL 204.533283 149.063333 \nL 201.026544 149.063333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_47\">\n    <path d=\"M 204.922921 170.44 \nL 208.42966 170.44 \nL 208.42966 147.12 \nL 204.922921 147.12 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_48\">\n    <path d=\"M 208.819298 170.44 \nL 212.326038 170.44 \nL 212.326038 149.063333 \nL 208.819298 149.063333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_49\">\n    <path d=\"M 212.715675 170.44 \nL 216.222415 170.44 \nL 216.222415 153.921667 \nL 212.715675 153.921667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_50\">\n    <path d=\"M 216.612053 170.44 \nL 220.118792 170.44 \nL 220.118792 156.836667 \nL 216.612053 156.836667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_51\">\n    <path d=\"M 220.50843 170.44 \nL 224.01517 170.44 \nL 224.01517 151.006667 \nL 220.50843 151.006667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_52\">\n    <path d=\"M 224.404807 170.44 \nL 227.911547 170.44 \nL 227.911547 155.865 \nL 224.404807 155.865 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_53\">\n    <path d=\"M 228.301185 170.44 \nL 231.807924 170.44 \nL 231.807924 154.893333 \nL 228.301185 154.893333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_54\">\n    <path d=\"M 232.197562 170.44 \nL 235.704302 170.44 \nL 235.704302 161.695 \nL 232.197562 161.695 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_55\">\n    <path d=\"M 236.093939 170.44 \nL 239.600679 170.44 \nL 239.600679 165.581667 \nL 236.093939 165.581667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_56\">\n    <path d=\"M 239.990317 170.44 \nL 243.497056 170.44 \nL 243.497056 160.723333 \nL 239.990317 160.723333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_57\">\n    <path d=\"M 243.886694 170.44 \nL 247.393434 170.44 \nL 247.393434 166.553333 \nL 243.886694 166.553333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_58\">\n    <path d=\"M 247.783071 170.44 \nL 251.289811 170.44 \nL 251.289811 167.525 \nL 247.783071 167.525 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_59\">\n    <path d=\"M 251.679449 170.44 \nL 255.186188 170.44 \nL 255.186188 165.581667 \nL 251.679449 165.581667 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_60\">\n    <path d=\"M 255.575826 170.44 \nL 259.082566 170.44 \nL 259.082566 167.525 \nL 255.575826 167.525 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_61\">\n    <path d=\"M 259.472203 170.44 \nL 262.978943 170.44 \nL 262.978943 164.61 \nL 259.472203 164.61 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_62\">\n    <path d=\"M 263.368581 170.44 \nL 266.87532 170.44 \nL 266.87532 169.468333 \nL 263.368581 169.468333 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"patch_63\">\n    <path d=\"M 267.264958 170.44 \nL 270.771698 170.44 \nL 270.771698 147.12 \nL 267.264958 147.12 \nz\n\" clip-path=\"url(#p1de8f4c821)\" style=\"fill: #1f77b4\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"meb175d3a40\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#meb175d3a40\" x=\"33.2875\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(30.10625 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#meb175d3a40\" x=\"72.251273\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <g transform=\"translate(65.888773 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#meb175d3a40\" x=\"111.215046\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <g transform=\"translate(104.852546 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#meb175d3a40\" x=\"150.17882\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30 -->\n      <g transform=\"translate(143.81632 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#meb175d3a40\" x=\"189.142593\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40 -->\n      <g transform=\"translate(182.780093 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#meb175d3a40\" x=\"228.106366\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50 -->\n      <g transform=\"translate(221.743866 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#meb175d3a40\" x=\"267.070139\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 60 -->\n      <g transform=\"translate(260.707639 185.038437)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_8\">\n     <!-- sentence length in words -->\n     <g transform=\"translate(89.087946 198.716563)scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-65\" d=\"M 3597 1894 \nL 3597 1613 \nL 953 1613 \nQ 991 1019 1311 708 \nQ 1631 397 2203 397 \nQ 2534 397 2845 478 \nQ 3156 559 3463 722 \nL 3463 178 \nQ 3153 47 2828 -22 \nQ 2503 -91 2169 -91 \nQ 1331 -91 842 396 \nQ 353 884 353 1716 \nQ 353 2575 817 3079 \nQ 1281 3584 2069 3584 \nQ 2775 3584 3186 3129 \nQ 3597 2675 3597 1894 \nz\nM 3022 2063 \nQ 3016 2534 2758 2815 \nQ 2500 3097 2075 3097 \nQ 1594 3097 1305 2825 \nQ 1016 2553 972 2059 \nL 3022 2063 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-77\" d=\"M 269 3500 \nL 844 3500 \nL 1563 769 \nL 2278 3500 \nL 2956 3500 \nL 3675 769 \nL 4391 3500 \nL 4966 3500 \nL 4050 0 \nL 3372 0 \nL 2619 2869 \nL 1863 0 \nL 1184 0 \nL 269 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-73\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"52.099609\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"113.623047\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"177.001953\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"216.210938\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"277.734375\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"341.113281\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"396.09375\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"457.617188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"489.404297\"/>\n      <use xlink:href=\"#DejaVuSans-65\" x=\"517.1875\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"578.710938\"/>\n      <use xlink:href=\"#DejaVuSans-67\" x=\"642.089844\"/>\n      <use xlink:href=\"#DejaVuSans-74\" x=\"705.566406\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"744.775391\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"808.154297\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"839.941406\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"867.724609\"/>\n      <use xlink:href=\"#DejaVuSans-20\" x=\"931.103516\"/>\n      <use xlink:href=\"#DejaVuSans-77\" x=\"962.890625\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"1044.677734\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"1105.859375\"/>\n      <use xlink:href=\"#DejaVuSans-64\" x=\"1145.222656\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"1208.699219\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path id=\"m70dcc7fe08\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m70dcc7fe08\" x=\"33.2875\" y=\"170.44\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 0 -->\n      <g transform=\"translate(19.925 174.239219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m70dcc7fe08\" x=\"33.2875\" y=\"146.148333\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 25 -->\n      <g transform=\"translate(13.5625 149.947552)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use xlink:href=\"#m70dcc7fe08\" x=\"33.2875\" y=\"121.856667\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 50 -->\n      <g transform=\"translate(13.5625 125.655885)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m70dcc7fe08\" x=\"33.2875\" y=\"97.565\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 75 -->\n      <g transform=\"translate(13.5625 101.364219)scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m70dcc7fe08\" x=\"33.2875\" y=\"73.273333\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 100 -->\n      <g transform=\"translate(7.2 77.072552)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m70dcc7fe08\" x=\"33.2875\" y=\"48.981667\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 125 -->\n      <g transform=\"translate(7.2 52.780885)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m70dcc7fe08\" x=\"33.2875\" y=\"24.69\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 150 -->\n      <g transform=\"translate(7.2 28.489219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_64\">\n    <path d=\"M 33.2875 170.44 \nL 33.2875 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_65\">\n    <path d=\"M 270.966516 170.44 \nL 270.966516 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_66\">\n    <path d=\"M 33.2875 170.44 \nL 270.966516 170.44 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_67\">\n    <path d=\"M 33.2875 7.2 \nL 270.966516 7.2 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p1de8f4c821\">\n   <rect x=\"33.2875\" y=\"7.2\" width=\"237.679016\" height=\"163.24\"/>\n  </clipPath>\n </defs>\n</svg>\n",
            "text/plain": [
              "<Figure size 800x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sentence_lengths = np.array([len(text) for text in df['text']])\n",
        "\n",
        "print(f\"Longest sentence has {np.max(sentence_lengths)} words.\")\n",
        "print(f\"mean sentence length is {np.mean(sentence_lengths):.2f} words.\")\n",
        "print(f\"std = {np.std(sentence_lengths):.2f}.\")\n",
        "\n",
        "m = 60\n",
        "print(f\"Lenghts of sentences longer than {m} words:\")\n",
        "print(sorted(sentence_lengths[np.where(sentence_lengths>m)]))\n",
        "\n",
        "w, h, dpi = 800, 600, 200\n",
        "fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
        "\n",
        "ax.hist(np.where(sentence_lengths<=m, sentence_lengths, m+1), bins=np.arange(m+2), rwidth=0.9)\n",
        "ax.set_xlabel('sentence length in words')\n",
        "ax.set_xlim(0, m+1)\n",
        "\n",
        "fig.tight_layout()\n",
        "fig.savefig('sentence_lengths.pdf')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igBEseAqgIpK"
      },
      "source": [
        "## Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qya3qo9QgIpK",
        "outputId": "9ef7ce31-0da7-48ef-fe10-de22a05e74f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset splits statistics: \n",
            "Train data: (1963,)\n",
            "Validation data: (1299,)\n",
            "Test data: (652,)\n"
          ]
        }
      ],
      "source": [
        "train_data = df[df['split'] == 'train']\n",
        "val_data = df[df['split'] == 'val']\n",
        "test_data = df[df['split'] == 'test']\n",
        "\n",
        "x_train = train_data['text'].values\n",
        "y_train = train_data['tags'].values\n",
        "\n",
        "x_val = val_data['text'].values\n",
        "y_val = val_data['tags'].values\n",
        "\n",
        "x_test = test_data['text'].values\n",
        "y_test = test_data['tags'].values\n",
        "\n",
        "print('Dataset splits statistics: ')\n",
        "print(f'Train data: {x_train.shape}')\n",
        "print(f'Validation data: {x_val.shape}')\n",
        "print(f'Test data: {x_test.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIFpQxIKgIpK"
      },
      "source": [
        "## Add OOV words to GloVe embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ9I7HVNgIpK",
        "outputId": "5e2a7395-5f58-4041-fc1e-00ee002bcb36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading GloVe embedding.\n",
            "[=================================================-] 98.1% 64.7/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "from utils.preprocessing import load_embedding_model, add_OOV_embeddings\n",
        "\n",
        "print(\"Loading GloVe embedding.\")\n",
        "my_embedding_dimension = 50\n",
        "my_embedding_model = load_embedding_model('glove', my_embedding_dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCqQiHAjgIpK",
        "outputId": "5f9345d7-2680-4fd3-d4a0-913b8b036cce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GLOVE vocabulary size:  400000\n",
            "Add unknown token [UNK] and padding token \n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 33.20it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "V1 size:  400002\n",
            "\n",
            "Creating V2 using training set (V1 + OOV1)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 359/359 [00:07<00:00, 46.84it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "V2 size:  400361\n",
            "\n",
            "Creating V3 using validation set (V2 + OOV2)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 189/189 [00:03<00:00, 48.97it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "V3 size:  400550\n",
            "\n",
            "Creating V4 using validation set (V3 + OOV3)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 128/128 [00:02<00:00, 46.21it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "V4 size:  400678\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"GLOVE vocabulary size: \", len(my_embedding_model))\n",
        "\n",
        "unknown_token = '[UNK]'\n",
        "padding_token = ''\n",
        "\n",
        "print(f\"Add unknown token {unknown_token} and padding token {padding_token}\")\n",
        "add_OOV_embeddings(my_embedding_model, [unknown_token, padding_token], my_embedding_dimension)\n",
        "print(\"V1 size: \", len(my_embedding_model))\n",
        "\n",
        "print(\"\\nCreating V2 using training set (V1 + OOV1)\")\n",
        "add_OOV_embeddings(my_embedding_model, x_train, my_embedding_dimension)\n",
        "print(\"V2 size: \", len(my_embedding_model))\n",
        "\n",
        "print(\"\\nCreating V3 using validation set (V2 + OOV2)\")\n",
        "add_OOV_embeddings(my_embedding_model, x_val, my_embedding_dimension)\n",
        "print(\"V3 size: \", len(my_embedding_model))\n",
        "\n",
        "print(\"\\nCreating V4 using validation set (V3 + OOV3)\")\n",
        "add_OOV_embeddings(my_embedding_model, x_test, my_embedding_dimension)\n",
        "print(\"V4 size: \", len(my_embedding_model))\n",
        "\n",
        "# build vocabulary for x\n",
        "dataset_vocabulary = np.unique([word for sentence in df['text'] for word in sentence])\n",
        "dataset_vocabulary = np.concatenate([[unknown_token], dataset_vocabulary])\n",
        "\n",
        "# build vocabulary for y\n",
        "tags_s = ' '.join([' '.join(y) for y in df['tags']])\n",
        "tag_vocabulary = pd.DataFrame(tags_s.split())[0].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhUXQOQOgIpL"
      },
      "source": [
        "## Explore Tags and define punctuation tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElFVcIWjgIpL",
        "outputId": "0b720bb5-09e5-4d25-af68-5708239a7b6a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['NNP', ',', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', '.',\n",
              "       'VBZ', 'VBG', 'CC', 'VBD', 'VBN', '``', 'EX', \"''\", 'WDT', 'RB',\n",
              "       'RP', 'TO', 'WRB', 'RBR', 'VBP', 'JJR', 'WP', 'JJS', 'PRP', ':',\n",
              "       'POS', 'PRP$', '$', 'NNPS', 'WP$', '-LRB-', '-RRB-', 'PDT', 'RBS',\n",
              "       'FW', 'UH', 'SYM', 'LS', '#'], dtype=object)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tag_vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuXAhDi-gIpL"
      },
      "source": [
        "Mmh, there are some interesting looking tags. Let's build a DataFrame with some sentence examples to see what they mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Hjt38_VXgIpL"
      },
      "outputs": [],
      "source": [
        "d = {}\n",
        "\n",
        "for tag in tag_vocabulary:\n",
        "    i = df.loc[np.array([tag in t for t in df['tags']])].index[0]\n",
        "    s1 = df['text'][i]\n",
        "    t1 = df['tags'][i]\n",
        "    d[f'{tag} (w)'] = np.pad(s1, (0,90-len(s1)))\n",
        "    d[f'{tag} (t)'] = np.pad(t1, (0,90-len(t1)))\n",
        "\n",
        "with open('phrase_examples.csv', 'w') as f:\n",
        "    f.write(pd.DataFrame(d).to_csv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VjKb81QgIpM"
      },
      "source": [
        "After examining the resulting file, we know what the punctuation tags are. Let's put them in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "plFOBkssgIpM"
      },
      "outputs": [],
      "source": [
        "punctuation_tags = [',',\n",
        "                    '.',\n",
        "                    '``',\n",
        "                    \"''\",\n",
        "                    ':',\n",
        "                    '-LRB-',\n",
        "                    '-RRB-']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2rKisskgIpM"
      },
      "source": [
        "## Padding x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESiLWuI4gIpM",
        "outputId": "f96d4e93-9510-43ca-d2b9-61896173e235"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The padding length is 44\n"
          ]
        }
      ],
      "source": [
        "padding_length = int(df['tags'].apply(lambda x: len(x)).quantile(0.95))\n",
        "print(\"The padding length is\", padding_length)\n",
        "\n",
        "dataset_dict = {k: i for i, k in enumerate(dataset_vocabulary)}\n",
        "\n",
        "def tokenize_x(x):\n",
        "    return [[dataset_dict[word] for word in phrase] for phrase in x]\n",
        "\n",
        "x_train_tokenized = tokenize_x(x_train)\n",
        "x_val_tokenized = tokenize_x(x_val)\n",
        "x_test_tokenized = tokenize_x(x_test)\n",
        "\n",
        "x_train_pad = tf.keras.preprocessing.sequence.pad_sequences(x_train_tokenized, maxlen=padding_length, padding=\"post\")\n",
        "x_val_pad = tf.keras.preprocessing.sequence.pad_sequences(x_val_tokenized, maxlen=padding_length, padding=\"post\")\n",
        "x_test_pad = tf.keras.preprocessing.sequence.pad_sequences(x_test_tokenized, maxlen=padding_length, padding=\"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsGEMRh-gIpM"
      },
      "source": [
        "## Padding y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tznLopnrgIpM"
      },
      "outputs": [],
      "source": [
        "tag_dict = {k: i for i, k in enumerate(tag_vocabulary)}\n",
        "\n",
        "def tokenize_y(y):\n",
        "    return [[tag_dict[tag] for tag in phrase] for phrase in y]\n",
        "\n",
        "y_train_tokenized = tokenize_y(y_train)\n",
        "y_val_tokenized = tokenize_y(y_val)\n",
        "y_test_tokenized = tokenize_y(y_test)\n",
        "\n",
        "y_train_pad = tf.keras.preprocessing.sequence.pad_sequences(y_train_tokenized, maxlen=padding_length, padding=\"post\")\n",
        "y_val_pad = tf.keras.preprocessing.sequence.pad_sequences(y_val_tokenized, maxlen=padding_length, padding=\"post\")\n",
        "y_test_pad = tf.keras.preprocessing.sequence.pad_sequences(y_test_tokenized, maxlen=padding_length, padding=\"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21U5S5GYgIpN"
      },
      "source": [
        "# Train Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bVXtGu6dgIpN"
      },
      "outputs": [],
      "source": [
        "from keras.optimizer_v2.adam import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from functools import partial\n",
        "\n",
        "from utils.training_utils import MyHistory, plot_history\n",
        "from models import embedding_layer\n",
        "\n",
        "embedding_func = partial(embedding_layer,\n",
        "                         vocabulary=dataset_vocabulary,\n",
        "                         embedding_model=my_embedding_model,\n",
        "                         embedding_dimension=my_embedding_dimension)\n",
        "\n",
        "try:\n",
        "    weights_folder = os.path.join(drive_folder, \"weights\")\n",
        "except NameError as e:\n",
        "    weights_folder = \"weights\"\n",
        "\n",
        "checkpoint_partial = partial(ModelCheckpoint, monitor=\"val_loss\", mode=\"auto\")#, save_format=\"tf\")\n",
        "compile_args = dict(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "input_shape = (padding_length, my_embedding_dimension)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llojTn_UgIpN"
      },
      "source": [
        "## Baseline LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hfa8_PBLgIpN",
        "outputId": "fda13aa4-490a-48b6-eaed-5f060a981560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 4s 132ms/step - loss: 3.7878 - acc: 0.0684 - val_loss: 3.7559 - val_acc: 0.2263\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.7388 - acc: 0.3667 - val_loss: 3.7079 - val_acc: 0.4647\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 3.6892 - acc: 0.4811 - val_loss: 3.6584 - val_acc: 0.5092\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 3.6374 - acc: 0.5160 - val_loss: 3.6058 - val_acc: 0.5332\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 3.5811 - acc: 0.5332 - val_loss: 3.5475 - val_acc: 0.5430\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 3.5180 - acc: 0.5395 - val_loss: 3.4804 - val_acc: 0.5443\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 3.4436 - acc: 0.5402 - val_loss: 3.4000 - val_acc: 0.5425\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 3.3533 - acc: 0.5383 - val_loss: 3.3000 - val_acc: 0.5391\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 3.2393 - acc: 0.5355 - val_loss: 3.1725 - val_acc: 0.5353\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 3.0941 - acc: 0.5325 - val_loss: 3.0092 - val_acc: 0.5300\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 2.9115 - acc: 0.5294 - val_loss: 2.8128 - val_acc: 0.5269\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.7066 - acc: 0.5274 - val_loss: 2.6083 - val_acc: 0.5246\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.5125 - acc: 0.5262 - val_loss: 2.4308 - val_acc: 0.5230\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.3534 - acc: 0.5253 - val_loss: 2.2915 - val_acc: 0.5220\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.2287 - acc: 0.5247 - val_loss: 2.1831 - val_acc: 0.5217\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.1309 - acc: 0.5243 - val_loss: 2.0959 - val_acc: 0.5218\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 2.0519 - acc: 0.5243 - val_loss: 2.0242 - val_acc: 0.5225\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.9863 - acc: 0.5247 - val_loss: 1.9641 - val_acc: 0.5237\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.9313 - acc: 0.5257 - val_loss: 1.9125 - val_acc: 0.5248\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.8838 - acc: 0.5266 - val_loss: 1.8675 - val_acc: 0.5265\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.8424 - acc: 0.5279 - val_loss: 1.8282 - val_acc: 0.5288\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.8063 - acc: 0.5302 - val_loss: 1.7939 - val_acc: 0.5313\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.7750 - acc: 0.5325 - val_loss: 1.7642 - val_acc: 0.5342\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.7477 - acc: 0.5350 - val_loss: 1.7388 - val_acc: 0.5370\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.7239 - acc: 0.5374 - val_loss: 1.7164 - val_acc: 0.5399\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.7027 - acc: 0.5400 - val_loss: 1.6965 - val_acc: 0.5429\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.6836 - acc: 0.5432 - val_loss: 1.6787 - val_acc: 0.5467\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.6664 - acc: 0.5459 - val_loss: 1.6625 - val_acc: 0.5503\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.6507 - acc: 0.5492 - val_loss: 1.6476 - val_acc: 0.5541\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.6362 - acc: 0.5529 - val_loss: 1.6338 - val_acc: 0.5577\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.6228 - acc: 0.5565 - val_loss: 1.6208 - val_acc: 0.5609\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.6102 - acc: 0.5596 - val_loss: 1.6086 - val_acc: 0.5641\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5982 - acc: 0.5627 - val_loss: 1.5971 - val_acc: 0.5665\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5868 - acc: 0.5655 - val_loss: 1.5861 - val_acc: 0.5693\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5759 - acc: 0.5686 - val_loss: 1.5755 - val_acc: 0.5731\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.5654 - acc: 0.5721 - val_loss: 1.5652 - val_acc: 0.5765\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5552 - acc: 0.5749 - val_loss: 1.5553 - val_acc: 0.5782\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.5454 - acc: 0.5776 - val_loss: 1.5458 - val_acc: 0.5820\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.5359 - acc: 0.5807 - val_loss: 1.5366 - val_acc: 0.5847\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.5266 - acc: 0.5836 - val_loss: 1.5276 - val_acc: 0.5878\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.5176 - acc: 0.5873 - val_loss: 1.5188 - val_acc: 0.5913\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.5088 - acc: 0.5899 - val_loss: 1.5102 - val_acc: 0.5936\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5002 - acc: 0.5924 - val_loss: 1.5017 - val_acc: 0.5964\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.4917 - acc: 0.5949 - val_loss: 1.4934 - val_acc: 0.5990\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.4834 - acc: 0.5975 - val_loss: 1.4852 - val_acc: 0.6024\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.4752 - acc: 0.6008 - val_loss: 1.4771 - val_acc: 0.6049\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.4672 - acc: 0.6034 - val_loss: 1.4691 - val_acc: 0.6079\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.4592 - acc: 0.6067 - val_loss: 1.4613 - val_acc: 0.6110\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4513 - acc: 0.6095 - val_loss: 1.4536 - val_acc: 0.6136\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.4436 - acc: 0.6123 - val_loss: 1.4458 - val_acc: 0.6164\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.4359 - acc: 0.6148 - val_loss: 1.4383 - val_acc: 0.6189\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.4283 - acc: 0.6180 - val_loss: 1.4308 - val_acc: 0.6218\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.4208 - acc: 0.6203 - val_loss: 1.4235 - val_acc: 0.6247\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.4134 - acc: 0.6231 - val_loss: 1.4160 - val_acc: 0.6270\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.4061 - acc: 0.6266 - val_loss: 1.4086 - val_acc: 0.6306\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3988 - acc: 0.6288 - val_loss: 1.4016 - val_acc: 0.6338\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3916 - acc: 0.6321 - val_loss: 1.3943 - val_acc: 0.6365\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3844 - acc: 0.6352 - val_loss: 1.3872 - val_acc: 0.6396\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.3773 - acc: 0.6387 - val_loss: 1.3801 - val_acc: 0.6428\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3703 - acc: 0.6414 - val_loss: 1.3731 - val_acc: 0.6456\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3633 - acc: 0.6442 - val_loss: 1.3661 - val_acc: 0.6490\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3563 - acc: 0.6479 - val_loss: 1.3591 - val_acc: 0.6517\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3493 - acc: 0.6512 - val_loss: 1.3523 - val_acc: 0.6548\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3425 - acc: 0.6540 - val_loss: 1.3454 - val_acc: 0.6573\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.3356 - acc: 0.6569 - val_loss: 1.3386 - val_acc: 0.6606\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.3288 - acc: 0.6597 - val_loss: 1.3317 - val_acc: 0.6635\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3220 - acc: 0.6620 - val_loss: 1.3250 - val_acc: 0.6658\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.3152 - acc: 0.6645 - val_loss: 1.3182 - val_acc: 0.6686\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.3084 - acc: 0.6675 - val_loss: 1.3115 - val_acc: 0.6711\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.3017 - acc: 0.6697 - val_loss: 1.3049 - val_acc: 0.6731\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.2950 - acc: 0.6718 - val_loss: 1.2982 - val_acc: 0.6753\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.2883 - acc: 0.6747 - val_loss: 1.2915 - val_acc: 0.6777\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.2817 - acc: 0.6771 - val_loss: 1.2849 - val_acc: 0.6802\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.2750 - acc: 0.6795 - val_loss: 1.2783 - val_acc: 0.6824\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.2684 - acc: 0.6815 - val_loss: 1.2719 - val_acc: 0.6848\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.2618 - acc: 0.6834 - val_loss: 1.2652 - val_acc: 0.6870\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.2553 - acc: 0.6863 - val_loss: 1.2587 - val_acc: 0.6890\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.2487 - acc: 0.6883 - val_loss: 1.2524 - val_acc: 0.6903\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.2422 - acc: 0.6906 - val_loss: 1.2458 - val_acc: 0.6936\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.2357 - acc: 0.6927 - val_loss: 1.2395 - val_acc: 0.6943\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.2294 - acc: 0.6940 - val_loss: 1.2330 - val_acc: 0.6960\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.2229 - acc: 0.6962 - val_loss: 1.2271 - val_acc: 0.6983\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.2165 - acc: 0.6983 - val_loss: 1.2206 - val_acc: 0.6998\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.2101 - acc: 0.7002 - val_loss: 1.2143 - val_acc: 0.7014\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.2037 - acc: 0.7018 - val_loss: 1.2080 - val_acc: 0.7031\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1974 - acc: 0.7035 - val_loss: 1.2017 - val_acc: 0.7047\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.1911 - acc: 0.7051 - val_loss: 1.1954 - val_acc: 0.7060\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.1848 - acc: 0.7067 - val_loss: 1.1893 - val_acc: 0.7073\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1786 - acc: 0.7080 - val_loss: 1.1832 - val_acc: 0.7085\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1723 - acc: 0.7099 - val_loss: 1.1770 - val_acc: 0.7099\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1661 - acc: 0.7114 - val_loss: 1.1710 - val_acc: 0.7112\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1599 - acc: 0.7126 - val_loss: 1.1649 - val_acc: 0.7125\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1538 - acc: 0.7138 - val_loss: 1.1589 - val_acc: 0.7140\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1477 - acc: 0.7150 - val_loss: 1.1530 - val_acc: 0.7151\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1417 - acc: 0.7164 - val_loss: 1.1471 - val_acc: 0.7166\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.1357 - acc: 0.7178 - val_loss: 1.1413 - val_acc: 0.7177\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.1297 - acc: 0.7192 - val_loss: 1.1353 - val_acc: 0.7190\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1237 - acc: 0.7203 - val_loss: 1.1296 - val_acc: 0.7197\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.1177 - acc: 0.7217 - val_loss: 1.1238 - val_acc: 0.7211\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1119 - acc: 0.7237 - val_loss: 1.1180 - val_acc: 0.7230\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1061 - acc: 0.7249 - val_loss: 1.1124 - val_acc: 0.7241\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1002 - acc: 0.7262 - val_loss: 1.1068 - val_acc: 0.7253\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0945 - acc: 0.7281 - val_loss: 1.1010 - val_acc: 0.7269\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.0887 - acc: 0.7296 - val_loss: 1.0956 - val_acc: 0.7283\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0830 - acc: 0.7305 - val_loss: 1.0900 - val_acc: 0.7293\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.0773 - acc: 0.7320 - val_loss: 1.0845 - val_acc: 0.7309\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.0717 - acc: 0.7335 - val_loss: 1.0793 - val_acc: 0.7328\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.0661 - acc: 0.7349 - val_loss: 1.0736 - val_acc: 0.7331\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.0606 - acc: 0.7361 - val_loss: 1.0684 - val_acc: 0.7341\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.0551 - acc: 0.7370 - val_loss: 1.0629 - val_acc: 0.7360\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.0496 - acc: 0.7386 - val_loss: 1.0577 - val_acc: 0.7373\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.0442 - acc: 0.7401 - val_loss: 1.0525 - val_acc: 0.7387\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.0388 - acc: 0.7415 - val_loss: 1.0472 - val_acc: 0.7401\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.0335 - acc: 0.7425 - val_loss: 1.0421 - val_acc: 0.7414\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.0282 - acc: 0.7439 - val_loss: 1.0372 - val_acc: 0.7419\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0231 - acc: 0.7450 - val_loss: 1.0320 - val_acc: 0.7435\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.0177 - acc: 0.7463 - val_loss: 1.0269 - val_acc: 0.7449\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.0126 - acc: 0.7476 - val_loss: 1.0219 - val_acc: 0.7464\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.0074 - acc: 0.7491 - val_loss: 1.0171 - val_acc: 0.7470\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.0024 - acc: 0.7501 - val_loss: 1.0121 - val_acc: 0.7482\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9973 - acc: 0.7514 - val_loss: 1.0073 - val_acc: 0.7494\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9923 - acc: 0.7524 - val_loss: 1.0025 - val_acc: 0.7503\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9874 - acc: 0.7538 - val_loss: 0.9977 - val_acc: 0.7511\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9825 - acc: 0.7548 - val_loss: 0.9931 - val_acc: 0.7521\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9776 - acc: 0.7560 - val_loss: 0.9883 - val_acc: 0.7535\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9728 - acc: 0.7571 - val_loss: 0.9837 - val_acc: 0.7543\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9680 - acc: 0.7582 - val_loss: 0.9791 - val_acc: 0.7559\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9633 - acc: 0.7591 - val_loss: 0.9747 - val_acc: 0.7566\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9586 - acc: 0.7602 - val_loss: 0.9702 - val_acc: 0.7580\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9540 - acc: 0.7618 - val_loss: 0.9656 - val_acc: 0.7588\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9494 - acc: 0.7629 - val_loss: 0.9615 - val_acc: 0.7592\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9448 - acc: 0.7640 - val_loss: 0.9568 - val_acc: 0.7606\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9402 - acc: 0.7653 - val_loss: 0.9524 - val_acc: 0.7619\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9357 - acc: 0.7664 - val_loss: 0.9483 - val_acc: 0.7635\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9313 - acc: 0.7677 - val_loss: 0.9441 - val_acc: 0.7646\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9268 - acc: 0.7688 - val_loss: 0.9396 - val_acc: 0.7651\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9225 - acc: 0.7696 - val_loss: 0.9354 - val_acc: 0.7657\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9181 - acc: 0.7708 - val_loss: 0.9312 - val_acc: 0.7667\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9138 - acc: 0.7719 - val_loss: 0.9271 - val_acc: 0.7683\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9095 - acc: 0.7731 - val_loss: 0.9231 - val_acc: 0.7693\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.9052 - acc: 0.7743 - val_loss: 0.9190 - val_acc: 0.7703\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9011 - acc: 0.7755 - val_loss: 0.9150 - val_acc: 0.7713\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8969 - acc: 0.7764 - val_loss: 0.9109 - val_acc: 0.7721\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8928 - acc: 0.7775 - val_loss: 0.9070 - val_acc: 0.7731\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8887 - acc: 0.7787 - val_loss: 0.9031 - val_acc: 0.7737\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8846 - acc: 0.7798 - val_loss: 0.8992 - val_acc: 0.7746\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8806 - acc: 0.7809 - val_loss: 0.8953 - val_acc: 0.7754\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8766 - acc: 0.7817 - val_loss: 0.8916 - val_acc: 0.7768\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8727 - acc: 0.7826 - val_loss: 0.8878 - val_acc: 0.7775\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8688 - acc: 0.7840 - val_loss: 0.8839 - val_acc: 0.7785\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8649 - acc: 0.7850 - val_loss: 0.8803 - val_acc: 0.7789\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8610 - acc: 0.7858 - val_loss: 0.8766 - val_acc: 0.7798\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8572 - acc: 0.7868 - val_loss: 0.8729 - val_acc: 0.7807\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8534 - acc: 0.7880 - val_loss: 0.8693 - val_acc: 0.7817\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8497 - acc: 0.7889 - val_loss: 0.8657 - val_acc: 0.7823\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8460 - acc: 0.7896 - val_loss: 0.8621 - val_acc: 0.7831\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8423 - acc: 0.7907 - val_loss: 0.8586 - val_acc: 0.7840\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8387 - acc: 0.7917 - val_loss: 0.8551 - val_acc: 0.7848\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.8350 - acc: 0.7929 - val_loss: 0.8517 - val_acc: 0.7855\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8314 - acc: 0.7939 - val_loss: 0.8481 - val_acc: 0.7867\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8278 - acc: 0.7946 - val_loss: 0.8447 - val_acc: 0.7877\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8243 - acc: 0.7954 - val_loss: 0.8413 - val_acc: 0.7886\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8209 - acc: 0.7962 - val_loss: 0.8379 - val_acc: 0.7893\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8173 - acc: 0.7967 - val_loss: 0.8347 - val_acc: 0.7901\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8139 - acc: 0.7978 - val_loss: 0.8313 - val_acc: 0.7905\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8105 - acc: 0.7988 - val_loss: 0.8282 - val_acc: 0.7911\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.8071 - acc: 0.7997 - val_loss: 0.8247 - val_acc: 0.7921\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8037 - acc: 0.8003 - val_loss: 0.8215 - val_acc: 0.7929\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8004 - acc: 0.8011 - val_loss: 0.8183 - val_acc: 0.7934\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7971 - acc: 0.8018 - val_loss: 0.8152 - val_acc: 0.7941\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7938 - acc: 0.8025 - val_loss: 0.8120 - val_acc: 0.7956\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7906 - acc: 0.8035 - val_loss: 0.8089 - val_acc: 0.7965\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7873 - acc: 0.8047 - val_loss: 0.8057 - val_acc: 0.7973\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7841 - acc: 0.8053 - val_loss: 0.8027 - val_acc: 0.7977\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7810 - acc: 0.8065 - val_loss: 0.7996 - val_acc: 0.7984\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7778 - acc: 0.8075 - val_loss: 0.7966 - val_acc: 0.7991\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7748 - acc: 0.8078 - val_loss: 0.7936 - val_acc: 0.8003\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7717 - acc: 0.8083 - val_loss: 0.7906 - val_acc: 0.8014\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7686 - acc: 0.8096 - val_loss: 0.7877 - val_acc: 0.8018\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7655 - acc: 0.8106 - val_loss: 0.7847 - val_acc: 0.8025\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7625 - acc: 0.8112 - val_loss: 0.7818 - val_acc: 0.8034\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7595 - acc: 0.8120 - val_loss: 0.7789 - val_acc: 0.8041\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7565 - acc: 0.8128 - val_loss: 0.7760 - val_acc: 0.8048\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7535 - acc: 0.8134 - val_loss: 0.7732 - val_acc: 0.8056\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7506 - acc: 0.8141 - val_loss: 0.7703 - val_acc: 0.8063\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7477 - acc: 0.8151 - val_loss: 0.7676 - val_acc: 0.8074\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7449 - acc: 0.8159 - val_loss: 0.7648 - val_acc: 0.8079\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7420 - acc: 0.8165 - val_loss: 0.7621 - val_acc: 0.8089\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7392 - acc: 0.8173 - val_loss: 0.7594 - val_acc: 0.8094\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7364 - acc: 0.8180 - val_loss: 0.7566 - val_acc: 0.8103\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7336 - acc: 0.8188 - val_loss: 0.7539 - val_acc: 0.8107\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.7309 - acc: 0.8198 - val_loss: 0.7512 - val_acc: 0.8115\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7281 - acc: 0.8201 - val_loss: 0.7486 - val_acc: 0.8123\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7254 - acc: 0.8210 - val_loss: 0.7460 - val_acc: 0.8127\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7227 - acc: 0.8220 - val_loss: 0.7434 - val_acc: 0.8135\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7200 - acc: 0.8227 - val_loss: 0.7407 - val_acc: 0.8144\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7174 - acc: 0.8232 - val_loss: 0.7382 - val_acc: 0.8151\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7148 - acc: 0.8242 - val_loss: 0.7357 - val_acc: 0.8158\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7122 - acc: 0.8250 - val_loss: 0.7332 - val_acc: 0.8162\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7096 - acc: 0.8255 - val_loss: 0.7307 - val_acc: 0.8169\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7070 - acc: 0.8264 - val_loss: 0.7282 - val_acc: 0.8176\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.7045 - acc: 0.8272 - val_loss: 0.7257 - val_acc: 0.8181\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7019 - acc: 0.8279 - val_loss: 0.7233 - val_acc: 0.8187\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6994 - acc: 0.8284 - val_loss: 0.7208 - val_acc: 0.8195\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6969 - acc: 0.8290 - val_loss: 0.7185 - val_acc: 0.8200\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6945 - acc: 0.8298 - val_loss: 0.7161 - val_acc: 0.8206\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6920 - acc: 0.8302 - val_loss: 0.7136 - val_acc: 0.8213\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.6896 - acc: 0.8308 - val_loss: 0.7113 - val_acc: 0.8219\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6871 - acc: 0.8316 - val_loss: 0.7090 - val_acc: 0.8223\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6848 - acc: 0.8321 - val_loss: 0.7067 - val_acc: 0.8228\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6824 - acc: 0.8325 - val_loss: 0.7044 - val_acc: 0.8235\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6800 - acc: 0.8331 - val_loss: 0.7021 - val_acc: 0.8239\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6777 - acc: 0.8337 - val_loss: 0.6998 - val_acc: 0.8244\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6754 - acc: 0.8343 - val_loss: 0.6976 - val_acc: 0.8247\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6731 - acc: 0.8348 - val_loss: 0.6953 - val_acc: 0.8254\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6708 - acc: 0.8353 - val_loss: 0.6931 - val_acc: 0.8258\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6685 - acc: 0.8359 - val_loss: 0.6909 - val_acc: 0.8263\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6663 - acc: 0.8366 - val_loss: 0.6887 - val_acc: 0.8268\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6641 - acc: 0.8371 - val_loss: 0.6866 - val_acc: 0.8272\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6619 - acc: 0.8376 - val_loss: 0.6845 - val_acc: 0.8277\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6596 - acc: 0.8379 - val_loss: 0.6824 - val_acc: 0.8282\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6574 - acc: 0.8384 - val_loss: 0.6802 - val_acc: 0.8289\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6553 - acc: 0.8389 - val_loss: 0.6782 - val_acc: 0.8294\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6532 - acc: 0.8392 - val_loss: 0.6761 - val_acc: 0.8296\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6510 - acc: 0.8396 - val_loss: 0.6740 - val_acc: 0.8301\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6489 - acc: 0.8400 - val_loss: 0.6720 - val_acc: 0.8305\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6468 - acc: 0.8403 - val_loss: 0.6699 - val_acc: 0.8312\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6447 - acc: 0.8407 - val_loss: 0.6679 - val_acc: 0.8317\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6426 - acc: 0.8411 - val_loss: 0.6659 - val_acc: 0.8321\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6406 - acc: 0.8419 - val_loss: 0.6640 - val_acc: 0.8325\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6386 - acc: 0.8422 - val_loss: 0.6619 - val_acc: 0.8331\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6366 - acc: 0.8427 - val_loss: 0.6600 - val_acc: 0.8333\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.6345 - acc: 0.8433 - val_loss: 0.6580 - val_acc: 0.8337\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6325 - acc: 0.8435 - val_loss: 0.6561 - val_acc: 0.8341\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6306 - acc: 0.8440 - val_loss: 0.6543 - val_acc: 0.8345\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6286 - acc: 0.8445 - val_loss: 0.6523 - val_acc: 0.8351\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.6267 - acc: 0.8449 - val_loss: 0.6505 - val_acc: 0.8354\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6247 - acc: 0.8453 - val_loss: 0.6485 - val_acc: 0.8360\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6228 - acc: 0.8457 - val_loss: 0.6467 - val_acc: 0.8361\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6209 - acc: 0.8462 - val_loss: 0.6448 - val_acc: 0.8366\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6190 - acc: 0.8466 - val_loss: 0.6430 - val_acc: 0.8369\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6171 - acc: 0.8469 - val_loss: 0.6412 - val_acc: 0.8377\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6152 - acc: 0.8473 - val_loss: 0.6394 - val_acc: 0.8380\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6134 - acc: 0.8478 - val_loss: 0.6375 - val_acc: 0.8385\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6116 - acc: 0.8480 - val_loss: 0.6358 - val_acc: 0.8389\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6097 - acc: 0.8485 - val_loss: 0.6340 - val_acc: 0.8394\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6079 - acc: 0.8491 - val_loss: 0.6322 - val_acc: 0.8397\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6062 - acc: 0.8495 - val_loss: 0.6305 - val_acc: 0.8402\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6043 - acc: 0.8499 - val_loss: 0.6288 - val_acc: 0.8404\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6026 - acc: 0.8501 - val_loss: 0.6270 - val_acc: 0.8406\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6008 - acc: 0.8503 - val_loss: 0.6254 - val_acc: 0.8408\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5991 - acc: 0.8506 - val_loss: 0.6237 - val_acc: 0.8415\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.5973 - acc: 0.8511 - val_loss: 0.6220 - val_acc: 0.8418\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5956 - acc: 0.8514 - val_loss: 0.6203 - val_acc: 0.8422\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5939 - acc: 0.8518 - val_loss: 0.6186 - val_acc: 0.8425\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5922 - acc: 0.8523 - val_loss: 0.6170 - val_acc: 0.8427\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5905 - acc: 0.8525 - val_loss: 0.6154 - val_acc: 0.8431\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5888 - acc: 0.8530 - val_loss: 0.6137 - val_acc: 0.8436\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5872 - acc: 0.8533 - val_loss: 0.6122 - val_acc: 0.8438\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5855 - acc: 0.8536 - val_loss: 0.6106 - val_acc: 0.8441\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5838 - acc: 0.8539 - val_loss: 0.6090 - val_acc: 0.8444\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5822 - acc: 0.8543 - val_loss: 0.6074 - val_acc: 0.8447\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5806 - acc: 0.8545 - val_loss: 0.6058 - val_acc: 0.8452\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5790 - acc: 0.8548 - val_loss: 0.6043 - val_acc: 0.8452\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5774 - acc: 0.8551 - val_loss: 0.6027 - val_acc: 0.8454\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5758 - acc: 0.8556 - val_loss: 0.6012 - val_acc: 0.8458\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5742 - acc: 0.8558 - val_loss: 0.5997 - val_acc: 0.8458\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5726 - acc: 0.8561 - val_loss: 0.5981 - val_acc: 0.8463\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5711 - acc: 0.8565 - val_loss: 0.5966 - val_acc: 0.8465\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5695 - acc: 0.8567 - val_loss: 0.5951 - val_acc: 0.8468\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5680 - acc: 0.8569 - val_loss: 0.5936 - val_acc: 0.8470\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5664 - acc: 0.8576 - val_loss: 0.5922 - val_acc: 0.8473\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.5650 - acc: 0.8577 - val_loss: 0.5908 - val_acc: 0.8476\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5635 - acc: 0.8579 - val_loss: 0.5892 - val_acc: 0.8478\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5620 - acc: 0.8581 - val_loss: 0.5878 - val_acc: 0.8481\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5604 - acc: 0.8584 - val_loss: 0.5863 - val_acc: 0.8485\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5590 - acc: 0.8588 - val_loss: 0.5850 - val_acc: 0.8486\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5575 - acc: 0.8591 - val_loss: 0.5835 - val_acc: 0.8489\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5560 - acc: 0.8593 - val_loss: 0.5821 - val_acc: 0.8492\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5546 - acc: 0.8595 - val_loss: 0.5807 - val_acc: 0.8494\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5531 - acc: 0.8599 - val_loss: 0.5793 - val_acc: 0.8494\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5517 - acc: 0.8603 - val_loss: 0.5779 - val_acc: 0.8497\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5503 - acc: 0.8606 - val_loss: 0.5766 - val_acc: 0.8500\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.5489 - acc: 0.8608 - val_loss: 0.5752 - val_acc: 0.8503\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5475 - acc: 0.8611 - val_loss: 0.5739 - val_acc: 0.8505\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5461 - acc: 0.8612 - val_loss: 0.5725 - val_acc: 0.8508\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5447 - acc: 0.8615 - val_loss: 0.5712 - val_acc: 0.8510\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5433 - acc: 0.8617 - val_loss: 0.5699 - val_acc: 0.8512\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5419 - acc: 0.8621 - val_loss: 0.5686 - val_acc: 0.8513\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5406 - acc: 0.8624 - val_loss: 0.5672 - val_acc: 0.8514\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5392 - acc: 0.8628 - val_loss: 0.5660 - val_acc: 0.8516\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5379 - acc: 0.8630 - val_loss: 0.5647 - val_acc: 0.8518\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5366 - acc: 0.8634 - val_loss: 0.5634 - val_acc: 0.8521\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.5352 - acc: 0.8637 - val_loss: 0.5621 - val_acc: 0.8525\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5339 - acc: 0.8639 - val_loss: 0.5608 - val_acc: 0.8527\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5326 - acc: 0.8642 - val_loss: 0.5595 - val_acc: 0.8528\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5313 - acc: 0.8645 - val_loss: 0.5583 - val_acc: 0.8531\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5300 - acc: 0.8648 - val_loss: 0.5571 - val_acc: 0.8531\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5287 - acc: 0.8650 - val_loss: 0.5558 - val_acc: 0.8535\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5274 - acc: 0.8653 - val_loss: 0.5546 - val_acc: 0.8537\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5261 - acc: 0.8655 - val_loss: 0.5534 - val_acc: 0.8540\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5249 - acc: 0.8657 - val_loss: 0.5521 - val_acc: 0.8542\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5236 - acc: 0.8661 - val_loss: 0.5509 - val_acc: 0.8546\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5224 - acc: 0.8662 - val_loss: 0.5497 - val_acc: 0.8549\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5211 - acc: 0.8666 - val_loss: 0.5486 - val_acc: 0.8552\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5199 - acc: 0.8669 - val_loss: 0.5473 - val_acc: 0.8554\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5186 - acc: 0.8672 - val_loss: 0.5462 - val_acc: 0.8557\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5174 - acc: 0.8670 - val_loss: 0.5450 - val_acc: 0.8557\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5162 - acc: 0.8674 - val_loss: 0.5438 - val_acc: 0.8562\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5150 - acc: 0.8678 - val_loss: 0.5427 - val_acc: 0.8566\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5138 - acc: 0.8680 - val_loss: 0.5415 - val_acc: 0.8567\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5126 - acc: 0.8683 - val_loss: 0.5404 - val_acc: 0.8571\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5114 - acc: 0.8686 - val_loss: 0.5392 - val_acc: 0.8572\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5102 - acc: 0.8688 - val_loss: 0.5381 - val_acc: 0.8574\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5091 - acc: 0.8691 - val_loss: 0.5369 - val_acc: 0.8575\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5079 - acc: 0.8694 - val_loss: 0.5359 - val_acc: 0.8577\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5067 - acc: 0.8697 - val_loss: 0.5347 - val_acc: 0.8579\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5056 - acc: 0.8698 - val_loss: 0.5336 - val_acc: 0.8581\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5044 - acc: 0.8700 - val_loss: 0.5325 - val_acc: 0.8584\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5033 - acc: 0.8703 - val_loss: 0.5314 - val_acc: 0.8587\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5021 - acc: 0.8705 - val_loss: 0.5303 - val_acc: 0.8589\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5010 - acc: 0.8708 - val_loss: 0.5293 - val_acc: 0.8592\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4999 - acc: 0.8709 - val_loss: 0.5283 - val_acc: 0.8593\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4988 - acc: 0.8711 - val_loss: 0.5271 - val_acc: 0.8596\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4977 - acc: 0.8713 - val_loss: 0.5262 - val_acc: 0.8596\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4966 - acc: 0.8716 - val_loss: 0.5250 - val_acc: 0.8596\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4954 - acc: 0.8720 - val_loss: 0.5239 - val_acc: 0.8599\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4943 - acc: 0.8719 - val_loss: 0.5229 - val_acc: 0.8602\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4932 - acc: 0.8721 - val_loss: 0.5219 - val_acc: 0.8603\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4922 - acc: 0.8724 - val_loss: 0.5208 - val_acc: 0.8604\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4911 - acc: 0.8726 - val_loss: 0.5198 - val_acc: 0.8607\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4900 - acc: 0.8729 - val_loss: 0.5187 - val_acc: 0.8609\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4889 - acc: 0.8730 - val_loss: 0.5177 - val_acc: 0.8614\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4878 - acc: 0.8734 - val_loss: 0.5167 - val_acc: 0.8614\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4868 - acc: 0.8736 - val_loss: 0.5157 - val_acc: 0.8616\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4857 - acc: 0.8739 - val_loss: 0.5147 - val_acc: 0.8618\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4847 - acc: 0.8743 - val_loss: 0.5138 - val_acc: 0.8620\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4836 - acc: 0.8744 - val_loss: 0.5128 - val_acc: 0.8624\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4826 - acc: 0.8747 - val_loss: 0.5117 - val_acc: 0.8624\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4816 - acc: 0.8748 - val_loss: 0.5107 - val_acc: 0.8628\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4806 - acc: 0.8750 - val_loss: 0.5098 - val_acc: 0.8627\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4795 - acc: 0.8754 - val_loss: 0.5088 - val_acc: 0.8629\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4785 - acc: 0.8756 - val_loss: 0.5078 - val_acc: 0.8630\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4775 - acc: 0.8756 - val_loss: 0.5069 - val_acc: 0.8633\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.4765 - acc: 0.8756 - val_loss: 0.5059 - val_acc: 0.8638\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.4755 - acc: 0.8760 - val_loss: 0.5050 - val_acc: 0.8640\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4745 - acc: 0.8760 - val_loss: 0.5040 - val_acc: 0.8641\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4735 - acc: 0.8763 - val_loss: 0.5031 - val_acc: 0.8644\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4725 - acc: 0.8766 - val_loss: 0.5022 - val_acc: 0.8646\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4715 - acc: 0.8768 - val_loss: 0.5012 - val_acc: 0.8648\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4706 - acc: 0.8770 - val_loss: 0.5002 - val_acc: 0.8650\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4696 - acc: 0.8771 - val_loss: 0.4993 - val_acc: 0.8651\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4686 - acc: 0.8773 - val_loss: 0.4984 - val_acc: 0.8652\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4677 - acc: 0.8773 - val_loss: 0.4975 - val_acc: 0.8654\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4667 - acc: 0.8775 - val_loss: 0.4967 - val_acc: 0.8655\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4657 - acc: 0.8778 - val_loss: 0.4957 - val_acc: 0.8660\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4648 - acc: 0.8782 - val_loss: 0.4949 - val_acc: 0.8660\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4638 - acc: 0.8783 - val_loss: 0.4939 - val_acc: 0.8663\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4629 - acc: 0.8785 - val_loss: 0.4932 - val_acc: 0.8662\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4620 - acc: 0.8785 - val_loss: 0.4921 - val_acc: 0.8668\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4610 - acc: 0.8787 - val_loss: 0.4912 - val_acc: 0.8669\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4601 - acc: 0.8788 - val_loss: 0.4904 - val_acc: 0.8669\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4591 - acc: 0.8792 - val_loss: 0.4895 - val_acc: 0.8673\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4582 - acc: 0.8794 - val_loss: 0.4887 - val_acc: 0.8674\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4573 - acc: 0.8794 - val_loss: 0.4877 - val_acc: 0.8678\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4564 - acc: 0.8797 - val_loss: 0.4869 - val_acc: 0.8677\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4555 - acc: 0.8799 - val_loss: 0.4860 - val_acc: 0.8684\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4546 - acc: 0.8801 - val_loss: 0.4852 - val_acc: 0.8685\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4537 - acc: 0.8801 - val_loss: 0.4843 - val_acc: 0.8687\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4528 - acc: 0.8804 - val_loss: 0.4835 - val_acc: 0.8690\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.4519 - acc: 0.8804 - val_loss: 0.4826 - val_acc: 0.8692\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4510 - acc: 0.8806 - val_loss: 0.4818 - val_acc: 0.8693\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4501 - acc: 0.8808 - val_loss: 0.4810 - val_acc: 0.8695\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4493 - acc: 0.8810 - val_loss: 0.4801 - val_acc: 0.8698\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4484 - acc: 0.8813 - val_loss: 0.4793 - val_acc: 0.8699\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4475 - acc: 0.8815 - val_loss: 0.4785 - val_acc: 0.8700\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4466 - acc: 0.8816 - val_loss: 0.4777 - val_acc: 0.8701\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4457 - acc: 0.8818 - val_loss: 0.4769 - val_acc: 0.8705\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4449 - acc: 0.8818 - val_loss: 0.4760 - val_acc: 0.8707\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4440 - acc: 0.8820 - val_loss: 0.4752 - val_acc: 0.8708\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4432 - acc: 0.8821 - val_loss: 0.4745 - val_acc: 0.8708\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4423 - acc: 0.8822 - val_loss: 0.4737 - val_acc: 0.8709\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4415 - acc: 0.8824 - val_loss: 0.4728 - val_acc: 0.8713\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4406 - acc: 0.8827 - val_loss: 0.4721 - val_acc: 0.8713\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4398 - acc: 0.8829 - val_loss: 0.4712 - val_acc: 0.8716\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4389 - acc: 0.8831 - val_loss: 0.4705 - val_acc: 0.8716\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4381 - acc: 0.8832 - val_loss: 0.4697 - val_acc: 0.8718\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4372 - acc: 0.8834 - val_loss: 0.4690 - val_acc: 0.8719\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4365 - acc: 0.8834 - val_loss: 0.4681 - val_acc: 0.8722\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4356 - acc: 0.8837 - val_loss: 0.4674 - val_acc: 0.8723\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4348 - acc: 0.8840 - val_loss: 0.4666 - val_acc: 0.8724\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4340 - acc: 0.8841 - val_loss: 0.4659 - val_acc: 0.8725\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4332 - acc: 0.8843 - val_loss: 0.4651 - val_acc: 0.8728\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4324 - acc: 0.8846 - val_loss: 0.4643 - val_acc: 0.8730\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4316 - acc: 0.8848 - val_loss: 0.4637 - val_acc: 0.8729\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4308 - acc: 0.8847 - val_loss: 0.4628 - val_acc: 0.8733\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4299 - acc: 0.8850 - val_loss: 0.4621 - val_acc: 0.8733\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4291 - acc: 0.8852 - val_loss: 0.4613 - val_acc: 0.8734\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4283 - acc: 0.8854 - val_loss: 0.4606 - val_acc: 0.8736\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4275 - acc: 0.8856 - val_loss: 0.4598 - val_acc: 0.8737\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4268 - acc: 0.8857 - val_loss: 0.4592 - val_acc: 0.8738\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4260 - acc: 0.8860 - val_loss: 0.4583 - val_acc: 0.8740\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4252 - acc: 0.8860 - val_loss: 0.4576 - val_acc: 0.8742\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4244 - acc: 0.8862 - val_loss: 0.4569 - val_acc: 0.8743\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4236 - acc: 0.8863 - val_loss: 0.4561 - val_acc: 0.8746\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.4228 - acc: 0.8867 - val_loss: 0.4555 - val_acc: 0.8746\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4221 - acc: 0.8867 - val_loss: 0.4547 - val_acc: 0.8748\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4213 - acc: 0.8871 - val_loss: 0.4541 - val_acc: 0.8749\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.4206 - acc: 0.8872 - val_loss: 0.4533 - val_acc: 0.8752\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4198 - acc: 0.8873 - val_loss: 0.4527 - val_acc: 0.8754\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4190 - acc: 0.8877 - val_loss: 0.4519 - val_acc: 0.8756\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4183 - acc: 0.8878 - val_loss: 0.4512 - val_acc: 0.8757\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4175 - acc: 0.8881 - val_loss: 0.4505 - val_acc: 0.8757\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4168 - acc: 0.8881 - val_loss: 0.4498 - val_acc: 0.8758\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4160 - acc: 0.8883 - val_loss: 0.4491 - val_acc: 0.8761\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4153 - acc: 0.8886 - val_loss: 0.4484 - val_acc: 0.8763\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4145 - acc: 0.8888 - val_loss: 0.4477 - val_acc: 0.8764\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4138 - acc: 0.8890 - val_loss: 0.4471 - val_acc: 0.8763\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4130 - acc: 0.8892 - val_loss: 0.4464 - val_acc: 0.8767\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4123 - acc: 0.8892 - val_loss: 0.4457 - val_acc: 0.8769\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4116 - acc: 0.8896 - val_loss: 0.4451 - val_acc: 0.8770\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4109 - acc: 0.8897 - val_loss: 0.4444 - val_acc: 0.8770\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4101 - acc: 0.8897 - val_loss: 0.4437 - val_acc: 0.8774\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4094 - acc: 0.8900 - val_loss: 0.4431 - val_acc: 0.8774\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4087 - acc: 0.8901 - val_loss: 0.4424 - val_acc: 0.8775\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4080 - acc: 0.8901 - val_loss: 0.4417 - val_acc: 0.8778\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4073 - acc: 0.8903 - val_loss: 0.4411 - val_acc: 0.8776\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4065 - acc: 0.8904 - val_loss: 0.4404 - val_acc: 0.8779\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4058 - acc: 0.8905 - val_loss: 0.4397 - val_acc: 0.8779\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4051 - acc: 0.8908 - val_loss: 0.4391 - val_acc: 0.8782\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4044 - acc: 0.8909 - val_loss: 0.4384 - val_acc: 0.8786\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4037 - acc: 0.8910 - val_loss: 0.4378 - val_acc: 0.8785\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4030 - acc: 0.8913 - val_loss: 0.4371 - val_acc: 0.8788\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4023 - acc: 0.8913 - val_loss: 0.4365 - val_acc: 0.8789\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4016 - acc: 0.8914 - val_loss: 0.4358 - val_acc: 0.8790\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4009 - acc: 0.8917 - val_loss: 0.4353 - val_acc: 0.8790\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4003 - acc: 0.8918 - val_loss: 0.4346 - val_acc: 0.8793\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3996 - acc: 0.8920 - val_loss: 0.4340 - val_acc: 0.8793\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3989 - acc: 0.8920 - val_loss: 0.4333 - val_acc: 0.8795\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3982 - acc: 0.8923 - val_loss: 0.4327 - val_acc: 0.8797\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3975 - acc: 0.8925 - val_loss: 0.4322 - val_acc: 0.8800\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3968 - acc: 0.8926 - val_loss: 0.4314 - val_acc: 0.8802\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3962 - acc: 0.8927 - val_loss: 0.4309 - val_acc: 0.8801\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3955 - acc: 0.8929 - val_loss: 0.4303 - val_acc: 0.8803\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3948 - acc: 0.8930 - val_loss: 0.4296 - val_acc: 0.8806\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3941 - acc: 0.8932 - val_loss: 0.4291 - val_acc: 0.8806\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3935 - acc: 0.8932 - val_loss: 0.4284 - val_acc: 0.8807\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3928 - acc: 0.8935 - val_loss: 0.4278 - val_acc: 0.8809\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3922 - acc: 0.8937 - val_loss: 0.4272 - val_acc: 0.8809\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3915 - acc: 0.8939 - val_loss: 0.4266 - val_acc: 0.8811\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3908 - acc: 0.8940 - val_loss: 0.4260 - val_acc: 0.8814\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3902 - acc: 0.8940 - val_loss: 0.4254 - val_acc: 0.8815\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3896 - acc: 0.8942 - val_loss: 0.4248 - val_acc: 0.8815\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3889 - acc: 0.8946 - val_loss: 0.4244 - val_acc: 0.8818\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3883 - acc: 0.8945 - val_loss: 0.4236 - val_acc: 0.8819\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3876 - acc: 0.8947 - val_loss: 0.4231 - val_acc: 0.8820\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.3869 - acc: 0.8950 - val_loss: 0.4224 - val_acc: 0.8822\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.3863 - acc: 0.8952 - val_loss: 0.4219 - val_acc: 0.8824\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3856 - acc: 0.8953 - val_loss: 0.4213 - val_acc: 0.8824\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3850 - acc: 0.8954 - val_loss: 0.4208 - val_acc: 0.8824\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3844 - acc: 0.8955 - val_loss: 0.4201 - val_acc: 0.8827\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3837 - acc: 0.8957 - val_loss: 0.4196 - val_acc: 0.8828\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3831 - acc: 0.8959 - val_loss: 0.4190 - val_acc: 0.8830\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3825 - acc: 0.8961 - val_loss: 0.4184 - val_acc: 0.8830\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3819 - acc: 0.8960 - val_loss: 0.4179 - val_acc: 0.8832\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3812 - acc: 0.8962 - val_loss: 0.4174 - val_acc: 0.8833\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3806 - acc: 0.8963 - val_loss: 0.4167 - val_acc: 0.8834\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3800 - acc: 0.8966 - val_loss: 0.4161 - val_acc: 0.8834\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3794 - acc: 0.8966 - val_loss: 0.4156 - val_acc: 0.8837\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3787 - acc: 0.8968 - val_loss: 0.4150 - val_acc: 0.8837\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3781 - acc: 0.8970 - val_loss: 0.4145 - val_acc: 0.8839\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.3775 - acc: 0.8973 - val_loss: 0.4140 - val_acc: 0.8840\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3769 - acc: 0.8973 - val_loss: 0.4134 - val_acc: 0.8841\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3763 - acc: 0.8975 - val_loss: 0.4129 - val_acc: 0.8842\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3757 - acc: 0.8975 - val_loss: 0.4123 - val_acc: 0.8844\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3751 - acc: 0.8977 - val_loss: 0.4118 - val_acc: 0.8845\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3745 - acc: 0.8977 - val_loss: 0.4112 - val_acc: 0.8846\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.3739 - acc: 0.8979 - val_loss: 0.4107 - val_acc: 0.8848\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3733 - acc: 0.8982 - val_loss: 0.4101 - val_acc: 0.8848\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3727 - acc: 0.8984 - val_loss: 0.4096 - val_acc: 0.8851\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3721 - acc: 0.8984 - val_loss: 0.4090 - val_acc: 0.8852\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3715 - acc: 0.8987 - val_loss: 0.4085 - val_acc: 0.8852\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3709 - acc: 0.8987 - val_loss: 0.4080 - val_acc: 0.8852\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.3704 - acc: 0.8987 - val_loss: 0.4075 - val_acc: 0.8854\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3697 - acc: 0.8990 - val_loss: 0.4070 - val_acc: 0.8856\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3692 - acc: 0.8991 - val_loss: 0.4065 - val_acc: 0.8856\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3686 - acc: 0.8992 - val_loss: 0.4059 - val_acc: 0.8856\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.3680 - acc: 0.8995 - val_loss: 0.4054 - val_acc: 0.8859\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3674 - acc: 0.8994 - val_loss: 0.4048 - val_acc: 0.8860\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3668 - acc: 0.8996 - val_loss: 0.4044 - val_acc: 0.8861\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3662 - acc: 0.8996 - val_loss: 0.4038 - val_acc: 0.8862\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3656 - acc: 0.8998 - val_loss: 0.4034 - val_acc: 0.8861\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3651 - acc: 0.8999 - val_loss: 0.4028 - val_acc: 0.8863\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3645 - acc: 0.9001 - val_loss: 0.4024 - val_acc: 0.8864\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.3639 - acc: 0.9003 - val_loss: 0.4017 - val_acc: 0.8867\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3634 - acc: 0.9004 - val_loss: 0.4013 - val_acc: 0.8867\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3628 - acc: 0.9003 - val_loss: 0.4008 - val_acc: 0.8868\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3623 - acc: 0.9006 - val_loss: 0.4004 - val_acc: 0.8869\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3617 - acc: 0.9004 - val_loss: 0.3997 - val_acc: 0.8871\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3611 - acc: 0.9008 - val_loss: 0.3993 - val_acc: 0.8871\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from models import baselineLSTM\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "checkpoint_path = os.path.join(weights_folder, \"baseline\", \"checkpoint.hdf5\")\n",
        "history_path = os.path.join(weights_folder, \"baseline\", \"history.npy\")\n",
        "\n",
        "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
        "hist_callback = MyHistory(history_path)\n",
        "\n",
        "model = baselineLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "model.compile(**compile_args, optimizer=optimizer)\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "history = model.fit(x=x_train_pad,\n",
        "                    y=y_train_pad,\n",
        "                    batch_size=256,\n",
        "                    epochs=500,\n",
        "                    validation_data=(x_val_pad,\n",
        "                                     y_val_pad),\n",
        "                    callbacks=[checkpoint_callback, hist_callback])\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUPAV9S4gIpN"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZF_3KM3qgIpO",
        "outputId": "7248babd-ffc6-4c84-a47e-f0f7734228b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 3s 79ms/step - loss: 3.8208 - acc: 0.0232 - val_loss: 3.8008 - val_acc: 0.0273\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.7905 - acc: 0.0309 - val_loss: 3.7715 - val_acc: 0.0349\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 3.7605 - acc: 0.0380 - val_loss: 3.7423 - val_acc: 0.0414\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.7306 - acc: 0.0468 - val_loss: 3.7130 - val_acc: 0.0511\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.7004 - acc: 0.0542 - val_loss: 3.6833 - val_acc: 0.0563\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.6697 - acc: 0.2195 - val_loss: 3.6529 - val_acc: 0.3953\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.6380 - acc: 0.4190 - val_loss: 3.6214 - val_acc: 0.4425\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3.6051 - acc: 0.4576 - val_loss: 3.5884 - val_acc: 0.4697\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 3.5705 - acc: 0.4807 - val_loss: 3.5536 - val_acc: 0.4908\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.5337 - acc: 0.4999 - val_loss: 3.5163 - val_acc: 0.5093\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.4941 - acc: 0.5169 - val_loss: 3.4762 - val_acc: 0.5254\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.4512 - acc: 0.5303 - val_loss: 3.4323 - val_acc: 0.5386\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.4040 - acc: 0.5428 - val_loss: 3.3838 - val_acc: 0.5482\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.3513 - acc: 0.5517 - val_loss: 3.3293 - val_acc: 0.5552\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 3.2917 - acc: 0.5584 - val_loss: 3.2670 - val_acc: 0.5603\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.2228 - acc: 0.5627 - val_loss: 3.1943 - val_acc: 0.5634\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.1418 - acc: 0.5637 - val_loss: 3.1072 - val_acc: 0.5619\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.0431 - acc: 0.5622 - val_loss: 2.9991 - val_acc: 0.5580\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.9192 - acc: 0.5580 - val_loss: 2.8589 - val_acc: 0.5526\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.7569 - acc: 0.5518 - val_loss: 2.6722 - val_acc: 0.5441\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.5435 - acc: 0.5441 - val_loss: 2.4428 - val_acc: 0.5343\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.3174 - acc: 0.5363 - val_loss: 2.2407 - val_acc: 0.5266\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.1514 - acc: 0.5319 - val_loss: 2.1201 - val_acc: 0.5227\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 2.0556 - acc: 0.5298 - val_loss: 2.0502 - val_acc: 0.5209\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.9973 - acc: 0.5290 - val_loss: 2.0044 - val_acc: 0.5201\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.9576 - acc: 0.5290 - val_loss: 1.9703 - val_acc: 0.5203\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.9267 - acc: 0.5295 - val_loss: 1.9425 - val_acc: 0.5207\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.9009 - acc: 0.5300 - val_loss: 1.9184 - val_acc: 0.5212\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.8784 - acc: 0.5308 - val_loss: 1.8969 - val_acc: 0.5223\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.8583 - acc: 0.5317 - val_loss: 1.8774 - val_acc: 0.5237\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.8399 - acc: 0.5328 - val_loss: 1.8594 - val_acc: 0.5248\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.8229 - acc: 0.5336 - val_loss: 1.8426 - val_acc: 0.5257\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.8070 - acc: 0.5347 - val_loss: 1.8268 - val_acc: 0.5272\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7921 - acc: 0.5361 - val_loss: 1.8120 - val_acc: 0.5287\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7781 - acc: 0.5376 - val_loss: 1.7980 - val_acc: 0.5307\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7649 - acc: 0.5393 - val_loss: 1.7847 - val_acc: 0.5330\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.7524 - acc: 0.5411 - val_loss: 1.7722 - val_acc: 0.5358\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.7407 - acc: 0.5428 - val_loss: 1.7604 - val_acc: 0.5384\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.7296 - acc: 0.5446 - val_loss: 1.7493 - val_acc: 0.5414\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7191 - acc: 0.5470 - val_loss: 1.7387 - val_acc: 0.5439\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.7092 - acc: 0.5490 - val_loss: 1.7286 - val_acc: 0.5466\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.6997 - acc: 0.5511 - val_loss: 1.7191 - val_acc: 0.5498\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.6907 - acc: 0.5539 - val_loss: 1.7100 - val_acc: 0.5526\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.6822 - acc: 0.5566 - val_loss: 1.7013 - val_acc: 0.5553\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.6740 - acc: 0.5590 - val_loss: 1.6929 - val_acc: 0.5577\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6661 - acc: 0.5618 - val_loss: 1.6849 - val_acc: 0.5610\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.6585 - acc: 0.5647 - val_loss: 1.6771 - val_acc: 0.5631\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.6512 - acc: 0.5670 - val_loss: 1.6697 - val_acc: 0.5653\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6442 - acc: 0.5691 - val_loss: 1.6626 - val_acc: 0.5675\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6373 - acc: 0.5712 - val_loss: 1.6556 - val_acc: 0.5700\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.6307 - acc: 0.5735 - val_loss: 1.6488 - val_acc: 0.5723\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.6242 - acc: 0.5754 - val_loss: 1.6422 - val_acc: 0.5748\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.6179 - acc: 0.5772 - val_loss: 1.6358 - val_acc: 0.5769\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.6117 - acc: 0.5792 - val_loss: 1.6295 - val_acc: 0.5786\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.6056 - acc: 0.5808 - val_loss: 1.6233 - val_acc: 0.5808\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.5997 - acc: 0.5827 - val_loss: 1.6173 - val_acc: 0.5826\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5938 - acc: 0.5845 - val_loss: 1.6113 - val_acc: 0.5841\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.5881 - acc: 0.5859 - val_loss: 1.6055 - val_acc: 0.5851\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5824 - acc: 0.5873 - val_loss: 1.5997 - val_acc: 0.5869\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5767 - acc: 0.5890 - val_loss: 1.5940 - val_acc: 0.5889\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5711 - acc: 0.5905 - val_loss: 1.5883 - val_acc: 0.5902\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.5656 - acc: 0.5917 - val_loss: 1.5827 - val_acc: 0.5917\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5601 - acc: 0.5934 - val_loss: 1.5771 - val_acc: 0.5929\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5546 - acc: 0.5951 - val_loss: 1.5716 - val_acc: 0.5943\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.5492 - acc: 0.5967 - val_loss: 1.5661 - val_acc: 0.5957\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5438 - acc: 0.5981 - val_loss: 1.5605 - val_acc: 0.5973\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.5383 - acc: 0.5996 - val_loss: 1.5551 - val_acc: 0.5985\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5329 - acc: 0.6008 - val_loss: 1.5496 - val_acc: 0.5996\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.5275 - acc: 0.6022 - val_loss: 1.5441 - val_acc: 0.6010\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5220 - acc: 0.6035 - val_loss: 1.5387 - val_acc: 0.6024\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5166 - acc: 0.6050 - val_loss: 1.5332 - val_acc: 0.6035\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.5112 - acc: 0.6062 - val_loss: 1.5277 - val_acc: 0.6053\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.5058 - acc: 0.6073 - val_loss: 1.5222 - val_acc: 0.6067\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.5003 - acc: 0.6087 - val_loss: 1.5167 - val_acc: 0.6081\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4948 - acc: 0.6099 - val_loss: 1.5113 - val_acc: 0.6094\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.4893 - acc: 0.6110 - val_loss: 1.5057 - val_acc: 0.6108\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.4838 - acc: 0.6122 - val_loss: 1.5002 - val_acc: 0.6124\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4783 - acc: 0.6138 - val_loss: 1.4947 - val_acc: 0.6137\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4728 - acc: 0.6153 - val_loss: 1.4891 - val_acc: 0.6155\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.4672 - acc: 0.6169 - val_loss: 1.4835 - val_acc: 0.6172\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.4616 - acc: 0.6186 - val_loss: 1.4779 - val_acc: 0.6186\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4560 - acc: 0.6203 - val_loss: 1.4723 - val_acc: 0.6203\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4503 - acc: 0.6227 - val_loss: 1.4667 - val_acc: 0.6227\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4447 - acc: 0.6251 - val_loss: 1.4610 - val_acc: 0.6255\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4390 - acc: 0.6278 - val_loss: 1.4553 - val_acc: 0.6282\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4333 - acc: 0.6314 - val_loss: 1.4496 - val_acc: 0.6328\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.4276 - acc: 0.6348 - val_loss: 1.4439 - val_acc: 0.6353\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.4218 - acc: 0.6373 - val_loss: 1.4382 - val_acc: 0.6380\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4161 - acc: 0.6402 - val_loss: 1.4324 - val_acc: 0.6409\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.4103 - acc: 0.6427 - val_loss: 1.4266 - val_acc: 0.6436\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4044 - acc: 0.6453 - val_loss: 1.4208 - val_acc: 0.6462\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.3986 - acc: 0.6475 - val_loss: 1.4150 - val_acc: 0.6485\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.3927 - acc: 0.6495 - val_loss: 1.4091 - val_acc: 0.6504\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3868 - acc: 0.6516 - val_loss: 1.4032 - val_acc: 0.6523\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.3809 - acc: 0.6540 - val_loss: 1.3973 - val_acc: 0.6544\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3750 - acc: 0.6563 - val_loss: 1.3914 - val_acc: 0.6564\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.3690 - acc: 0.6582 - val_loss: 1.3854 - val_acc: 0.6584\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.3630 - acc: 0.6600 - val_loss: 1.3794 - val_acc: 0.6601\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.3570 - acc: 0.6616 - val_loss: 1.3734 - val_acc: 0.6618\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.3510 - acc: 0.6632 - val_loss: 1.3674 - val_acc: 0.6635\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3449 - acc: 0.6644 - val_loss: 1.3614 - val_acc: 0.6649\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.3389 - acc: 0.6657 - val_loss: 1.3554 - val_acc: 0.6662\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3328 - acc: 0.6671 - val_loss: 1.3493 - val_acc: 0.6679\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3268 - acc: 0.6684 - val_loss: 1.3433 - val_acc: 0.6693\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.3207 - acc: 0.6698 - val_loss: 1.3373 - val_acc: 0.6705\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.3147 - acc: 0.6708 - val_loss: 1.3313 - val_acc: 0.6718\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.3087 - acc: 0.6722 - val_loss: 1.3253 - val_acc: 0.6732\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.3027 - acc: 0.6733 - val_loss: 1.3193 - val_acc: 0.6740\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.2967 - acc: 0.6745 - val_loss: 1.3134 - val_acc: 0.6749\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2907 - acc: 0.6758 - val_loss: 1.3074 - val_acc: 0.6762\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.2847 - acc: 0.6770 - val_loss: 1.3016 - val_acc: 0.6773\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2788 - acc: 0.6779 - val_loss: 1.2957 - val_acc: 0.6783\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.2730 - acc: 0.6789 - val_loss: 1.2899 - val_acc: 0.6794\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2671 - acc: 0.6801 - val_loss: 1.2841 - val_acc: 0.6803\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2613 - acc: 0.6812 - val_loss: 1.2783 - val_acc: 0.6813\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2555 - acc: 0.6828 - val_loss: 1.2725 - val_acc: 0.6833\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.2497 - acc: 0.6844 - val_loss: 1.2668 - val_acc: 0.6840\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.2440 - acc: 0.6853 - val_loss: 1.2612 - val_acc: 0.6846\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2382 - acc: 0.6859 - val_loss: 1.2555 - val_acc: 0.6855\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.2325 - acc: 0.6868 - val_loss: 1.2499 - val_acc: 0.6859\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.2269 - acc: 0.6876 - val_loss: 1.2443 - val_acc: 0.6867\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.2212 - acc: 0.6885 - val_loss: 1.2388 - val_acc: 0.6876\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2157 - acc: 0.6895 - val_loss: 1.2332 - val_acc: 0.6883\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2101 - acc: 0.6904 - val_loss: 1.2277 - val_acc: 0.6889\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2046 - acc: 0.6914 - val_loss: 1.2223 - val_acc: 0.6897\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.1991 - acc: 0.6922 - val_loss: 1.2168 - val_acc: 0.6903\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1936 - acc: 0.6930 - val_loss: 1.2115 - val_acc: 0.6910\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.1881 - acc: 0.6937 - val_loss: 1.2061 - val_acc: 0.6916\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1827 - acc: 0.6947 - val_loss: 1.2008 - val_acc: 0.6927\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1773 - acc: 0.6955 - val_loss: 1.1955 - val_acc: 0.6936\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1720 - acc: 0.6964 - val_loss: 1.1902 - val_acc: 0.6943\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1667 - acc: 0.6974 - val_loss: 1.1850 - val_acc: 0.6952\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1614 - acc: 0.6984 - val_loss: 1.1798 - val_acc: 0.6958\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1561 - acc: 0.6991 - val_loss: 1.1746 - val_acc: 0.6965\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1509 - acc: 0.7001 - val_loss: 1.1695 - val_acc: 0.6976\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1457 - acc: 0.7010 - val_loss: 1.1644 - val_acc: 0.6986\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.1405 - acc: 0.7021 - val_loss: 1.1593 - val_acc: 0.6995\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1354 - acc: 0.7030 - val_loss: 1.1542 - val_acc: 0.7005\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1303 - acc: 0.7041 - val_loss: 1.1492 - val_acc: 0.7014\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1252 - acc: 0.7051 - val_loss: 1.1443 - val_acc: 0.7024\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.1202 - acc: 0.7062 - val_loss: 1.1393 - val_acc: 0.7033\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1152 - acc: 0.7075 - val_loss: 1.1345 - val_acc: 0.7045\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1102 - acc: 0.7089 - val_loss: 1.1296 - val_acc: 0.7059\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.1053 - acc: 0.7104 - val_loss: 1.1247 - val_acc: 0.7071\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1004 - acc: 0.7117 - val_loss: 1.1199 - val_acc: 0.7081\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0955 - acc: 0.7133 - val_loss: 1.1152 - val_acc: 0.7091\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0907 - acc: 0.7146 - val_loss: 1.1105 - val_acc: 0.7104\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0859 - acc: 0.7163 - val_loss: 1.1058 - val_acc: 0.7117\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0812 - acc: 0.7178 - val_loss: 1.1012 - val_acc: 0.7129\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0765 - acc: 0.7192 - val_loss: 1.0965 - val_acc: 0.7145\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.0718 - acc: 0.7204 - val_loss: 1.0920 - val_acc: 0.7159\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0671 - acc: 0.7222 - val_loss: 1.0875 - val_acc: 0.7173\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.0626 - acc: 0.7235 - val_loss: 1.0830 - val_acc: 0.7190\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0580 - acc: 0.7251 - val_loss: 1.0785 - val_acc: 0.7203\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.0535 - acc: 0.7264 - val_loss: 1.0741 - val_acc: 0.7214\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.0490 - acc: 0.7275 - val_loss: 1.0697 - val_acc: 0.7228\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.0445 - acc: 0.7291 - val_loss: 1.0653 - val_acc: 0.7247\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0401 - acc: 0.7307 - val_loss: 1.0610 - val_acc: 0.7260\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.0357 - acc: 0.7320 - val_loss: 1.0568 - val_acc: 0.7280\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0314 - acc: 0.7334 - val_loss: 1.0525 - val_acc: 0.7293\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.0271 - acc: 0.7349 - val_loss: 1.0483 - val_acc: 0.7312\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0228 - acc: 0.7365 - val_loss: 1.0441 - val_acc: 0.7328\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0186 - acc: 0.7381 - val_loss: 1.0400 - val_acc: 0.7344\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.0144 - acc: 0.7398 - val_loss: 1.0359 - val_acc: 0.7361\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0102 - acc: 0.7415 - val_loss: 1.0318 - val_acc: 0.7380\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0061 - acc: 0.7435 - val_loss: 1.0278 - val_acc: 0.7399\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.0020 - acc: 0.7455 - val_loss: 1.0238 - val_acc: 0.7415\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9979 - acc: 0.7473 - val_loss: 1.0198 - val_acc: 0.7432\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.9939 - acc: 0.7492 - val_loss: 1.0158 - val_acc: 0.7448\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9899 - acc: 0.7510 - val_loss: 1.0119 - val_acc: 0.7462\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9860 - acc: 0.7527 - val_loss: 1.0080 - val_acc: 0.7477\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9820 - acc: 0.7544 - val_loss: 1.0042 - val_acc: 0.7499\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9781 - acc: 0.7561 - val_loss: 1.0003 - val_acc: 0.7514\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9743 - acc: 0.7576 - val_loss: 0.9966 - val_acc: 0.7531\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9704 - acc: 0.7593 - val_loss: 0.9928 - val_acc: 0.7544\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9666 - acc: 0.7608 - val_loss: 0.9891 - val_acc: 0.7559\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.9628 - acc: 0.7619 - val_loss: 0.9854 - val_acc: 0.7570\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9591 - acc: 0.7637 - val_loss: 0.9817 - val_acc: 0.7587\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9554 - acc: 0.7649 - val_loss: 0.9780 - val_acc: 0.7599\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9517 - acc: 0.7663 - val_loss: 0.9744 - val_acc: 0.7612\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9480 - acc: 0.7677 - val_loss: 0.9708 - val_acc: 0.7623\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.9444 - acc: 0.7690 - val_loss: 0.9672 - val_acc: 0.7633\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9408 - acc: 0.7702 - val_loss: 0.9637 - val_acc: 0.7644\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9372 - acc: 0.7711 - val_loss: 0.9602 - val_acc: 0.7654\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9337 - acc: 0.7721 - val_loss: 0.9567 - val_acc: 0.7665\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9302 - acc: 0.7733 - val_loss: 0.9532 - val_acc: 0.7673\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.9267 - acc: 0.7741 - val_loss: 0.9498 - val_acc: 0.7681\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9232 - acc: 0.7751 - val_loss: 0.9464 - val_acc: 0.7690\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9197 - acc: 0.7762 - val_loss: 0.9430 - val_acc: 0.7698\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9163 - acc: 0.7771 - val_loss: 0.9396 - val_acc: 0.7705\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9129 - acc: 0.7779 - val_loss: 0.9363 - val_acc: 0.7713\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9096 - acc: 0.7790 - val_loss: 0.9329 - val_acc: 0.7722\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9062 - acc: 0.7800 - val_loss: 0.9296 - val_acc: 0.7727\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9029 - acc: 0.7811 - val_loss: 0.9264 - val_acc: 0.7736\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.8996 - acc: 0.7821 - val_loss: 0.9231 - val_acc: 0.7742\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8963 - acc: 0.7828 - val_loss: 0.9199 - val_acc: 0.7749\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8931 - acc: 0.7836 - val_loss: 0.9167 - val_acc: 0.7757\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8898 - acc: 0.7849 - val_loss: 0.9135 - val_acc: 0.7770\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8867 - acc: 0.7861 - val_loss: 0.9103 - val_acc: 0.7777\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8835 - acc: 0.7868 - val_loss: 0.9072 - val_acc: 0.7786\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.8803 - acc: 0.7874 - val_loss: 0.9041 - val_acc: 0.7793\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8772 - acc: 0.7882 - val_loss: 0.9010 - val_acc: 0.7800\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.8740 - acc: 0.7891 - val_loss: 0.8979 - val_acc: 0.7804\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8709 - acc: 0.7897 - val_loss: 0.8948 - val_acc: 0.7811\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8678 - acc: 0.7904 - val_loss: 0.8918 - val_acc: 0.7818\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8648 - acc: 0.7912 - val_loss: 0.8888 - val_acc: 0.7826\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.8617 - acc: 0.7920 - val_loss: 0.8857 - val_acc: 0.7833\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8587 - acc: 0.7927 - val_loss: 0.8827 - val_acc: 0.7837\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8557 - acc: 0.7932 - val_loss: 0.8798 - val_acc: 0.7843\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.8527 - acc: 0.7938 - val_loss: 0.8768 - val_acc: 0.7850\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.8497 - acc: 0.7946 - val_loss: 0.8739 - val_acc: 0.7855\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8468 - acc: 0.7951 - val_loss: 0.8710 - val_acc: 0.7860\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8439 - acc: 0.7957 - val_loss: 0.8681 - val_acc: 0.7868\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8409 - acc: 0.7963 - val_loss: 0.8652 - val_acc: 0.7872\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.8381 - acc: 0.7968 - val_loss: 0.8623 - val_acc: 0.7878\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8352 - acc: 0.7974 - val_loss: 0.8595 - val_acc: 0.7883\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.8323 - acc: 0.7979 - val_loss: 0.8567 - val_acc: 0.7887\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8295 - acc: 0.7983 - val_loss: 0.8539 - val_acc: 0.7892\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8267 - acc: 0.7988 - val_loss: 0.8511 - val_acc: 0.7898\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8239 - acc: 0.7994 - val_loss: 0.8483 - val_acc: 0.7904\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.8211 - acc: 0.7999 - val_loss: 0.8456 - val_acc: 0.7908\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.8183 - acc: 0.8002 - val_loss: 0.8428 - val_acc: 0.7913\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8156 - acc: 0.8008 - val_loss: 0.8401 - val_acc: 0.7922\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8129 - acc: 0.8016 - val_loss: 0.8374 - val_acc: 0.7926\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8101 - acc: 0.8021 - val_loss: 0.8348 - val_acc: 0.7933\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8074 - acc: 0.8029 - val_loss: 0.8321 - val_acc: 0.7938\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8048 - acc: 0.8035 - val_loss: 0.8294 - val_acc: 0.7944\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8021 - acc: 0.8042 - val_loss: 0.8268 - val_acc: 0.7950\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7995 - acc: 0.8047 - val_loss: 0.8242 - val_acc: 0.7955\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7969 - acc: 0.8051 - val_loss: 0.8216 - val_acc: 0.7959\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.7943 - acc: 0.8059 - val_loss: 0.8190 - val_acc: 0.7966\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7917 - acc: 0.8066 - val_loss: 0.8165 - val_acc: 0.7971\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7891 - acc: 0.8072 - val_loss: 0.8139 - val_acc: 0.7976\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7865 - acc: 0.8077 - val_loss: 0.8114 - val_acc: 0.7982\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7840 - acc: 0.8082 - val_loss: 0.8089 - val_acc: 0.7986\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7815 - acc: 0.8087 - val_loss: 0.8064 - val_acc: 0.7989\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7790 - acc: 0.8093 - val_loss: 0.8039 - val_acc: 0.7993\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7765 - acc: 0.8098 - val_loss: 0.8015 - val_acc: 0.7999\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7741 - acc: 0.8103 - val_loss: 0.7990 - val_acc: 0.8004\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7716 - acc: 0.8108 - val_loss: 0.7966 - val_acc: 0.8009\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.7692 - acc: 0.8111 - val_loss: 0.7942 - val_acc: 0.8014\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7668 - acc: 0.8116 - val_loss: 0.7919 - val_acc: 0.8017\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7644 - acc: 0.8122 - val_loss: 0.7895 - val_acc: 0.8021\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7620 - acc: 0.8126 - val_loss: 0.7871 - val_acc: 0.8024\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7596 - acc: 0.8131 - val_loss: 0.7848 - val_acc: 0.8028\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7573 - acc: 0.8137 - val_loss: 0.7824 - val_acc: 0.8035\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7549 - acc: 0.8141 - val_loss: 0.7801 - val_acc: 0.8037\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7526 - acc: 0.8146 - val_loss: 0.7778 - val_acc: 0.8041\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7503 - acc: 0.8151 - val_loss: 0.7755 - val_acc: 0.8045\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7480 - acc: 0.8156 - val_loss: 0.7733 - val_acc: 0.8050\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7458 - acc: 0.8161 - val_loss: 0.7710 - val_acc: 0.8054\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7435 - acc: 0.8165 - val_loss: 0.7688 - val_acc: 0.8059\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7413 - acc: 0.8170 - val_loss: 0.7666 - val_acc: 0.8064\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7390 - acc: 0.8173 - val_loss: 0.7643 - val_acc: 0.8070\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7368 - acc: 0.8178 - val_loss: 0.7622 - val_acc: 0.8075\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7346 - acc: 0.8182 - val_loss: 0.7600 - val_acc: 0.8079\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7325 - acc: 0.8188 - val_loss: 0.7578 - val_acc: 0.8082\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7303 - acc: 0.8192 - val_loss: 0.7557 - val_acc: 0.8087\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7281 - acc: 0.8196 - val_loss: 0.7535 - val_acc: 0.8092\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7260 - acc: 0.8200 - val_loss: 0.7514 - val_acc: 0.8095\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7239 - acc: 0.8204 - val_loss: 0.7494 - val_acc: 0.8097\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7218 - acc: 0.8208 - val_loss: 0.7473 - val_acc: 0.8101\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7197 - acc: 0.8212 - val_loss: 0.7452 - val_acc: 0.8105\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.7176 - acc: 0.8216 - val_loss: 0.7431 - val_acc: 0.8110\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7155 - acc: 0.8220 - val_loss: 0.7410 - val_acc: 0.8114\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7135 - acc: 0.8223 - val_loss: 0.7390 - val_acc: 0.8118\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7114 - acc: 0.8226 - val_loss: 0.7370 - val_acc: 0.8121\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7094 - acc: 0.8229 - val_loss: 0.7350 - val_acc: 0.8125\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7074 - acc: 0.8232 - val_loss: 0.7329 - val_acc: 0.8130\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7054 - acc: 0.8235 - val_loss: 0.7310 - val_acc: 0.8134\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7034 - acc: 0.8238 - val_loss: 0.7290 - val_acc: 0.8140\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7014 - acc: 0.8242 - val_loss: 0.7270 - val_acc: 0.8145\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6994 - acc: 0.8247 - val_loss: 0.7250 - val_acc: 0.8148\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6974 - acc: 0.8250 - val_loss: 0.7231 - val_acc: 0.8152\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6955 - acc: 0.8254 - val_loss: 0.7212 - val_acc: 0.8157\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6936 - acc: 0.8258 - val_loss: 0.7193 - val_acc: 0.8161\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6916 - acc: 0.8262 - val_loss: 0.7174 - val_acc: 0.8165\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6897 - acc: 0.8267 - val_loss: 0.7155 - val_acc: 0.8171\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6878 - acc: 0.8271 - val_loss: 0.7136 - val_acc: 0.8176\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6860 - acc: 0.8276 - val_loss: 0.7117 - val_acc: 0.8180\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6841 - acc: 0.8279 - val_loss: 0.7099 - val_acc: 0.8187\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6822 - acc: 0.8283 - val_loss: 0.7080 - val_acc: 0.8192\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6804 - acc: 0.8285 - val_loss: 0.7062 - val_acc: 0.8196\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6785 - acc: 0.8288 - val_loss: 0.7044 - val_acc: 0.8201\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6767 - acc: 0.8291 - val_loss: 0.7025 - val_acc: 0.8205\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6749 - acc: 0.8295 - val_loss: 0.7007 - val_acc: 0.8209\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6731 - acc: 0.8299 - val_loss: 0.6989 - val_acc: 0.8214\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6713 - acc: 0.8303 - val_loss: 0.6971 - val_acc: 0.8217\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6695 - acc: 0.8308 - val_loss: 0.6954 - val_acc: 0.8220\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6677 - acc: 0.8311 - val_loss: 0.6936 - val_acc: 0.8224\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6660 - acc: 0.8315 - val_loss: 0.6919 - val_acc: 0.8226\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6642 - acc: 0.8319 - val_loss: 0.6902 - val_acc: 0.8229\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6625 - acc: 0.8324 - val_loss: 0.6885 - val_acc: 0.8234\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6607 - acc: 0.8327 - val_loss: 0.6867 - val_acc: 0.8238\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6590 - acc: 0.8331 - val_loss: 0.6850 - val_acc: 0.8242\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6573 - acc: 0.8335 - val_loss: 0.6833 - val_acc: 0.8245\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.6556 - acc: 0.8338 - val_loss: 0.6816 - val_acc: 0.8249\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6539 - acc: 0.8341 - val_loss: 0.6799 - val_acc: 0.8252\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6522 - acc: 0.8343 - val_loss: 0.6782 - val_acc: 0.8255\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6505 - acc: 0.8349 - val_loss: 0.6766 - val_acc: 0.8260\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6488 - acc: 0.8353 - val_loss: 0.6749 - val_acc: 0.8265\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6472 - acc: 0.8357 - val_loss: 0.6733 - val_acc: 0.8268\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6455 - acc: 0.8360 - val_loss: 0.6717 - val_acc: 0.8274\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6439 - acc: 0.8363 - val_loss: 0.6700 - val_acc: 0.8277\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6423 - acc: 0.8367 - val_loss: 0.6684 - val_acc: 0.8282\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6406 - acc: 0.8372 - val_loss: 0.6668 - val_acc: 0.8286\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6390 - acc: 0.8376 - val_loss: 0.6652 - val_acc: 0.8291\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6374 - acc: 0.8378 - val_loss: 0.6636 - val_acc: 0.8294\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6358 - acc: 0.8381 - val_loss: 0.6620 - val_acc: 0.8297\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6342 - acc: 0.8384 - val_loss: 0.6604 - val_acc: 0.8302\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6326 - acc: 0.8388 - val_loss: 0.6589 - val_acc: 0.8306\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6311 - acc: 0.8391 - val_loss: 0.6573 - val_acc: 0.8308\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.6295 - acc: 0.8395 - val_loss: 0.6558 - val_acc: 0.8312\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6280 - acc: 0.8400 - val_loss: 0.6542 - val_acc: 0.8318\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6264 - acc: 0.8404 - val_loss: 0.6527 - val_acc: 0.8321\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6249 - acc: 0.8407 - val_loss: 0.6512 - val_acc: 0.8323\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6233 - acc: 0.8410 - val_loss: 0.6496 - val_acc: 0.8327\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6218 - acc: 0.8413 - val_loss: 0.6481 - val_acc: 0.8331\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.6203 - acc: 0.8416 - val_loss: 0.6466 - val_acc: 0.8335\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6188 - acc: 0.8419 - val_loss: 0.6452 - val_acc: 0.8340\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6173 - acc: 0.8422 - val_loss: 0.6437 - val_acc: 0.8344\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6158 - acc: 0.8423 - val_loss: 0.6422 - val_acc: 0.8347\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6143 - acc: 0.8427 - val_loss: 0.6408 - val_acc: 0.8349\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6128 - acc: 0.8431 - val_loss: 0.6393 - val_acc: 0.8354\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6114 - acc: 0.8434 - val_loss: 0.6378 - val_acc: 0.8358\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6099 - acc: 0.8437 - val_loss: 0.6364 - val_acc: 0.8364\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6085 - acc: 0.8442 - val_loss: 0.6350 - val_acc: 0.8368\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.6070 - acc: 0.8444 - val_loss: 0.6335 - val_acc: 0.8373\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6056 - acc: 0.8447 - val_loss: 0.6321 - val_acc: 0.8376\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6041 - acc: 0.8449 - val_loss: 0.6307 - val_acc: 0.8380\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6027 - acc: 0.8454 - val_loss: 0.6293 - val_acc: 0.8384\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.6013 - acc: 0.8457 - val_loss: 0.6279 - val_acc: 0.8386\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5999 - acc: 0.8460 - val_loss: 0.6265 - val_acc: 0.8390\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5985 - acc: 0.8465 - val_loss: 0.6251 - val_acc: 0.8392\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5971 - acc: 0.8467 - val_loss: 0.6237 - val_acc: 0.8396\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5957 - acc: 0.8471 - val_loss: 0.6224 - val_acc: 0.8399\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5943 - acc: 0.8474 - val_loss: 0.6210 - val_acc: 0.8402\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5929 - acc: 0.8478 - val_loss: 0.6197 - val_acc: 0.8404\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5916 - acc: 0.8482 - val_loss: 0.6183 - val_acc: 0.8409\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5902 - acc: 0.8484 - val_loss: 0.6170 - val_acc: 0.8413\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5888 - acc: 0.8487 - val_loss: 0.6157 - val_acc: 0.8416\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5875 - acc: 0.8491 - val_loss: 0.6143 - val_acc: 0.8419\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5861 - acc: 0.8497 - val_loss: 0.6130 - val_acc: 0.8427\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5848 - acc: 0.8505 - val_loss: 0.6117 - val_acc: 0.8429\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5835 - acc: 0.8508 - val_loss: 0.6104 - val_acc: 0.8431\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5822 - acc: 0.8512 - val_loss: 0.6091 - val_acc: 0.8436\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.5808 - acc: 0.8517 - val_loss: 0.6078 - val_acc: 0.8439\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5795 - acc: 0.8518 - val_loss: 0.6065 - val_acc: 0.8443\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5782 - acc: 0.8521 - val_loss: 0.6052 - val_acc: 0.8448\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5769 - acc: 0.8525 - val_loss: 0.6040 - val_acc: 0.8451\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5756 - acc: 0.8529 - val_loss: 0.6027 - val_acc: 0.8456\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5743 - acc: 0.8534 - val_loss: 0.6014 - val_acc: 0.8459\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5731 - acc: 0.8537 - val_loss: 0.6002 - val_acc: 0.8462\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5718 - acc: 0.8541 - val_loss: 0.5989 - val_acc: 0.8466\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5705 - acc: 0.8545 - val_loss: 0.5977 - val_acc: 0.8470\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5692 - acc: 0.8549 - val_loss: 0.5965 - val_acc: 0.8472\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5680 - acc: 0.8551 - val_loss: 0.5952 - val_acc: 0.8476\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5667 - acc: 0.8555 - val_loss: 0.5940 - val_acc: 0.8479\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5655 - acc: 0.8561 - val_loss: 0.5928 - val_acc: 0.8483\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5643 - acc: 0.8565 - val_loss: 0.5916 - val_acc: 0.8486\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5630 - acc: 0.8569 - val_loss: 0.5904 - val_acc: 0.8489\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5618 - acc: 0.8572 - val_loss: 0.5892 - val_acc: 0.8492\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5606 - acc: 0.8574 - val_loss: 0.5880 - val_acc: 0.8494\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5594 - acc: 0.8579 - val_loss: 0.5868 - val_acc: 0.8499\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5581 - acc: 0.8582 - val_loss: 0.5856 - val_acc: 0.8503\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5569 - acc: 0.8585 - val_loss: 0.5844 - val_acc: 0.8504\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5557 - acc: 0.8588 - val_loss: 0.5833 - val_acc: 0.8506\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.5545 - acc: 0.8592 - val_loss: 0.5821 - val_acc: 0.8508\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5534 - acc: 0.8594 - val_loss: 0.5810 - val_acc: 0.8510\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5522 - acc: 0.8598 - val_loss: 0.5798 - val_acc: 0.8513\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5510 - acc: 0.8602 - val_loss: 0.5787 - val_acc: 0.8516\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5498 - acc: 0.8605 - val_loss: 0.5775 - val_acc: 0.8518\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5487 - acc: 0.8608 - val_loss: 0.5764 - val_acc: 0.8521\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5475 - acc: 0.8611 - val_loss: 0.5753 - val_acc: 0.8526\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5463 - acc: 0.8614 - val_loss: 0.5742 - val_acc: 0.8528\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5452 - acc: 0.8616 - val_loss: 0.5730 - val_acc: 0.8530\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5440 - acc: 0.8619 - val_loss: 0.5719 - val_acc: 0.8531\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5429 - acc: 0.8620 - val_loss: 0.5708 - val_acc: 0.8534\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5418 - acc: 0.8623 - val_loss: 0.5697 - val_acc: 0.8536\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5406 - acc: 0.8626 - val_loss: 0.5686 - val_acc: 0.8539\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5395 - acc: 0.8628 - val_loss: 0.5675 - val_acc: 0.8541\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5384 - acc: 0.8630 - val_loss: 0.5665 - val_acc: 0.8543\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5373 - acc: 0.8633 - val_loss: 0.5654 - val_acc: 0.8547\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5362 - acc: 0.8635 - val_loss: 0.5643 - val_acc: 0.8550\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5351 - acc: 0.8638 - val_loss: 0.5632 - val_acc: 0.8552\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5340 - acc: 0.8641 - val_loss: 0.5622 - val_acc: 0.8553\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5329 - acc: 0.8643 - val_loss: 0.5611 - val_acc: 0.8555\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5318 - acc: 0.8644 - val_loss: 0.5601 - val_acc: 0.8556\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5307 - acc: 0.8646 - val_loss: 0.5590 - val_acc: 0.8559\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5296 - acc: 0.8648 - val_loss: 0.5580 - val_acc: 0.8562\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5285 - acc: 0.8650 - val_loss: 0.5569 - val_acc: 0.8563\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5275 - acc: 0.8652 - val_loss: 0.5559 - val_acc: 0.8565\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5264 - acc: 0.8654 - val_loss: 0.5549 - val_acc: 0.8567\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5253 - acc: 0.8657 - val_loss: 0.5539 - val_acc: 0.8570\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5243 - acc: 0.8659 - val_loss: 0.5528 - val_acc: 0.8573\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5232 - acc: 0.8661 - val_loss: 0.5519 - val_acc: 0.8573\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5222 - acc: 0.8661 - val_loss: 0.5508 - val_acc: 0.8576\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5211 - acc: 0.8665 - val_loss: 0.5499 - val_acc: 0.8577\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5201 - acc: 0.8667 - val_loss: 0.5489 - val_acc: 0.8578\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5191 - acc: 0.8668 - val_loss: 0.5479 - val_acc: 0.8580\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5181 - acc: 0.8669 - val_loss: 0.5469 - val_acc: 0.8580\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5170 - acc: 0.8672 - val_loss: 0.5459 - val_acc: 0.8582\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5160 - acc: 0.8673 - val_loss: 0.5449 - val_acc: 0.8586\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5150 - acc: 0.8676 - val_loss: 0.5439 - val_acc: 0.8588\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5140 - acc: 0.8677 - val_loss: 0.5430 - val_acc: 0.8589\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5130 - acc: 0.8679 - val_loss: 0.5420 - val_acc: 0.8590\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5120 - acc: 0.8681 - val_loss: 0.5410 - val_acc: 0.8591\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5110 - acc: 0.8683 - val_loss: 0.5401 - val_acc: 0.8593\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5100 - acc: 0.8684 - val_loss: 0.5391 - val_acc: 0.8596\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5090 - acc: 0.8686 - val_loss: 0.5382 - val_acc: 0.8597\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5080 - acc: 0.8687 - val_loss: 0.5372 - val_acc: 0.8598\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5070 - acc: 0.8689 - val_loss: 0.5363 - val_acc: 0.8600\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5060 - acc: 0.8692 - val_loss: 0.5354 - val_acc: 0.8603\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5051 - acc: 0.8695 - val_loss: 0.5344 - val_acc: 0.8605\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5041 - acc: 0.8697 - val_loss: 0.5335 - val_acc: 0.8607\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5031 - acc: 0.8699 - val_loss: 0.5326 - val_acc: 0.8609\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5022 - acc: 0.8700 - val_loss: 0.5317 - val_acc: 0.8609\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5012 - acc: 0.8702 - val_loss: 0.5308 - val_acc: 0.8613\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5003 - acc: 0.8705 - val_loss: 0.5299 - val_acc: 0.8614\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4993 - acc: 0.8707 - val_loss: 0.5290 - val_acc: 0.8615\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.4984 - acc: 0.8708 - val_loss: 0.5281 - val_acc: 0.8617\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4974 - acc: 0.8711 - val_loss: 0.5272 - val_acc: 0.8619\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4965 - acc: 0.8712 - val_loss: 0.5263 - val_acc: 0.8624\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4956 - acc: 0.8714 - val_loss: 0.5254 - val_acc: 0.8625\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4946 - acc: 0.8716 - val_loss: 0.5245 - val_acc: 0.8627\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4937 - acc: 0.8717 - val_loss: 0.5236 - val_acc: 0.8630\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4928 - acc: 0.8719 - val_loss: 0.5228 - val_acc: 0.8631\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4919 - acc: 0.8721 - val_loss: 0.5219 - val_acc: 0.8632\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4909 - acc: 0.8724 - val_loss: 0.5210 - val_acc: 0.8634\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4900 - acc: 0.8724 - val_loss: 0.5201 - val_acc: 0.8635\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4891 - acc: 0.8727 - val_loss: 0.5193 - val_acc: 0.8637\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.4882 - acc: 0.8729 - val_loss: 0.5185 - val_acc: 0.8639\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4873 - acc: 0.8729 - val_loss: 0.5176 - val_acc: 0.8641\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4864 - acc: 0.8733 - val_loss: 0.5168 - val_acc: 0.8641\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4855 - acc: 0.8734 - val_loss: 0.5159 - val_acc: 0.8641\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4847 - acc: 0.8736 - val_loss: 0.5151 - val_acc: 0.8642\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4838 - acc: 0.8737 - val_loss: 0.5142 - val_acc: 0.8644\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4829 - acc: 0.8739 - val_loss: 0.5134 - val_acc: 0.8648\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4820 - acc: 0.8740 - val_loss: 0.5126 - val_acc: 0.8649\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4811 - acc: 0.8741 - val_loss: 0.5118 - val_acc: 0.8651\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4803 - acc: 0.8743 - val_loss: 0.5109 - val_acc: 0.8653\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4794 - acc: 0.8745 - val_loss: 0.5101 - val_acc: 0.8657\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4785 - acc: 0.8745 - val_loss: 0.5093 - val_acc: 0.8657\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4777 - acc: 0.8747 - val_loss: 0.5085 - val_acc: 0.8659\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4768 - acc: 0.8749 - val_loss: 0.5077 - val_acc: 0.8660\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4760 - acc: 0.8752 - val_loss: 0.5069 - val_acc: 0.8662\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.4751 - acc: 0.8754 - val_loss: 0.5061 - val_acc: 0.8663\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4743 - acc: 0.8756 - val_loss: 0.5053 - val_acc: 0.8665\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4734 - acc: 0.8758 - val_loss: 0.5045 - val_acc: 0.8667\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4726 - acc: 0.8759 - val_loss: 0.5037 - val_acc: 0.8669\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4717 - acc: 0.8760 - val_loss: 0.5029 - val_acc: 0.8671\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4709 - acc: 0.8762 - val_loss: 0.5021 - val_acc: 0.8672\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4701 - acc: 0.8762 - val_loss: 0.5013 - val_acc: 0.8672\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4692 - acc: 0.8764 - val_loss: 0.5006 - val_acc: 0.8675\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4684 - acc: 0.8765 - val_loss: 0.4998 - val_acc: 0.8676\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4676 - acc: 0.8768 - val_loss: 0.4990 - val_acc: 0.8678\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4668 - acc: 0.8768 - val_loss: 0.4982 - val_acc: 0.8678\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4660 - acc: 0.8771 - val_loss: 0.4975 - val_acc: 0.8681\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4652 - acc: 0.8773 - val_loss: 0.4967 - val_acc: 0.8683\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4643 - acc: 0.8773 - val_loss: 0.4960 - val_acc: 0.8684\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4635 - acc: 0.8776 - val_loss: 0.4952 - val_acc: 0.8685\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4627 - acc: 0.8777 - val_loss: 0.4945 - val_acc: 0.8686\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4619 - acc: 0.8779 - val_loss: 0.4937 - val_acc: 0.8687\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4611 - acc: 0.8780 - val_loss: 0.4930 - val_acc: 0.8688\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4604 - acc: 0.8782 - val_loss: 0.4923 - val_acc: 0.8690\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4596 - acc: 0.8783 - val_loss: 0.4915 - val_acc: 0.8693\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4588 - acc: 0.8784 - val_loss: 0.4908 - val_acc: 0.8694\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4580 - acc: 0.8787 - val_loss: 0.4901 - val_acc: 0.8696\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4572 - acc: 0.8788 - val_loss: 0.4894 - val_acc: 0.8698\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4564 - acc: 0.8790 - val_loss: 0.4886 - val_acc: 0.8699\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4557 - acc: 0.8792 - val_loss: 0.4879 - val_acc: 0.8700\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4549 - acc: 0.8794 - val_loss: 0.4872 - val_acc: 0.8701\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4541 - acc: 0.8796 - val_loss: 0.4865 - val_acc: 0.8703\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4534 - acc: 0.8798 - val_loss: 0.4858 - val_acc: 0.8704\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4526 - acc: 0.8799 - val_loss: 0.4850 - val_acc: 0.8706\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4518 - acc: 0.8800 - val_loss: 0.4843 - val_acc: 0.8710\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.4511 - acc: 0.8803 - val_loss: 0.4836 - val_acc: 0.8710\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4503 - acc: 0.8804 - val_loss: 0.4829 - val_acc: 0.8713\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4496 - acc: 0.8806 - val_loss: 0.4823 - val_acc: 0.8714\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4488 - acc: 0.8807 - val_loss: 0.4815 - val_acc: 0.8716\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4481 - acc: 0.8808 - val_loss: 0.4808 - val_acc: 0.8717\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4473 - acc: 0.8809 - val_loss: 0.4802 - val_acc: 0.8718\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4466 - acc: 0.8811 - val_loss: 0.4795 - val_acc: 0.8719\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4459 - acc: 0.8812 - val_loss: 0.4788 - val_acc: 0.8720\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4451 - acc: 0.8814 - val_loss: 0.4781 - val_acc: 0.8722\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4444 - acc: 0.8815 - val_loss: 0.4775 - val_acc: 0.8722\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4437 - acc: 0.8816 - val_loss: 0.4768 - val_acc: 0.8723\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4429 - acc: 0.8818 - val_loss: 0.4761 - val_acc: 0.8725\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4422 - acc: 0.8820 - val_loss: 0.4754 - val_acc: 0.8725\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4415 - acc: 0.8821 - val_loss: 0.4748 - val_acc: 0.8727\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4408 - acc: 0.8822 - val_loss: 0.4741 - val_acc: 0.8736\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4400 - acc: 0.8833 - val_loss: 0.4735 - val_acc: 0.8737\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.4393 - acc: 0.8834 - val_loss: 0.4728 - val_acc: 0.8737\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4386 - acc: 0.8837 - val_loss: 0.4721 - val_acc: 0.8739\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4379 - acc: 0.8839 - val_loss: 0.4715 - val_acc: 0.8739\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4372 - acc: 0.8839 - val_loss: 0.4708 - val_acc: 0.8740\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4365 - acc: 0.8841 - val_loss: 0.4702 - val_acc: 0.8741\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4358 - acc: 0.8842 - val_loss: 0.4695 - val_acc: 0.8744\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4351 - acc: 0.8844 - val_loss: 0.4689 - val_acc: 0.8745\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4344 - acc: 0.8845 - val_loss: 0.4683 - val_acc: 0.8745\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from models import GRUModel\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "checkpoint_path = os.path.join(weights_folder, \"gru\", \"checkpoint.hdf5\")\n",
        "history_path = os.path.join(weights_folder, \"gru\", \"history.npy\")\n",
        "\n",
        "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
        "hist_callback = MyHistory(history_path)\n",
        "\n",
        "model = GRUModel(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "model.compile(**compile_args, optimizer=optimizer)\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "history = model.fit(x=x_train_pad,\n",
        "                    y=y_train_pad,\n",
        "                    batch_size=256,\n",
        "                    epochs=500,\n",
        "                    validation_data=(x_val_pad,\n",
        "                                     y_val_pad),\n",
        "                    callbacks=[checkpoint_callback, hist_callback])\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3z8B9GIgIpO"
      },
      "source": [
        "## Additional LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5AnRrcXngIpO",
        "outputId": "3d8156d4-b345-41c7-a9f8-e19e66a50e53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 7s 275ms/step - loss: 3.7498 - acc: 0.3156 - val_loss: 3.7001 - val_acc: 0.4764\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 3.6554 - acc: 0.4971 - val_loss: 3.6062 - val_acc: 0.5010\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.5547 - acc: 0.5157 - val_loss: 3.5016 - val_acc: 0.5091\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 3.4392 - acc: 0.5200 - val_loss: 3.3772 - val_acc: 0.5097\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 3.2986 - acc: 0.5204 - val_loss: 3.2219 - val_acc: 0.5099\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 3.1221 - acc: 0.5205 - val_loss: 3.0232 - val_acc: 0.5100\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 2.8958 - acc: 0.5200 - val_loss: 2.7724 - val_acc: 0.5099\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.6208 - acc: 0.5184 - val_loss: 2.4817 - val_acc: 0.5104\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.3318 - acc: 0.5174 - val_loss: 2.2121 - val_acc: 0.5115\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 2.0985 - acc: 0.5182 - val_loss: 2.0238 - val_acc: 0.5143\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.9495 - acc: 0.5201 - val_loss: 1.9075 - val_acc: 0.5197\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.8594 - acc: 0.5246 - val_loss: 1.8348 - val_acc: 0.5273\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.8016 - acc: 0.5294 - val_loss: 1.7878 - val_acc: 0.5317\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.7628 - acc: 0.5310 - val_loss: 1.7548 - val_acc: 0.5339\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.7344 - acc: 0.5322 - val_loss: 1.7300 - val_acc: 0.5350\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.7121 - acc: 0.5331 - val_loss: 1.7104 - val_acc: 0.5359\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.6942 - acc: 0.5341 - val_loss: 1.6943 - val_acc: 0.5368\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.6790 - acc: 0.5353 - val_loss: 1.6804 - val_acc: 0.5378\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.6656 - acc: 0.5365 - val_loss: 1.6680 - val_acc: 0.5391\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.6534 - acc: 0.5379 - val_loss: 1.6565 - val_acc: 0.5407\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.6421 - acc: 0.5396 - val_loss: 1.6460 - val_acc: 0.5422\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.6317 - acc: 0.5411 - val_loss: 1.6362 - val_acc: 0.5443\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.6220 - acc: 0.5435 - val_loss: 1.6268 - val_acc: 0.5459\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.6130 - acc: 0.5459 - val_loss: 1.6186 - val_acc: 0.5488\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.6045 - acc: 0.5485 - val_loss: 1.6107 - val_acc: 0.5502\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5966 - acc: 0.5510 - val_loss: 1.6033 - val_acc: 0.5516\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.5891 - acc: 0.5515 - val_loss: 1.5962 - val_acc: 0.5528\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5820 - acc: 0.5527 - val_loss: 1.5897 - val_acc: 0.5528\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5753 - acc: 0.5543 - val_loss: 1.5835 - val_acc: 0.5543\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5686 - acc: 0.5553 - val_loss: 1.5770 - val_acc: 0.5554\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.5623 - acc: 0.5559 - val_loss: 1.5711 - val_acc: 0.5564\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5561 - acc: 0.5583 - val_loss: 1.5653 - val_acc: 0.5572\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5501 - acc: 0.5578 - val_loss: 1.5594 - val_acc: 0.5578\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5442 - acc: 0.5595 - val_loss: 1.5540 - val_acc: 0.5607\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5386 - acc: 0.5612 - val_loss: 1.5484 - val_acc: 0.5604\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5329 - acc: 0.5614 - val_loss: 1.5430 - val_acc: 0.5616\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.5274 - acc: 0.5632 - val_loss: 1.5377 - val_acc: 0.5619\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.5219 - acc: 0.5650 - val_loss: 1.5322 - val_acc: 0.5629\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5164 - acc: 0.5646 - val_loss: 1.5270 - val_acc: 0.5649\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5111 - acc: 0.5689 - val_loss: 1.5219 - val_acc: 0.5677\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.5058 - acc: 0.5677 - val_loss: 1.5168 - val_acc: 0.5693\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5006 - acc: 0.5704 - val_loss: 1.5114 - val_acc: 0.5707\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4953 - acc: 0.5727 - val_loss: 1.5062 - val_acc: 0.5709\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4899 - acc: 0.5734 - val_loss: 1.5012 - val_acc: 0.5721\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4846 - acc: 0.5763 - val_loss: 1.4959 - val_acc: 0.5759\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4793 - acc: 0.5766 - val_loss: 1.4905 - val_acc: 0.5761\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4740 - acc: 0.5787 - val_loss: 1.4855 - val_acc: 0.5783\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.4687 - acc: 0.5809 - val_loss: 1.4802 - val_acc: 0.5791\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4633 - acc: 0.5808 - val_loss: 1.4746 - val_acc: 0.5824\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4580 - acc: 0.5845 - val_loss: 1.4694 - val_acc: 0.5835\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4525 - acc: 0.5838 - val_loss: 1.4641 - val_acc: 0.5866\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4469 - acc: 0.5879 - val_loss: 1.4583 - val_acc: 0.5874\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4412 - acc: 0.5879 - val_loss: 1.4527 - val_acc: 0.5895\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.4357 - acc: 0.5907 - val_loss: 1.4471 - val_acc: 0.5922\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.4300 - acc: 0.5915 - val_loss: 1.4413 - val_acc: 0.5937\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4242 - acc: 0.5953 - val_loss: 1.4355 - val_acc: 0.5951\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.4183 - acc: 0.5956 - val_loss: 1.4296 - val_acc: 0.5959\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4123 - acc: 0.5980 - val_loss: 1.4237 - val_acc: 0.5971\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.4063 - acc: 0.6002 - val_loss: 1.4176 - val_acc: 0.6011\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4003 - acc: 0.6022 - val_loss: 1.4116 - val_acc: 0.6019\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.3942 - acc: 0.6040 - val_loss: 1.4055 - val_acc: 0.6053\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3881 - acc: 0.6061 - val_loss: 1.3995 - val_acc: 0.6066\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3819 - acc: 0.6086 - val_loss: 1.3933 - val_acc: 0.6077\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3756 - acc: 0.6107 - val_loss: 1.3870 - val_acc: 0.6082\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3692 - acc: 0.6126 - val_loss: 1.3810 - val_acc: 0.6107\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3630 - acc: 0.6151 - val_loss: 1.3743 - val_acc: 0.6135\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.3564 - acc: 0.6177 - val_loss: 1.3678 - val_acc: 0.6171\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3498 - acc: 0.6201 - val_loss: 1.3614 - val_acc: 0.6211\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3432 - acc: 0.6231 - val_loss: 1.3548 - val_acc: 0.6219\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3364 - acc: 0.6250 - val_loss: 1.3484 - val_acc: 0.6264\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.3298 - acc: 0.6290 - val_loss: 1.3414 - val_acc: 0.6284\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.3231 - acc: 0.6313 - val_loss: 1.3349 - val_acc: 0.6283\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3162 - acc: 0.6345 - val_loss: 1.3280 - val_acc: 0.6323\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3094 - acc: 0.6378 - val_loss: 1.3217 - val_acc: 0.6331\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.3025 - acc: 0.6394 - val_loss: 1.3143 - val_acc: 0.6380\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.2953 - acc: 0.6444 - val_loss: 1.3071 - val_acc: 0.6429\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 1.2882 - acc: 0.6473 - val_loss: 1.3001 - val_acc: 0.6461\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.2810 - acc: 0.6496 - val_loss: 1.2932 - val_acc: 0.6513\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.2739 - acc: 0.6542 - val_loss: 1.2859 - val_acc: 0.6517\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.2665 - acc: 0.6562 - val_loss: 1.2784 - val_acc: 0.6548\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.2591 - acc: 0.6600 - val_loss: 1.2714 - val_acc: 0.6574\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.2517 - acc: 0.6641 - val_loss: 1.2637 - val_acc: 0.6619\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.2442 - acc: 0.6670 - val_loss: 1.2564 - val_acc: 0.6637\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.2367 - acc: 0.6710 - val_loss: 1.2489 - val_acc: 0.6678\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.2291 - acc: 0.6742 - val_loss: 1.2411 - val_acc: 0.6706\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.2214 - acc: 0.6777 - val_loss: 1.2337 - val_acc: 0.6750\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.2139 - acc: 0.6811 - val_loss: 1.2259 - val_acc: 0.6767\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.2061 - acc: 0.6831 - val_loss: 1.2185 - val_acc: 0.6787\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1983 - acc: 0.6875 - val_loss: 1.2107 - val_acc: 0.6819\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1904 - acc: 0.6895 - val_loss: 1.2027 - val_acc: 0.6847\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1826 - acc: 0.6922 - val_loss: 1.1948 - val_acc: 0.6882\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1746 - acc: 0.6957 - val_loss: 1.1870 - val_acc: 0.6910\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1668 - acc: 0.6984 - val_loss: 1.1790 - val_acc: 0.6931\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1587 - acc: 0.7011 - val_loss: 1.1712 - val_acc: 0.6952\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1507 - acc: 0.7037 - val_loss: 1.1632 - val_acc: 0.6971\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1429 - acc: 0.7059 - val_loss: 1.1553 - val_acc: 0.7000\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.1348 - acc: 0.7090 - val_loss: 1.1472 - val_acc: 0.7029\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.1268 - acc: 0.7103 - val_loss: 1.1394 - val_acc: 0.7056\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1187 - acc: 0.7134 - val_loss: 1.1313 - val_acc: 0.7075\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1106 - acc: 0.7153 - val_loss: 1.1235 - val_acc: 0.7096\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.1026 - acc: 0.7167 - val_loss: 1.1153 - val_acc: 0.7122\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0946 - acc: 0.7195 - val_loss: 1.1074 - val_acc: 0.7140\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0866 - acc: 0.7210 - val_loss: 1.0996 - val_acc: 0.7154\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.0786 - acc: 0.7230 - val_loss: 1.0916 - val_acc: 0.7179\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.0707 - acc: 0.7250 - val_loss: 1.0838 - val_acc: 0.7208\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0627 - acc: 0.7278 - val_loss: 1.0758 - val_acc: 0.7224\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0548 - acc: 0.7298 - val_loss: 1.0680 - val_acc: 0.7236\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0469 - acc: 0.7314 - val_loss: 1.0605 - val_acc: 0.7258\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.0390 - acc: 0.7338 - val_loss: 1.0528 - val_acc: 0.7270\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0313 - acc: 0.7352 - val_loss: 1.0452 - val_acc: 0.7289\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.0236 - acc: 0.7374 - val_loss: 1.0379 - val_acc: 0.7307\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0161 - acc: 0.7384 - val_loss: 1.0303 - val_acc: 0.7323\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0085 - acc: 0.7404 - val_loss: 1.0229 - val_acc: 0.7346\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.0010 - acc: 0.7421 - val_loss: 1.0156 - val_acc: 0.7362\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9936 - acc: 0.7436 - val_loss: 1.0088 - val_acc: 0.7375\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9864 - acc: 0.7458 - val_loss: 1.0015 - val_acc: 0.7388\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.9792 - acc: 0.7473 - val_loss: 0.9944 - val_acc: 0.7400\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9721 - acc: 0.7491 - val_loss: 0.9876 - val_acc: 0.7426\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9650 - acc: 0.7499 - val_loss: 0.9808 - val_acc: 0.7435\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9581 - acc: 0.7518 - val_loss: 0.9742 - val_acc: 0.7450\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.9513 - acc: 0.7536 - val_loss: 0.9673 - val_acc: 0.7462\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9445 - acc: 0.7543 - val_loss: 0.9611 - val_acc: 0.7468\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9379 - acc: 0.7558 - val_loss: 0.9546 - val_acc: 0.7488\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.9314 - acc: 0.7570 - val_loss: 0.9483 - val_acc: 0.7493\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.9249 - acc: 0.7582 - val_loss: 0.9421 - val_acc: 0.7509\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.9186 - acc: 0.7602 - val_loss: 0.9361 - val_acc: 0.7520\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.9122 - acc: 0.7610 - val_loss: 0.9302 - val_acc: 0.7530\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.9061 - acc: 0.7619 - val_loss: 0.9242 - val_acc: 0.7546\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8999 - acc: 0.7634 - val_loss: 0.9183 - val_acc: 0.7556\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8939 - acc: 0.7648 - val_loss: 0.9125 - val_acc: 0.7566\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8880 - acc: 0.7658 - val_loss: 0.9068 - val_acc: 0.7579\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8822 - acc: 0.7677 - val_loss: 0.9013 - val_acc: 0.7588\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8764 - acc: 0.7688 - val_loss: 0.8960 - val_acc: 0.7605\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8708 - acc: 0.7703 - val_loss: 0.8904 - val_acc: 0.7616\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8652 - acc: 0.7712 - val_loss: 0.8850 - val_acc: 0.7626\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8598 - acc: 0.7728 - val_loss: 0.8797 - val_acc: 0.7639\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8544 - acc: 0.7735 - val_loss: 0.8745 - val_acc: 0.7650\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.8489 - acc: 0.7749 - val_loss: 0.8694 - val_acc: 0.7664\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8436 - acc: 0.7763 - val_loss: 0.8643 - val_acc: 0.7673\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8384 - acc: 0.7768 - val_loss: 0.8593 - val_acc: 0.7687\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8332 - acc: 0.7783 - val_loss: 0.8544 - val_acc: 0.7699\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.8281 - acc: 0.7794 - val_loss: 0.8495 - val_acc: 0.7705\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8232 - acc: 0.7796 - val_loss: 0.8446 - val_acc: 0.7712\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8182 - acc: 0.7813 - val_loss: 0.8401 - val_acc: 0.7729\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8133 - acc: 0.7824 - val_loss: 0.8352 - val_acc: 0.7734\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8084 - acc: 0.7832 - val_loss: 0.8307 - val_acc: 0.7747\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8036 - acc: 0.7843 - val_loss: 0.8260 - val_acc: 0.7758\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7990 - acc: 0.7854 - val_loss: 0.8215 - val_acc: 0.7774\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.7943 - acc: 0.7862 - val_loss: 0.8171 - val_acc: 0.7780\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7898 - acc: 0.7873 - val_loss: 0.8127 - val_acc: 0.7788\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7852 - acc: 0.7883 - val_loss: 0.8083 - val_acc: 0.7798\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7808 - acc: 0.7889 - val_loss: 0.8041 - val_acc: 0.7813\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7764 - acc: 0.7906 - val_loss: 0.7997 - val_acc: 0.7820\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7720 - acc: 0.7915 - val_loss: 0.7956 - val_acc: 0.7831\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7676 - acc: 0.7925 - val_loss: 0.7913 - val_acc: 0.7839\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.7634 - acc: 0.7935 - val_loss: 0.7873 - val_acc: 0.7851\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.7592 - acc: 0.7951 - val_loss: 0.7833 - val_acc: 0.7856\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7551 - acc: 0.7957 - val_loss: 0.7790 - val_acc: 0.7868\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7509 - acc: 0.7969 - val_loss: 0.7752 - val_acc: 0.7880\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7467 - acc: 0.7977 - val_loss: 0.7711 - val_acc: 0.7887\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7426 - acc: 0.7990 - val_loss: 0.7674 - val_acc: 0.7898\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7387 - acc: 0.8003 - val_loss: 0.7633 - val_acc: 0.7910\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7346 - acc: 0.8016 - val_loss: 0.7596 - val_acc: 0.7923\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7308 - acc: 0.8027 - val_loss: 0.7557 - val_acc: 0.7935\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7268 - acc: 0.8040 - val_loss: 0.7520 - val_acc: 0.7945\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.7230 - acc: 0.8050 - val_loss: 0.7483 - val_acc: 0.7955\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7192 - acc: 0.8063 - val_loss: 0.7446 - val_acc: 0.7965\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.7155 - acc: 0.8071 - val_loss: 0.7410 - val_acc: 0.7974\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.7116 - acc: 0.8085 - val_loss: 0.7375 - val_acc: 0.7987\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7080 - acc: 0.8096 - val_loss: 0.7339 - val_acc: 0.7997\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7043 - acc: 0.8110 - val_loss: 0.7303 - val_acc: 0.8007\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7007 - acc: 0.8121 - val_loss: 0.7267 - val_acc: 0.8023\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.6971 - acc: 0.8133 - val_loss: 0.7233 - val_acc: 0.8031\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6936 - acc: 0.8144 - val_loss: 0.7202 - val_acc: 0.8042\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.6901 - acc: 0.8155 - val_loss: 0.7165 - val_acc: 0.8050\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.6867 - acc: 0.8165 - val_loss: 0.7131 - val_acc: 0.8059\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.6833 - acc: 0.8178 - val_loss: 0.7101 - val_acc: 0.8071\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.6799 - acc: 0.8188 - val_loss: 0.7066 - val_acc: 0.8080\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.6766 - acc: 0.8200 - val_loss: 0.7035 - val_acc: 0.8092\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6733 - acc: 0.8208 - val_loss: 0.7002 - val_acc: 0.8098\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.6700 - acc: 0.8219 - val_loss: 0.6971 - val_acc: 0.8109\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6669 - acc: 0.8230 - val_loss: 0.6939 - val_acc: 0.8120\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6636 - acc: 0.8243 - val_loss: 0.6911 - val_acc: 0.8127\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.6605 - acc: 0.8254 - val_loss: 0.6877 - val_acc: 0.8137\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6574 - acc: 0.8263 - val_loss: 0.6846 - val_acc: 0.8144\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.6543 - acc: 0.8272 - val_loss: 0.6818 - val_acc: 0.8151\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6513 - acc: 0.8277 - val_loss: 0.6787 - val_acc: 0.8159\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.6482 - acc: 0.8293 - val_loss: 0.6758 - val_acc: 0.8174\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6452 - acc: 0.8302 - val_loss: 0.6730 - val_acc: 0.8179\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6423 - acc: 0.8311 - val_loss: 0.6699 - val_acc: 0.8189\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.6394 - acc: 0.8318 - val_loss: 0.6671 - val_acc: 0.8194\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6365 - acc: 0.8331 - val_loss: 0.6644 - val_acc: 0.8203\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6337 - acc: 0.8339 - val_loss: 0.6617 - val_acc: 0.8208\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6308 - acc: 0.8343 - val_loss: 0.6587 - val_acc: 0.8219\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6280 - acc: 0.8358 - val_loss: 0.6561 - val_acc: 0.8225\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6252 - acc: 0.8360 - val_loss: 0.6531 - val_acc: 0.8233\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6225 - acc: 0.8371 - val_loss: 0.6506 - val_acc: 0.8240\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.6197 - acc: 0.8382 - val_loss: 0.6481 - val_acc: 0.8246\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.6171 - acc: 0.8386 - val_loss: 0.6453 - val_acc: 0.8254\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6144 - acc: 0.8393 - val_loss: 0.6427 - val_acc: 0.8261\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6117 - acc: 0.8400 - val_loss: 0.6401 - val_acc: 0.8266\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6091 - acc: 0.8408 - val_loss: 0.6376 - val_acc: 0.8276\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6065 - acc: 0.8413 - val_loss: 0.6350 - val_acc: 0.8283\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6040 - acc: 0.8420 - val_loss: 0.6325 - val_acc: 0.8290\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6014 - acc: 0.8429 - val_loss: 0.6302 - val_acc: 0.8298\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5989 - acc: 0.8432 - val_loss: 0.6274 - val_acc: 0.8305\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5964 - acc: 0.8442 - val_loss: 0.6251 - val_acc: 0.8309\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.5939 - acc: 0.8449 - val_loss: 0.6228 - val_acc: 0.8316\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5915 - acc: 0.8451 - val_loss: 0.6203 - val_acc: 0.8320\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5891 - acc: 0.8458 - val_loss: 0.6182 - val_acc: 0.8328\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5867 - acc: 0.8464 - val_loss: 0.6156 - val_acc: 0.8335\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5843 - acc: 0.8471 - val_loss: 0.6133 - val_acc: 0.8341\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5820 - acc: 0.8479 - val_loss: 0.6110 - val_acc: 0.8348\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5796 - acc: 0.8482 - val_loss: 0.6087 - val_acc: 0.8350\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5773 - acc: 0.8488 - val_loss: 0.6064 - val_acc: 0.8358\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5750 - acc: 0.8498 - val_loss: 0.6043 - val_acc: 0.8364\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5727 - acc: 0.8499 - val_loss: 0.6019 - val_acc: 0.8364\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5705 - acc: 0.8509 - val_loss: 0.5997 - val_acc: 0.8377\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5682 - acc: 0.8513 - val_loss: 0.5977 - val_acc: 0.8381\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5660 - acc: 0.8518 - val_loss: 0.5953 - val_acc: 0.8388\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5638 - acc: 0.8522 - val_loss: 0.5933 - val_acc: 0.8391\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.5616 - acc: 0.8531 - val_loss: 0.5912 - val_acc: 0.8400\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5595 - acc: 0.8535 - val_loss: 0.5891 - val_acc: 0.8407\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5573 - acc: 0.8543 - val_loss: 0.5869 - val_acc: 0.8409\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5552 - acc: 0.8547 - val_loss: 0.5849 - val_acc: 0.8415\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5532 - acc: 0.8554 - val_loss: 0.5829 - val_acc: 0.8420\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5511 - acc: 0.8558 - val_loss: 0.5809 - val_acc: 0.8427\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.5489 - acc: 0.8562 - val_loss: 0.5787 - val_acc: 0.8432\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5470 - acc: 0.8569 - val_loss: 0.5768 - val_acc: 0.8438\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5449 - acc: 0.8574 - val_loss: 0.5750 - val_acc: 0.8441\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5429 - acc: 0.8580 - val_loss: 0.5727 - val_acc: 0.8449\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5409 - acc: 0.8581 - val_loss: 0.5710 - val_acc: 0.8453\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5389 - acc: 0.8588 - val_loss: 0.5690 - val_acc: 0.8459\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5369 - acc: 0.8594 - val_loss: 0.5670 - val_acc: 0.8461\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5350 - acc: 0.8599 - val_loss: 0.5652 - val_acc: 0.8466\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5330 - acc: 0.8603 - val_loss: 0.5632 - val_acc: 0.8472\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5311 - acc: 0.8608 - val_loss: 0.5614 - val_acc: 0.8478\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5292 - acc: 0.8613 - val_loss: 0.5596 - val_acc: 0.8484\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5273 - acc: 0.8615 - val_loss: 0.5577 - val_acc: 0.8486\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5254 - acc: 0.8620 - val_loss: 0.5558 - val_acc: 0.8493\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5236 - acc: 0.8624 - val_loss: 0.5542 - val_acc: 0.8495\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5218 - acc: 0.8631 - val_loss: 0.5522 - val_acc: 0.8501\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5199 - acc: 0.8633 - val_loss: 0.5506 - val_acc: 0.8505\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5182 - acc: 0.8636 - val_loss: 0.5486 - val_acc: 0.8508\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5162 - acc: 0.8644 - val_loss: 0.5469 - val_acc: 0.8515\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5144 - acc: 0.8645 - val_loss: 0.5450 - val_acc: 0.8518\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5126 - acc: 0.8650 - val_loss: 0.5435 - val_acc: 0.8522\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5110 - acc: 0.8652 - val_loss: 0.5418 - val_acc: 0.8526\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.5091 - acc: 0.8658 - val_loss: 0.5399 - val_acc: 0.8530\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5074 - acc: 0.8661 - val_loss: 0.5384 - val_acc: 0.8532\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5057 - acc: 0.8664 - val_loss: 0.5367 - val_acc: 0.8536\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5040 - acc: 0.8670 - val_loss: 0.5351 - val_acc: 0.8541\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5022 - acc: 0.8672 - val_loss: 0.5334 - val_acc: 0.8546\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5005 - acc: 0.8676 - val_loss: 0.5317 - val_acc: 0.8551\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4989 - acc: 0.8681 - val_loss: 0.5301 - val_acc: 0.8558\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4972 - acc: 0.8686 - val_loss: 0.5285 - val_acc: 0.8559\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4955 - acc: 0.8691 - val_loss: 0.5268 - val_acc: 0.8565\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4938 - acc: 0.8693 - val_loss: 0.5252 - val_acc: 0.8568\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.4922 - acc: 0.8697 - val_loss: 0.5238 - val_acc: 0.8572\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4907 - acc: 0.8701 - val_loss: 0.5221 - val_acc: 0.8575\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4891 - acc: 0.8707 - val_loss: 0.5204 - val_acc: 0.8581\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4874 - acc: 0.8711 - val_loss: 0.5192 - val_acc: 0.8586\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4859 - acc: 0.8714 - val_loss: 0.5174 - val_acc: 0.8589\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4842 - acc: 0.8718 - val_loss: 0.5159 - val_acc: 0.8594\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4827 - acc: 0.8719 - val_loss: 0.5145 - val_acc: 0.8598\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4811 - acc: 0.8724 - val_loss: 0.5130 - val_acc: 0.8600\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4795 - acc: 0.8730 - val_loss: 0.5114 - val_acc: 0.8603\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4780 - acc: 0.8729 - val_loss: 0.5099 - val_acc: 0.8609\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.4764 - acc: 0.8736 - val_loss: 0.5085 - val_acc: 0.8612\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4749 - acc: 0.8737 - val_loss: 0.5070 - val_acc: 0.8613\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4734 - acc: 0.8741 - val_loss: 0.5055 - val_acc: 0.8622\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4719 - acc: 0.8745 - val_loss: 0.5041 - val_acc: 0.8623\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4704 - acc: 0.8751 - val_loss: 0.5027 - val_acc: 0.8627\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4689 - acc: 0.8754 - val_loss: 0.5011 - val_acc: 0.8631\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.4674 - acc: 0.8756 - val_loss: 0.4999 - val_acc: 0.8634\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4660 - acc: 0.8760 - val_loss: 0.4983 - val_acc: 0.8635\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4645 - acc: 0.8765 - val_loss: 0.4970 - val_acc: 0.8640\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4630 - acc: 0.8768 - val_loss: 0.4956 - val_acc: 0.8642\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.4617 - acc: 0.8770 - val_loss: 0.4944 - val_acc: 0.8647\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4602 - acc: 0.8775 - val_loss: 0.4928 - val_acc: 0.8647\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4588 - acc: 0.8779 - val_loss: 0.4915 - val_acc: 0.8651\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4574 - acc: 0.8782 - val_loss: 0.4902 - val_acc: 0.8656\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4560 - acc: 0.8785 - val_loss: 0.4888 - val_acc: 0.8658\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4546 - acc: 0.8791 - val_loss: 0.4876 - val_acc: 0.8662\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4532 - acc: 0.8794 - val_loss: 0.4861 - val_acc: 0.8666\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4518 - acc: 0.8797 - val_loss: 0.4848 - val_acc: 0.8670\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4505 - acc: 0.8800 - val_loss: 0.4835 - val_acc: 0.8673\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4491 - acc: 0.8805 - val_loss: 0.4824 - val_acc: 0.8673\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.4478 - acc: 0.8805 - val_loss: 0.4810 - val_acc: 0.8678\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4464 - acc: 0.8809 - val_loss: 0.4797 - val_acc: 0.8681\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4451 - acc: 0.8811 - val_loss: 0.4785 - val_acc: 0.8684\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4438 - acc: 0.8814 - val_loss: 0.4772 - val_acc: 0.8686\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4424 - acc: 0.8817 - val_loss: 0.4759 - val_acc: 0.8692\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4412 - acc: 0.8823 - val_loss: 0.4748 - val_acc: 0.8691\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4398 - acc: 0.8825 - val_loss: 0.4734 - val_acc: 0.8697\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4386 - acc: 0.8828 - val_loss: 0.4723 - val_acc: 0.8697\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4373 - acc: 0.8832 - val_loss: 0.4710 - val_acc: 0.8702\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4360 - acc: 0.8834 - val_loss: 0.4698 - val_acc: 0.8702\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.4347 - acc: 0.8836 - val_loss: 0.4686 - val_acc: 0.8709\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4335 - acc: 0.8841 - val_loss: 0.4675 - val_acc: 0.8710\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4322 - acc: 0.8844 - val_loss: 0.4662 - val_acc: 0.8716\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4310 - acc: 0.8848 - val_loss: 0.4650 - val_acc: 0.8716\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4297 - acc: 0.8851 - val_loss: 0.4638 - val_acc: 0.8722\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4285 - acc: 0.8853 - val_loss: 0.4628 - val_acc: 0.8724\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4273 - acc: 0.8856 - val_loss: 0.4617 - val_acc: 0.8726\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4261 - acc: 0.8858 - val_loss: 0.4603 - val_acc: 0.8729\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4248 - acc: 0.8862 - val_loss: 0.4594 - val_acc: 0.8733\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4237 - acc: 0.8865 - val_loss: 0.4581 - val_acc: 0.8737\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4225 - acc: 0.8867 - val_loss: 0.4570 - val_acc: 0.8737\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4213 - acc: 0.8870 - val_loss: 0.4561 - val_acc: 0.8742\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4201 - acc: 0.8874 - val_loss: 0.4547 - val_acc: 0.8744\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4190 - acc: 0.8876 - val_loss: 0.4539 - val_acc: 0.8748\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4178 - acc: 0.8879 - val_loss: 0.4525 - val_acc: 0.8749\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4166 - acc: 0.8881 - val_loss: 0.4515 - val_acc: 0.8751\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4155 - acc: 0.8883 - val_loss: 0.4504 - val_acc: 0.8758\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4144 - acc: 0.8886 - val_loss: 0.4494 - val_acc: 0.8757\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4132 - acc: 0.8888 - val_loss: 0.4484 - val_acc: 0.8760\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4121 - acc: 0.8890 - val_loss: 0.4472 - val_acc: 0.8763\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4109 - acc: 0.8894 - val_loss: 0.4462 - val_acc: 0.8766\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.4098 - acc: 0.8896 - val_loss: 0.4452 - val_acc: 0.8765\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4087 - acc: 0.8899 - val_loss: 0.4440 - val_acc: 0.8769\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4076 - acc: 0.8902 - val_loss: 0.4431 - val_acc: 0.8773\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4065 - acc: 0.8906 - val_loss: 0.4420 - val_acc: 0.8773\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4054 - acc: 0.8907 - val_loss: 0.4409 - val_acc: 0.8777\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4043 - acc: 0.8911 - val_loss: 0.4401 - val_acc: 0.8777\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.4032 - acc: 0.8912 - val_loss: 0.4389 - val_acc: 0.8778\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.4022 - acc: 0.8916 - val_loss: 0.4380 - val_acc: 0.8783\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4011 - acc: 0.8918 - val_loss: 0.4371 - val_acc: 0.8783\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4001 - acc: 0.8920 - val_loss: 0.4362 - val_acc: 0.8787\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3990 - acc: 0.8923 - val_loss: 0.4349 - val_acc: 0.8786\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3980 - acc: 0.8926 - val_loss: 0.4341 - val_acc: 0.8792\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3969 - acc: 0.8928 - val_loss: 0.4329 - val_acc: 0.8794\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3958 - acc: 0.8928 - val_loss: 0.4321 - val_acc: 0.8794\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3948 - acc: 0.8933 - val_loss: 0.4311 - val_acc: 0.8796\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3938 - acc: 0.8934 - val_loss: 0.4301 - val_acc: 0.8802\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3927 - acc: 0.8938 - val_loss: 0.4292 - val_acc: 0.8802\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3917 - acc: 0.8939 - val_loss: 0.4283 - val_acc: 0.8803\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3907 - acc: 0.8940 - val_loss: 0.4273 - val_acc: 0.8807\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3897 - acc: 0.8946 - val_loss: 0.4264 - val_acc: 0.8810\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3887 - acc: 0.8946 - val_loss: 0.4254 - val_acc: 0.8808\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3878 - acc: 0.8949 - val_loss: 0.4246 - val_acc: 0.8813\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3867 - acc: 0.8949 - val_loss: 0.4236 - val_acc: 0.8817\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3857 - acc: 0.8955 - val_loss: 0.4227 - val_acc: 0.8820\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3848 - acc: 0.8957 - val_loss: 0.4217 - val_acc: 0.8820\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3838 - acc: 0.8956 - val_loss: 0.4210 - val_acc: 0.8823\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3828 - acc: 0.8963 - val_loss: 0.4200 - val_acc: 0.8826\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3819 - acc: 0.8964 - val_loss: 0.4192 - val_acc: 0.8828\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3809 - acc: 0.8966 - val_loss: 0.4183 - val_acc: 0.8829\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3800 - acc: 0.8967 - val_loss: 0.4173 - val_acc: 0.8832\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3790 - acc: 0.8968 - val_loss: 0.4165 - val_acc: 0.8833\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3780 - acc: 0.8972 - val_loss: 0.4155 - val_acc: 0.8836\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3771 - acc: 0.8973 - val_loss: 0.4147 - val_acc: 0.8838\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3761 - acc: 0.8977 - val_loss: 0.4140 - val_acc: 0.8841\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3753 - acc: 0.8977 - val_loss: 0.4130 - val_acc: 0.8842\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3743 - acc: 0.8980 - val_loss: 0.4122 - val_acc: 0.8845\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3734 - acc: 0.8983 - val_loss: 0.4113 - val_acc: 0.8850\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3724 - acc: 0.8984 - val_loss: 0.4106 - val_acc: 0.8852\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3715 - acc: 0.8988 - val_loss: 0.4096 - val_acc: 0.8852\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3706 - acc: 0.8990 - val_loss: 0.4089 - val_acc: 0.8855\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.3697 - acc: 0.8993 - val_loss: 0.4080 - val_acc: 0.8858\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3688 - acc: 0.8993 - val_loss: 0.4070 - val_acc: 0.8860\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3679 - acc: 0.8998 - val_loss: 0.4064 - val_acc: 0.8862\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3670 - acc: 0.8998 - val_loss: 0.4055 - val_acc: 0.8864\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3662 - acc: 0.9001 - val_loss: 0.4047 - val_acc: 0.8866\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3652 - acc: 0.9004 - val_loss: 0.4038 - val_acc: 0.8868\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3644 - acc: 0.9006 - val_loss: 0.4030 - val_acc: 0.8868\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3635 - acc: 0.9010 - val_loss: 0.4023 - val_acc: 0.8872\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3627 - acc: 0.9009 - val_loss: 0.4016 - val_acc: 0.8874\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3618 - acc: 0.9012 - val_loss: 0.4006 - val_acc: 0.8877\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3609 - acc: 0.9015 - val_loss: 0.3999 - val_acc: 0.8878\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3600 - acc: 0.9018 - val_loss: 0.3991 - val_acc: 0.8880\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3592 - acc: 0.9021 - val_loss: 0.3982 - val_acc: 0.8883\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3583 - acc: 0.9024 - val_loss: 0.3976 - val_acc: 0.8884\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.3574 - acc: 0.9024 - val_loss: 0.3967 - val_acc: 0.8886\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3567 - acc: 0.9025 - val_loss: 0.3962 - val_acc: 0.8887\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.3558 - acc: 0.9030 - val_loss: 0.3952 - val_acc: 0.8889\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3549 - acc: 0.9032 - val_loss: 0.3945 - val_acc: 0.8891\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3541 - acc: 0.9035 - val_loss: 0.3938 - val_acc: 0.8893\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3533 - acc: 0.9040 - val_loss: 0.3930 - val_acc: 0.8894\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3524 - acc: 0.9040 - val_loss: 0.3923 - val_acc: 0.8895\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3516 - acc: 0.9041 - val_loss: 0.3915 - val_acc: 0.8899\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.3508 - acc: 0.9046 - val_loss: 0.3909 - val_acc: 0.8898\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.3500 - acc: 0.9046 - val_loss: 0.3899 - val_acc: 0.8901\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.3492 - acc: 0.9047 - val_loss: 0.3896 - val_acc: 0.8904\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 0.3484 - acc: 0.9051 - val_loss: 0.3885 - val_acc: 0.8904\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 0.3475 - acc: 0.9053 - val_loss: 0.3880 - val_acc: 0.8906\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3467 - acc: 0.9055 - val_loss: 0.3871 - val_acc: 0.8910\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3459 - acc: 0.9059 - val_loss: 0.3865 - val_acc: 0.8911\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3452 - acc: 0.9058 - val_loss: 0.3856 - val_acc: 0.8912\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.3443 - acc: 0.9060 - val_loss: 0.3850 - val_acc: 0.8912\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3436 - acc: 0.9062 - val_loss: 0.3842 - val_acc: 0.8914\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3428 - acc: 0.9065 - val_loss: 0.3837 - val_acc: 0.8914\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3420 - acc: 0.9067 - val_loss: 0.3828 - val_acc: 0.8918\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3412 - acc: 0.9067 - val_loss: 0.3822 - val_acc: 0.8917\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3405 - acc: 0.9070 - val_loss: 0.3815 - val_acc: 0.8920\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3398 - acc: 0.9070 - val_loss: 0.3809 - val_acc: 0.8921\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3390 - acc: 0.9073 - val_loss: 0.3803 - val_acc: 0.8922\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3381 - acc: 0.9076 - val_loss: 0.3794 - val_acc: 0.8924\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3373 - acc: 0.9077 - val_loss: 0.3789 - val_acc: 0.8926\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.3365 - acc: 0.9080 - val_loss: 0.3780 - val_acc: 0.8929\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3359 - acc: 0.9079 - val_loss: 0.3776 - val_acc: 0.8930\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3351 - acc: 0.9081 - val_loss: 0.3765 - val_acc: 0.8933\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3343 - acc: 0.9085 - val_loss: 0.3759 - val_acc: 0.8932\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3336 - acc: 0.9086 - val_loss: 0.3755 - val_acc: 0.8935\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3328 - acc: 0.9086 - val_loss: 0.3745 - val_acc: 0.8936\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3320 - acc: 0.9091 - val_loss: 0.3742 - val_acc: 0.8938\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3314 - acc: 0.9091 - val_loss: 0.3734 - val_acc: 0.8940\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3306 - acc: 0.9093 - val_loss: 0.3727 - val_acc: 0.8941\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3298 - acc: 0.9098 - val_loss: 0.3721 - val_acc: 0.8941\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3291 - acc: 0.9097 - val_loss: 0.3714 - val_acc: 0.8944\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3283 - acc: 0.9101 - val_loss: 0.3708 - val_acc: 0.8945\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3276 - acc: 0.9101 - val_loss: 0.3701 - val_acc: 0.8946\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3269 - acc: 0.9104 - val_loss: 0.3696 - val_acc: 0.8948\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3262 - acc: 0.9106 - val_loss: 0.3687 - val_acc: 0.8951\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3254 - acc: 0.9108 - val_loss: 0.3684 - val_acc: 0.8948\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.3247 - acc: 0.9109 - val_loss: 0.3675 - val_acc: 0.8955\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3240 - acc: 0.9113 - val_loss: 0.3669 - val_acc: 0.8953\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3233 - acc: 0.9114 - val_loss: 0.3664 - val_acc: 0.8959\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3225 - acc: 0.9117 - val_loss: 0.3658 - val_acc: 0.8957\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3219 - acc: 0.9117 - val_loss: 0.3650 - val_acc: 0.8959\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3211 - acc: 0.9118 - val_loss: 0.3645 - val_acc: 0.8963\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3204 - acc: 0.9121 - val_loss: 0.3639 - val_acc: 0.8962\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3197 - acc: 0.9122 - val_loss: 0.3632 - val_acc: 0.8966\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3190 - acc: 0.9123 - val_loss: 0.3627 - val_acc: 0.8965\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3183 - acc: 0.9127 - val_loss: 0.3621 - val_acc: 0.8967\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3176 - acc: 0.9125 - val_loss: 0.3612 - val_acc: 0.8972\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3169 - acc: 0.9131 - val_loss: 0.3608 - val_acc: 0.8972\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3162 - acc: 0.9131 - val_loss: 0.3602 - val_acc: 0.8975\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3156 - acc: 0.9133 - val_loss: 0.3595 - val_acc: 0.8975\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3148 - acc: 0.9135 - val_loss: 0.3590 - val_acc: 0.8977\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3142 - acc: 0.9137 - val_loss: 0.3584 - val_acc: 0.8977\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3135 - acc: 0.9139 - val_loss: 0.3577 - val_acc: 0.8979\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3128 - acc: 0.9140 - val_loss: 0.3573 - val_acc: 0.8981\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3121 - acc: 0.9143 - val_loss: 0.3565 - val_acc: 0.8983\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3114 - acc: 0.9143 - val_loss: 0.3559 - val_acc: 0.8983\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3107 - acc: 0.9147 - val_loss: 0.3555 - val_acc: 0.8984\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3101 - acc: 0.9146 - val_loss: 0.3548 - val_acc: 0.8985\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3095 - acc: 0.9151 - val_loss: 0.3543 - val_acc: 0.8988\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3087 - acc: 0.9152 - val_loss: 0.3536 - val_acc: 0.8990\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3081 - acc: 0.9153 - val_loss: 0.3531 - val_acc: 0.8993\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3074 - acc: 0.9156 - val_loss: 0.3525 - val_acc: 0.8996\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3067 - acc: 0.9160 - val_loss: 0.3518 - val_acc: 0.8997\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3061 - acc: 0.9158 - val_loss: 0.3515 - val_acc: 0.8997\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3054 - acc: 0.9161 - val_loss: 0.3508 - val_acc: 0.9000\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3047 - acc: 0.9164 - val_loss: 0.3503 - val_acc: 0.9001\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3041 - acc: 0.9163 - val_loss: 0.3498 - val_acc: 0.9003\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3034 - acc: 0.9167 - val_loss: 0.3492 - val_acc: 0.9005\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3028 - acc: 0.9168 - val_loss: 0.3485 - val_acc: 0.9009\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3022 - acc: 0.9171 - val_loss: 0.3482 - val_acc: 0.9008\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3015 - acc: 0.9173 - val_loss: 0.3475 - val_acc: 0.9010\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3009 - acc: 0.9174 - val_loss: 0.3469 - val_acc: 0.9011\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3002 - acc: 0.9176 - val_loss: 0.3465 - val_acc: 0.9015\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.2996 - acc: 0.9177 - val_loss: 0.3460 - val_acc: 0.9014\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2989 - acc: 0.9178 - val_loss: 0.3453 - val_acc: 0.9017\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2983 - acc: 0.9181 - val_loss: 0.3448 - val_acc: 0.9015\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2977 - acc: 0.9182 - val_loss: 0.3442 - val_acc: 0.9018\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2970 - acc: 0.9183 - val_loss: 0.3437 - val_acc: 0.9021\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2965 - acc: 0.9187 - val_loss: 0.3433 - val_acc: 0.9021\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2958 - acc: 0.9187 - val_loss: 0.3425 - val_acc: 0.9023\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2951 - acc: 0.9188 - val_loss: 0.3422 - val_acc: 0.9027\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2945 - acc: 0.9191 - val_loss: 0.3416 - val_acc: 0.9027\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2939 - acc: 0.9191 - val_loss: 0.3409 - val_acc: 0.9027\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.2933 - acc: 0.9193 - val_loss: 0.3406 - val_acc: 0.9029\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2927 - acc: 0.9194 - val_loss: 0.3400 - val_acc: 0.9030\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2920 - acc: 0.9196 - val_loss: 0.3396 - val_acc: 0.9030\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2915 - acc: 0.9199 - val_loss: 0.3389 - val_acc: 0.9033\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2909 - acc: 0.9199 - val_loss: 0.3384 - val_acc: 0.9034\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2902 - acc: 0.9202 - val_loss: 0.3380 - val_acc: 0.9035\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2896 - acc: 0.9203 - val_loss: 0.3377 - val_acc: 0.9038\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2890 - acc: 0.9205 - val_loss: 0.3368 - val_acc: 0.9039\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.2884 - acc: 0.9206 - val_loss: 0.3364 - val_acc: 0.9037\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.2878 - acc: 0.9207 - val_loss: 0.3359 - val_acc: 0.9042\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2871 - acc: 0.9208 - val_loss: 0.3354 - val_acc: 0.9043\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2866 - acc: 0.9211 - val_loss: 0.3348 - val_acc: 0.9045\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2859 - acc: 0.9213 - val_loss: 0.3345 - val_acc: 0.9045\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2854 - acc: 0.9216 - val_loss: 0.3340 - val_acc: 0.9046\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2848 - acc: 0.9216 - val_loss: 0.3334 - val_acc: 0.9048\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2842 - acc: 0.9217 - val_loss: 0.3329 - val_acc: 0.9048\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2836 - acc: 0.9219 - val_loss: 0.3325 - val_acc: 0.9049\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2830 - acc: 0.9221 - val_loss: 0.3319 - val_acc: 0.9052\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.2824 - acc: 0.9223 - val_loss: 0.3313 - val_acc: 0.9054\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2818 - acc: 0.9224 - val_loss: 0.3309 - val_acc: 0.9053\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2812 - acc: 0.9225 - val_loss: 0.3305 - val_acc: 0.9054\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2807 - acc: 0.9229 - val_loss: 0.3300 - val_acc: 0.9056\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2801 - acc: 0.9228 - val_loss: 0.3296 - val_acc: 0.9058\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2796 - acc: 0.9231 - val_loss: 0.3290 - val_acc: 0.9058\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2789 - acc: 0.9233 - val_loss: 0.3286 - val_acc: 0.9060\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2783 - acc: 0.9236 - val_loss: 0.3281 - val_acc: 0.9061\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2778 - acc: 0.9235 - val_loss: 0.3275 - val_acc: 0.9065\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2772 - acc: 0.9238 - val_loss: 0.3273 - val_acc: 0.9062\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2766 - acc: 0.9240 - val_loss: 0.3267 - val_acc: 0.9066\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2760 - acc: 0.9241 - val_loss: 0.3262 - val_acc: 0.9064\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2755 - acc: 0.9242 - val_loss: 0.3257 - val_acc: 0.9069\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2750 - acc: 0.9245 - val_loss: 0.3253 - val_acc: 0.9069\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2743 - acc: 0.9245 - val_loss: 0.3247 - val_acc: 0.9069\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2738 - acc: 0.9247 - val_loss: 0.3244 - val_acc: 0.9069\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2732 - acc: 0.9248 - val_loss: 0.3238 - val_acc: 0.9074\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2727 - acc: 0.9248 - val_loss: 0.3237 - val_acc: 0.9072\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2721 - acc: 0.9250 - val_loss: 0.3228 - val_acc: 0.9076\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2716 - acc: 0.9253 - val_loss: 0.3227 - val_acc: 0.9077\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from models import additionalLSTM\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "checkpoint_path = os.path.join(weights_folder, \"additionalLSTM\", \"checkpoint.hdf5\")\n",
        "history_path = os.path.join(weights_folder, \"additionalLSTM\", \"history.npy\")\n",
        "\n",
        "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
        "hist_callback = MyHistory(history_path)\n",
        "\n",
        "model = additionalLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "model.compile(**compile_args, optimizer=optimizer)\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "history = model.fit(x=x_train_pad,\n",
        "                    y=y_train_pad,\n",
        "                    batch_size=256,\n",
        "                    epochs=500,\n",
        "                    validation_data=(x_val_pad,\n",
        "                                     y_val_pad),\n",
        "                    callbacks=[checkpoint_callback, hist_callback])\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybT7-EN2gIpO"
      },
      "source": [
        "## Additional Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WzvrTGU3gIpP",
        "outputId": "c68ed51b-4bfd-48a5-b53e-3fd612e64ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 4s 145ms/step - loss: 0.9876 - acc: 0.6895 - val_loss: 1.0824 - val_acc: 0.6538\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.9849 - acc: 0.6859 - val_loss: 1.0817 - val_acc: 0.6681\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9830 - acc: 0.6902 - val_loss: 1.0801 - val_acc: 0.6680\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9818 - acc: 0.6920 - val_loss: 1.0800 - val_acc: 0.6637\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9807 - acc: 0.6918 - val_loss: 1.0788 - val_acc: 0.6674\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9797 - acc: 0.6920 - val_loss: 1.0783 - val_acc: 0.6683\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9787 - acc: 0.6924 - val_loss: 1.0778 - val_acc: 0.6679\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9778 - acc: 0.6924 - val_loss: 1.0773 - val_acc: 0.6679\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9770 - acc: 0.6925 - val_loss: 1.0765 - val_acc: 0.6681\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9761 - acc: 0.6926 - val_loss: 1.0761 - val_acc: 0.6678\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9752 - acc: 0.6926 - val_loss: 1.0754 - val_acc: 0.6682\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9744 - acc: 0.6927 - val_loss: 1.0752 - val_acc: 0.6677\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9736 - acc: 0.6927 - val_loss: 1.0744 - val_acc: 0.6681\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9728 - acc: 0.6928 - val_loss: 1.0741 - val_acc: 0.6679\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9720 - acc: 0.6929 - val_loss: 1.0734 - val_acc: 0.6679\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9712 - acc: 0.6929 - val_loss: 1.0731 - val_acc: 0.6685\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9705 - acc: 0.6930 - val_loss: 1.0724 - val_acc: 0.6685\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9697 - acc: 0.6931 - val_loss: 1.0720 - val_acc: 0.6681\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9690 - acc: 0.6931 - val_loss: 1.0713 - val_acc: 0.6687\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9682 - acc: 0.6931 - val_loss: 1.0711 - val_acc: 0.6683\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9675 - acc: 0.6931 - val_loss: 1.0708 - val_acc: 0.6687\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9668 - acc: 0.6932 - val_loss: 1.0702 - val_acc: 0.6679\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.9661 - acc: 0.6932 - val_loss: 1.0697 - val_acc: 0.6687\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9653 - acc: 0.6933 - val_loss: 1.0693 - val_acc: 0.6681\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9646 - acc: 0.6933 - val_loss: 1.0692 - val_acc: 0.6687\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9638 - acc: 0.6934 - val_loss: 1.0678 - val_acc: 0.6686\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9629 - acc: 0.6934 - val_loss: 1.0668 - val_acc: 0.6688\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9616 - acc: 0.6934 - val_loss: 1.0645 - val_acc: 0.6688\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9605 - acc: 0.6935 - val_loss: 1.0632 - val_acc: 0.6685\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9595 - acc: 0.6935 - val_loss: 1.0621 - val_acc: 0.6690\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9586 - acc: 0.6936 - val_loss: 1.0617 - val_acc: 0.6687\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9577 - acc: 0.6937 - val_loss: 1.0608 - val_acc: 0.6688\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.9567 - acc: 0.6936 - val_loss: 1.0594 - val_acc: 0.6694\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9558 - acc: 0.6937 - val_loss: 1.0590 - val_acc: 0.6693\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9550 - acc: 0.6938 - val_loss: 1.0579 - val_acc: 0.6690\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9540 - acc: 0.6939 - val_loss: 1.0572 - val_acc: 0.6692\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 66ms/step - loss: 0.9531 - acc: 0.6939 - val_loss: 1.0561 - val_acc: 0.6690\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.9521 - acc: 0.6940 - val_loss: 1.0553 - val_acc: 0.6691\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9511 - acc: 0.6940 - val_loss: 1.0547 - val_acc: 0.6694\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9501 - acc: 0.6941 - val_loss: 1.0536 - val_acc: 0.6693\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9491 - acc: 0.6941 - val_loss: 1.0526 - val_acc: 0.6693\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9480 - acc: 0.6942 - val_loss: 1.0518 - val_acc: 0.6692\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.9469 - acc: 0.6943 - val_loss: 1.0505 - val_acc: 0.6695\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9459 - acc: 0.6944 - val_loss: 1.0498 - val_acc: 0.6696\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.9449 - acc: 0.6944 - val_loss: 1.0484 - val_acc: 0.6699\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9438 - acc: 0.6945 - val_loss: 1.0480 - val_acc: 0.6693\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9427 - acc: 0.6945 - val_loss: 1.0472 - val_acc: 0.6693\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9417 - acc: 0.6946 - val_loss: 1.0460 - val_acc: 0.6698\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9406 - acc: 0.6947 - val_loss: 1.0453 - val_acc: 0.6696\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.9396 - acc: 0.6948 - val_loss: 1.0450 - val_acc: 0.6695\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9386 - acc: 0.6948 - val_loss: 1.0434 - val_acc: 0.6700\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9376 - acc: 0.6948 - val_loss: 1.0425 - val_acc: 0.6702\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9367 - acc: 0.6948 - val_loss: 1.0419 - val_acc: 0.6700\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9356 - acc: 0.6949 - val_loss: 1.0413 - val_acc: 0.6699\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9345 - acc: 0.6949 - val_loss: 1.0402 - val_acc: 0.6701\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9334 - acc: 0.6953 - val_loss: 1.0395 - val_acc: 0.6704\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9323 - acc: 0.6958 - val_loss: 1.0386 - val_acc: 0.6706\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9312 - acc: 0.6962 - val_loss: 1.0378 - val_acc: 0.6708\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9303 - acc: 0.6967 - val_loss: 1.0367 - val_acc: 0.6717\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9292 - acc: 0.6974 - val_loss: 1.0360 - val_acc: 0.6719\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9282 - acc: 0.6977 - val_loss: 1.0353 - val_acc: 0.6727\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9272 - acc: 0.6989 - val_loss: 1.0339 - val_acc: 0.6734\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.9262 - acc: 0.6994 - val_loss: 1.0337 - val_acc: 0.6745\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9252 - acc: 0.7002 - val_loss: 1.0326 - val_acc: 0.6752\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9241 - acc: 0.7009 - val_loss: 1.0318 - val_acc: 0.6758\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9232 - acc: 0.7019 - val_loss: 1.0312 - val_acc: 0.6760\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9222 - acc: 0.7026 - val_loss: 1.0305 - val_acc: 0.6772\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9212 - acc: 0.7032 - val_loss: 1.0295 - val_acc: 0.6780\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9203 - acc: 0.7044 - val_loss: 1.0290 - val_acc: 0.6786\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9193 - acc: 0.7049 - val_loss: 1.0279 - val_acc: 0.6792\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9184 - acc: 0.7061 - val_loss: 1.0271 - val_acc: 0.6802\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9173 - acc: 0.7064 - val_loss: 1.0263 - val_acc: 0.6812\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.9165 - acc: 0.7076 - val_loss: 1.0257 - val_acc: 0.6810\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9154 - acc: 0.7079 - val_loss: 1.0250 - val_acc: 0.6818\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9144 - acc: 0.7084 - val_loss: 1.0242 - val_acc: 0.6829\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.9135 - acc: 0.7096 - val_loss: 1.0235 - val_acc: 0.6827\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9126 - acc: 0.7100 - val_loss: 1.0228 - val_acc: 0.6839\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9115 - acc: 0.7102 - val_loss: 1.0219 - val_acc: 0.6850\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9105 - acc: 0.7110 - val_loss: 1.0213 - val_acc: 0.6851\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9096 - acc: 0.7113 - val_loss: 1.0202 - val_acc: 0.6851\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9086 - acc: 0.7117 - val_loss: 1.0196 - val_acc: 0.6863\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9075 - acc: 0.7125 - val_loss: 1.0187 - val_acc: 0.6866\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9065 - acc: 0.7130 - val_loss: 1.0184 - val_acc: 0.6870\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9055 - acc: 0.7132 - val_loss: 1.0174 - val_acc: 0.6872\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9045 - acc: 0.7134 - val_loss: 1.0163 - val_acc: 0.6878\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9034 - acc: 0.7141 - val_loss: 1.0160 - val_acc: 0.6885\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.9024 - acc: 0.7144 - val_loss: 1.0152 - val_acc: 0.6883\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9013 - acc: 0.7150 - val_loss: 1.0142 - val_acc: 0.6888\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9002 - acc: 0.7157 - val_loss: 1.0138 - val_acc: 0.6888\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8992 - acc: 0.7166 - val_loss: 1.0133 - val_acc: 0.6891\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8983 - acc: 0.7167 - val_loss: 1.0122 - val_acc: 0.6895\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8972 - acc: 0.7171 - val_loss: 1.0111 - val_acc: 0.6898\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8963 - acc: 0.7170 - val_loss: 1.0108 - val_acc: 0.6901\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8953 - acc: 0.7177 - val_loss: 1.0099 - val_acc: 0.6898\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8943 - acc: 0.7181 - val_loss: 1.0092 - val_acc: 0.6900\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8932 - acc: 0.7186 - val_loss: 1.0084 - val_acc: 0.6903\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8921 - acc: 0.7192 - val_loss: 1.0075 - val_acc: 0.6905\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8910 - acc: 0.7195 - val_loss: 1.0068 - val_acc: 0.6904\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8900 - acc: 0.7195 - val_loss: 1.0055 - val_acc: 0.6912\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8888 - acc: 0.7202 - val_loss: 1.0048 - val_acc: 0.6910\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8877 - acc: 0.7210 - val_loss: 1.0037 - val_acc: 0.6915\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8864 - acc: 0.7214 - val_loss: 1.0026 - val_acc: 0.6919\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.8853 - acc: 0.7224 - val_loss: 1.0020 - val_acc: 0.6923\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8840 - acc: 0.7228 - val_loss: 1.0005 - val_acc: 0.6926\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8827 - acc: 0.7235 - val_loss: 0.9993 - val_acc: 0.6934\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8814 - acc: 0.7240 - val_loss: 0.9981 - val_acc: 0.6939\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8800 - acc: 0.7246 - val_loss: 0.9975 - val_acc: 0.6936\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8786 - acc: 0.7252 - val_loss: 0.9960 - val_acc: 0.6942\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8770 - acc: 0.7264 - val_loss: 0.9952 - val_acc: 0.6943\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8754 - acc: 0.7271 - val_loss: 0.9941 - val_acc: 0.6950\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8739 - acc: 0.7277 - val_loss: 0.9931 - val_acc: 0.6952\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8724 - acc: 0.7282 - val_loss: 0.9921 - val_acc: 0.6958\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.8711 - acc: 0.7287 - val_loss: 0.9904 - val_acc: 0.6960\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8695 - acc: 0.7294 - val_loss: 0.9898 - val_acc: 0.6961\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8679 - acc: 0.7301 - val_loss: 0.9888 - val_acc: 0.6962\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8664 - acc: 0.7307 - val_loss: 0.9876 - val_acc: 0.6969\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8649 - acc: 0.7312 - val_loss: 0.9865 - val_acc: 0.6973\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8632 - acc: 0.7320 - val_loss: 0.9853 - val_acc: 0.6979\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.8617 - acc: 0.7325 - val_loss: 0.9842 - val_acc: 0.6982\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8603 - acc: 0.7327 - val_loss: 0.9830 - val_acc: 0.6987\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8590 - acc: 0.7330 - val_loss: 0.9822 - val_acc: 0.6993\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8576 - acc: 0.7336 - val_loss: 0.9808 - val_acc: 0.6995\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.8562 - acc: 0.7338 - val_loss: 0.9799 - val_acc: 0.7000\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.8547 - acc: 0.7344 - val_loss: 0.9795 - val_acc: 0.7000\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8533 - acc: 0.7352 - val_loss: 0.9780 - val_acc: 0.7007\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8519 - acc: 0.7354 - val_loss: 0.9769 - val_acc: 0.7008\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.8506 - acc: 0.7357 - val_loss: 0.9767 - val_acc: 0.7008\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.8493 - acc: 0.7365 - val_loss: 0.9754 - val_acc: 0.7017\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.8479 - acc: 0.7366 - val_loss: 0.9750 - val_acc: 0.7013\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.8467 - acc: 0.7374 - val_loss: 0.9739 - val_acc: 0.7017\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.8454 - acc: 0.7376 - val_loss: 0.9733 - val_acc: 0.7020\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.8442 - acc: 0.7377 - val_loss: 0.9726 - val_acc: 0.7022\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8429 - acc: 0.7384 - val_loss: 0.9717 - val_acc: 0.7026\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8416 - acc: 0.7390 - val_loss: 0.9707 - val_acc: 0.7028\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8403 - acc: 0.7391 - val_loss: 0.9701 - val_acc: 0.7033\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.8392 - acc: 0.7393 - val_loss: 0.9690 - val_acc: 0.7037\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.8380 - acc: 0.7399 - val_loss: 0.9686 - val_acc: 0.7037\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.8368 - acc: 0.7400 - val_loss: 0.9679 - val_acc: 0.7043\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8356 - acc: 0.7404 - val_loss: 0.9671 - val_acc: 0.7040\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8344 - acc: 0.7406 - val_loss: 0.9664 - val_acc: 0.7044\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.8332 - acc: 0.7410 - val_loss: 0.9657 - val_acc: 0.7044\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8321 - acc: 0.7410 - val_loss: 0.9659 - val_acc: 0.7045\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.8310 - acc: 0.7414 - val_loss: 0.9645 - val_acc: 0.7046\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8299 - acc: 0.7417 - val_loss: 0.9638 - val_acc: 0.7049\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.8287 - acc: 0.7419 - val_loss: 0.9635 - val_acc: 0.7049\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8276 - acc: 0.7418 - val_loss: 0.9634 - val_acc: 0.7049\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8266 - acc: 0.7420 - val_loss: 0.9623 - val_acc: 0.7049\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8256 - acc: 0.7421 - val_loss: 0.9622 - val_acc: 0.7051\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8245 - acc: 0.7425 - val_loss: 0.9617 - val_acc: 0.7045\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8235 - acc: 0.7428 - val_loss: 0.9613 - val_acc: 0.7046\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8225 - acc: 0.7424 - val_loss: 0.9610 - val_acc: 0.7048\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8215 - acc: 0.7429 - val_loss: 0.9600 - val_acc: 0.7049\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8204 - acc: 0.7432 - val_loss: 0.9596 - val_acc: 0.7050\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8194 - acc: 0.7428 - val_loss: 0.9601 - val_acc: 0.7045\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8184 - acc: 0.7432 - val_loss: 0.9591 - val_acc: 0.7049\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8174 - acc: 0.7433 - val_loss: 0.9584 - val_acc: 0.7046\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8165 - acc: 0.7433 - val_loss: 0.9588 - val_acc: 0.7045\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8156 - acc: 0.7436 - val_loss: 0.9580 - val_acc: 0.7045\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8146 - acc: 0.7441 - val_loss: 0.9573 - val_acc: 0.7044\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8136 - acc: 0.7437 - val_loss: 0.9571 - val_acc: 0.7042\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8127 - acc: 0.7437 - val_loss: 0.9577 - val_acc: 0.7040\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8118 - acc: 0.7439 - val_loss: 0.9566 - val_acc: 0.7039\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8109 - acc: 0.7440 - val_loss: 0.9563 - val_acc: 0.7043\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8100 - acc: 0.7440 - val_loss: 0.9560 - val_acc: 0.7042\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8092 - acc: 0.7439 - val_loss: 0.9560 - val_acc: 0.7040\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8083 - acc: 0.7443 - val_loss: 0.9557 - val_acc: 0.7043\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8074 - acc: 0.7441 - val_loss: 0.9549 - val_acc: 0.7041\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8065 - acc: 0.7442 - val_loss: 0.9554 - val_acc: 0.7037\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8056 - acc: 0.7443 - val_loss: 0.9546 - val_acc: 0.7041\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8047 - acc: 0.7448 - val_loss: 0.9541 - val_acc: 0.7041\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8038 - acc: 0.7448 - val_loss: 0.9531 - val_acc: 0.7037\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8030 - acc: 0.7450 - val_loss: 0.9532 - val_acc: 0.7038\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8023 - acc: 0.7450 - val_loss: 0.9532 - val_acc: 0.7036\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8015 - acc: 0.7448 - val_loss: 0.9530 - val_acc: 0.7039\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8006 - acc: 0.7451 - val_loss: 0.9527 - val_acc: 0.7039\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7998 - acc: 0.7453 - val_loss: 0.9515 - val_acc: 0.7041\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7990 - acc: 0.7455 - val_loss: 0.9520 - val_acc: 0.7040\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7982 - acc: 0.7455 - val_loss: 0.9515 - val_acc: 0.7042\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7975 - acc: 0.7452 - val_loss: 0.9509 - val_acc: 0.7042\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7967 - acc: 0.7454 - val_loss: 0.9505 - val_acc: 0.7041\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7958 - acc: 0.7452 - val_loss: 0.9508 - val_acc: 0.7042\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7952 - acc: 0.7459 - val_loss: 0.9503 - val_acc: 0.7040\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.7945 - acc: 0.7456 - val_loss: 0.9503 - val_acc: 0.7038\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7937 - acc: 0.7456 - val_loss: 0.9495 - val_acc: 0.7040\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7929 - acc: 0.7460 - val_loss: 0.9497 - val_acc: 0.7037\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7921 - acc: 0.7462 - val_loss: 0.9494 - val_acc: 0.7035\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7914 - acc: 0.7461 - val_loss: 0.9492 - val_acc: 0.7036\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7906 - acc: 0.7460 - val_loss: 0.9492 - val_acc: 0.7034\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7898 - acc: 0.7462 - val_loss: 0.9489 - val_acc: 0.7036\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7891 - acc: 0.7461 - val_loss: 0.9482 - val_acc: 0.7035\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7884 - acc: 0.7461 - val_loss: 0.9480 - val_acc: 0.7038\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7877 - acc: 0.7461 - val_loss: 0.9483 - val_acc: 0.7034\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.7870 - acc: 0.7463 - val_loss: 0.9483 - val_acc: 0.7039\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7862 - acc: 0.7463 - val_loss: 0.9474 - val_acc: 0.7038\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7855 - acc: 0.7463 - val_loss: 0.9477 - val_acc: 0.7035\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7848 - acc: 0.7467 - val_loss: 0.9471 - val_acc: 0.7034\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7840 - acc: 0.7468 - val_loss: 0.9471 - val_acc: 0.7037\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7833 - acc: 0.7467 - val_loss: 0.9468 - val_acc: 0.7039\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7826 - acc: 0.7468 - val_loss: 0.9464 - val_acc: 0.7037\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7819 - acc: 0.7471 - val_loss: 0.9463 - val_acc: 0.7038\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7811 - acc: 0.7471 - val_loss: 0.9456 - val_acc: 0.7039\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7805 - acc: 0.7473 - val_loss: 0.9455 - val_acc: 0.7038\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7798 - acc: 0.7472 - val_loss: 0.9458 - val_acc: 0.7041\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7791 - acc: 0.7473 - val_loss: 0.9449 - val_acc: 0.7034\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7784 - acc: 0.7475 - val_loss: 0.9447 - val_acc: 0.7037\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7777 - acc: 0.7473 - val_loss: 0.9453 - val_acc: 0.7036\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7771 - acc: 0.7476 - val_loss: 0.9445 - val_acc: 0.7040\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7763 - acc: 0.7475 - val_loss: 0.9449 - val_acc: 0.7038\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7758 - acc: 0.7472 - val_loss: 0.9441 - val_acc: 0.7040\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7749 - acc: 0.7475 - val_loss: 0.9434 - val_acc: 0.7038\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7742 - acc: 0.7475 - val_loss: 0.9434 - val_acc: 0.7039\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7735 - acc: 0.7476 - val_loss: 0.9435 - val_acc: 0.7040\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7728 - acc: 0.7480 - val_loss: 0.9434 - val_acc: 0.7039\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7721 - acc: 0.7477 - val_loss: 0.9433 - val_acc: 0.7039\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7715 - acc: 0.7478 - val_loss: 0.9428 - val_acc: 0.7041\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7708 - acc: 0.7479 - val_loss: 0.9429 - val_acc: 0.7043\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7703 - acc: 0.7482 - val_loss: 0.9419 - val_acc: 0.7040\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.7697 - acc: 0.7481 - val_loss: 0.9425 - val_acc: 0.7040\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7690 - acc: 0.7480 - val_loss: 0.9426 - val_acc: 0.7041\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7685 - acc: 0.7481 - val_loss: 0.9417 - val_acc: 0.7044\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.7677 - acc: 0.7483 - val_loss: 0.9419 - val_acc: 0.7042\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7671 - acc: 0.7485 - val_loss: 0.9412 - val_acc: 0.7045\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7665 - acc: 0.7483 - val_loss: 0.9411 - val_acc: 0.7046\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7658 - acc: 0.7483 - val_loss: 0.9416 - val_acc: 0.7042\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7652 - acc: 0.7483 - val_loss: 0.9410 - val_acc: 0.7042\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7646 - acc: 0.7484 - val_loss: 0.9404 - val_acc: 0.7041\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7640 - acc: 0.7481 - val_loss: 0.9404 - val_acc: 0.7038\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7634 - acc: 0.7482 - val_loss: 0.9412 - val_acc: 0.7039\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7628 - acc: 0.7483 - val_loss: 0.9403 - val_acc: 0.7038\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7621 - acc: 0.7484 - val_loss: 0.9399 - val_acc: 0.7038\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7616 - acc: 0.7484 - val_loss: 0.9401 - val_acc: 0.7041\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7610 - acc: 0.7486 - val_loss: 0.9398 - val_acc: 0.7040\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7604 - acc: 0.7485 - val_loss: 0.9397 - val_acc: 0.7035\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7598 - acc: 0.7486 - val_loss: 0.9391 - val_acc: 0.7035\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7592 - acc: 0.7488 - val_loss: 0.9394 - val_acc: 0.7037\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7585 - acc: 0.7488 - val_loss: 0.9394 - val_acc: 0.7036\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7579 - acc: 0.7488 - val_loss: 0.9386 - val_acc: 0.7039\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7572 - acc: 0.7491 - val_loss: 0.9391 - val_acc: 0.7035\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7566 - acc: 0.7487 - val_loss: 0.9390 - val_acc: 0.7038\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7560 - acc: 0.7491 - val_loss: 0.9385 - val_acc: 0.7038\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7554 - acc: 0.7490 - val_loss: 0.9386 - val_acc: 0.7033\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7548 - acc: 0.7490 - val_loss: 0.9395 - val_acc: 0.7033\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7543 - acc: 0.7489 - val_loss: 0.9381 - val_acc: 0.7038\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.7538 - acc: 0.7491 - val_loss: 0.9383 - val_acc: 0.7033\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7531 - acc: 0.7491 - val_loss: 0.9383 - val_acc: 0.7036\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7526 - acc: 0.7490 - val_loss: 0.9385 - val_acc: 0.7037\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7521 - acc: 0.7492 - val_loss: 0.9381 - val_acc: 0.7034\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7515 - acc: 0.7492 - val_loss: 0.9385 - val_acc: 0.7037\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7508 - acc: 0.7492 - val_loss: 0.9384 - val_acc: 0.7032\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7502 - acc: 0.7495 - val_loss: 0.9376 - val_acc: 0.7035\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7497 - acc: 0.7495 - val_loss: 0.9370 - val_acc: 0.7037\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7491 - acc: 0.7496 - val_loss: 0.9373 - val_acc: 0.7034\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7484 - acc: 0.7496 - val_loss: 0.9369 - val_acc: 0.7031\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7478 - acc: 0.7499 - val_loss: 0.9367 - val_acc: 0.7033\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7472 - acc: 0.7498 - val_loss: 0.9366 - val_acc: 0.7036\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7467 - acc: 0.7496 - val_loss: 0.9369 - val_acc: 0.7035\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7461 - acc: 0.7498 - val_loss: 0.9368 - val_acc: 0.7033\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7456 - acc: 0.7499 - val_loss: 0.9361 - val_acc: 0.7036\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7450 - acc: 0.7497 - val_loss: 0.9364 - val_acc: 0.7030\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7444 - acc: 0.7498 - val_loss: 0.9361 - val_acc: 0.7028\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7439 - acc: 0.7499 - val_loss: 0.9354 - val_acc: 0.7032\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7433 - acc: 0.7499 - val_loss: 0.9362 - val_acc: 0.7032\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7429 - acc: 0.7498 - val_loss: 0.9361 - val_acc: 0.7031\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.7422 - acc: 0.7498 - val_loss: 0.9359 - val_acc: 0.7028\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7417 - acc: 0.7497 - val_loss: 0.9356 - val_acc: 0.7028\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7411 - acc: 0.7498 - val_loss: 0.9354 - val_acc: 0.7030\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7405 - acc: 0.7498 - val_loss: 0.9354 - val_acc: 0.7029\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7399 - acc: 0.7498 - val_loss: 0.9347 - val_acc: 0.7025\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7395 - acc: 0.7500 - val_loss: 0.9346 - val_acc: 0.7026\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7389 - acc: 0.7500 - val_loss: 0.9353 - val_acc: 0.7025\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7383 - acc: 0.7498 - val_loss: 0.9350 - val_acc: 0.7023\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7378 - acc: 0.7499 - val_loss: 0.9347 - val_acc: 0.7027\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7372 - acc: 0.7502 - val_loss: 0.9347 - val_acc: 0.7025\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7366 - acc: 0.7500 - val_loss: 0.9344 - val_acc: 0.7027\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7359 - acc: 0.7500 - val_loss: 0.9343 - val_acc: 0.7022\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7353 - acc: 0.7501 - val_loss: 0.9343 - val_acc: 0.7023\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7348 - acc: 0.7501 - val_loss: 0.9333 - val_acc: 0.7020\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7342 - acc: 0.7502 - val_loss: 0.9338 - val_acc: 0.7022\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7336 - acc: 0.7501 - val_loss: 0.9341 - val_acc: 0.7021\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7330 - acc: 0.7503 - val_loss: 0.9329 - val_acc: 0.7021\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7325 - acc: 0.7504 - val_loss: 0.9336 - val_acc: 0.7020\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7319 - acc: 0.7502 - val_loss: 0.9328 - val_acc: 0.7020\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7314 - acc: 0.7503 - val_loss: 0.9323 - val_acc: 0.7018\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.7309 - acc: 0.7504 - val_loss: 0.9325 - val_acc: 0.7019\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7303 - acc: 0.7505 - val_loss: 0.9319 - val_acc: 0.7020\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7299 - acc: 0.7506 - val_loss: 0.9324 - val_acc: 0.7020\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7292 - acc: 0.7505 - val_loss: 0.9317 - val_acc: 0.7021\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7285 - acc: 0.7505 - val_loss: 0.9314 - val_acc: 0.7017\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7280 - acc: 0.7505 - val_loss: 0.9314 - val_acc: 0.7013\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7274 - acc: 0.7507 - val_loss: 0.9304 - val_acc: 0.7020\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7269 - acc: 0.7507 - val_loss: 0.9302 - val_acc: 0.7016\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7262 - acc: 0.7509 - val_loss: 0.9310 - val_acc: 0.7014\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7257 - acc: 0.7509 - val_loss: 0.9301 - val_acc: 0.7018\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7251 - acc: 0.7508 - val_loss: 0.9296 - val_acc: 0.7016\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7244 - acc: 0.7508 - val_loss: 0.9290 - val_acc: 0.7016\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7239 - acc: 0.7509 - val_loss: 0.9289 - val_acc: 0.7012\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7233 - acc: 0.7510 - val_loss: 0.9290 - val_acc: 0.7012\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7226 - acc: 0.7509 - val_loss: 0.9285 - val_acc: 0.7016\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7220 - acc: 0.7510 - val_loss: 0.9283 - val_acc: 0.7011\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7214 - acc: 0.7510 - val_loss: 0.9281 - val_acc: 0.7016\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7208 - acc: 0.7511 - val_loss: 0.9276 - val_acc: 0.7010\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7202 - acc: 0.7510 - val_loss: 0.9273 - val_acc: 0.7010\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7196 - acc: 0.7512 - val_loss: 0.9266 - val_acc: 0.7010\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7190 - acc: 0.7511 - val_loss: 0.9269 - val_acc: 0.7008\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7184 - acc: 0.7513 - val_loss: 0.9265 - val_acc: 0.7007\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.7177 - acc: 0.7514 - val_loss: 0.9262 - val_acc: 0.7006\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7170 - acc: 0.7513 - val_loss: 0.9252 - val_acc: 0.7006\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7164 - acc: 0.7514 - val_loss: 0.9249 - val_acc: 0.7009\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7158 - acc: 0.7512 - val_loss: 0.9245 - val_acc: 0.7007\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7151 - acc: 0.7514 - val_loss: 0.9241 - val_acc: 0.7002\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7144 - acc: 0.7513 - val_loss: 0.9240 - val_acc: 0.7006\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7138 - acc: 0.7516 - val_loss: 0.9230 - val_acc: 0.7001\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7131 - acc: 0.7518 - val_loss: 0.9230 - val_acc: 0.6999\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.7125 - acc: 0.7515 - val_loss: 0.9225 - val_acc: 0.7001\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7117 - acc: 0.7517 - val_loss: 0.9225 - val_acc: 0.6996\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7110 - acc: 0.7517 - val_loss: 0.9217 - val_acc: 0.7001\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7104 - acc: 0.7517 - val_loss: 0.9213 - val_acc: 0.7003\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7096 - acc: 0.7518 - val_loss: 0.9211 - val_acc: 0.6994\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7089 - acc: 0.7519 - val_loss: 0.9200 - val_acc: 0.6999\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7082 - acc: 0.7523 - val_loss: 0.9199 - val_acc: 0.7001\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7075 - acc: 0.7524 - val_loss: 0.9199 - val_acc: 0.6997\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7067 - acc: 0.7524 - val_loss: 0.9194 - val_acc: 0.6995\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7061 - acc: 0.7524 - val_loss: 0.9183 - val_acc: 0.6995\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.7052 - acc: 0.7525 - val_loss: 0.9181 - val_acc: 0.6995\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7044 - acc: 0.7522 - val_loss: 0.9175 - val_acc: 0.6995\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7037 - acc: 0.7527 - val_loss: 0.9180 - val_acc: 0.6992\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7030 - acc: 0.7529 - val_loss: 0.9166 - val_acc: 0.6999\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7022 - acc: 0.7529 - val_loss: 0.9166 - val_acc: 0.6994\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7015 - acc: 0.7533 - val_loss: 0.9156 - val_acc: 0.6995\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7008 - acc: 0.7530 - val_loss: 0.9148 - val_acc: 0.6990\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7000 - acc: 0.7532 - val_loss: 0.9139 - val_acc: 0.6997\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6993 - acc: 0.7531 - val_loss: 0.9140 - val_acc: 0.6998\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6986 - acc: 0.7538 - val_loss: 0.9135 - val_acc: 0.6989\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6978 - acc: 0.7536 - val_loss: 0.9125 - val_acc: 0.6991\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.6969 - acc: 0.7535 - val_loss: 0.9118 - val_acc: 0.6995\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6959 - acc: 0.7535 - val_loss: 0.9115 - val_acc: 0.6995\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6952 - acc: 0.7540 - val_loss: 0.9104 - val_acc: 0.6993\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6943 - acc: 0.7536 - val_loss: 0.9107 - val_acc: 0.6995\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6934 - acc: 0.7540 - val_loss: 0.9086 - val_acc: 0.6994\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6924 - acc: 0.7538 - val_loss: 0.9081 - val_acc: 0.7000\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6915 - acc: 0.7544 - val_loss: 0.9071 - val_acc: 0.6997\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6904 - acc: 0.7548 - val_loss: 0.9070 - val_acc: 0.6994\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6894 - acc: 0.7542 - val_loss: 0.9065 - val_acc: 0.6995\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6885 - acc: 0.7547 - val_loss: 0.9058 - val_acc: 0.6992\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.6877 - acc: 0.7546 - val_loss: 0.9057 - val_acc: 0.6996\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6868 - acc: 0.7550 - val_loss: 0.9050 - val_acc: 0.6990\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6858 - acc: 0.7553 - val_loss: 0.9046 - val_acc: 0.6986\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6850 - acc: 0.7547 - val_loss: 0.9035 - val_acc: 0.6987\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6840 - acc: 0.7551 - val_loss: 0.9028 - val_acc: 0.6990\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6833 - acc: 0.7553 - val_loss: 0.9022 - val_acc: 0.6986\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6822 - acc: 0.7555 - val_loss: 0.9017 - val_acc: 0.6995\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6814 - acc: 0.7555 - val_loss: 0.9007 - val_acc: 0.6990\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6805 - acc: 0.7558 - val_loss: 0.9004 - val_acc: 0.6990\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6795 - acc: 0.7562 - val_loss: 0.8999 - val_acc: 0.6989\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6787 - acc: 0.7563 - val_loss: 0.8993 - val_acc: 0.6990\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6778 - acc: 0.7558 - val_loss: 0.8991 - val_acc: 0.6994\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6767 - acc: 0.7563 - val_loss: 0.8976 - val_acc: 0.6990\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6757 - acc: 0.7560 - val_loss: 0.8980 - val_acc: 0.6988\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6749 - acc: 0.7564 - val_loss: 0.8967 - val_acc: 0.6990\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6740 - acc: 0.7565 - val_loss: 0.8965 - val_acc: 0.6985\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6730 - acc: 0.7567 - val_loss: 0.8965 - val_acc: 0.6981\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6724 - acc: 0.7566 - val_loss: 0.8947 - val_acc: 0.6995\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6716 - acc: 0.7572 - val_loss: 0.8947 - val_acc: 0.7008\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6707 - acc: 0.7605 - val_loss: 0.8944 - val_acc: 0.7032\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.6695 - acc: 0.7636 - val_loss: 0.8940 - val_acc: 0.7056\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6687 - acc: 0.7653 - val_loss: 0.8936 - val_acc: 0.7064\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6678 - acc: 0.7671 - val_loss: 0.8927 - val_acc: 0.7075\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6668 - acc: 0.7682 - val_loss: 0.8926 - val_acc: 0.7084\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6660 - acc: 0.7694 - val_loss: 0.8922 - val_acc: 0.7095\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6651 - acc: 0.7705 - val_loss: 0.8911 - val_acc: 0.7091\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6644 - acc: 0.7717 - val_loss: 0.8908 - val_acc: 0.7102\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6636 - acc: 0.7726 - val_loss: 0.8906 - val_acc: 0.7113\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6627 - acc: 0.7735 - val_loss: 0.8896 - val_acc: 0.7119\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6618 - acc: 0.7742 - val_loss: 0.8891 - val_acc: 0.7119\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6608 - acc: 0.7746 - val_loss: 0.8894 - val_acc: 0.7117\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6599 - acc: 0.7754 - val_loss: 0.8889 - val_acc: 0.7121\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6591 - acc: 0.7761 - val_loss: 0.8886 - val_acc: 0.7126\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6583 - acc: 0.7765 - val_loss: 0.8882 - val_acc: 0.7127\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6574 - acc: 0.7768 - val_loss: 0.8874 - val_acc: 0.7138\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6566 - acc: 0.7782 - val_loss: 0.8875 - val_acc: 0.7134\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6560 - acc: 0.7779 - val_loss: 0.8871 - val_acc: 0.7133\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6551 - acc: 0.7785 - val_loss: 0.8869 - val_acc: 0.7124\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6544 - acc: 0.7789 - val_loss: 0.8862 - val_acc: 0.7143\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6536 - acc: 0.7798 - val_loss: 0.8854 - val_acc: 0.7143\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6527 - acc: 0.7800 - val_loss: 0.8855 - val_acc: 0.7140\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6519 - acc: 0.7799 - val_loss: 0.8857 - val_acc: 0.7146\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6511 - acc: 0.7808 - val_loss: 0.8852 - val_acc: 0.7141\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6503 - acc: 0.7810 - val_loss: 0.8845 - val_acc: 0.7148\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6494 - acc: 0.7814 - val_loss: 0.8844 - val_acc: 0.7152\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6486 - acc: 0.7821 - val_loss: 0.8843 - val_acc: 0.7151\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6479 - acc: 0.7824 - val_loss: 0.8838 - val_acc: 0.7147\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6471 - acc: 0.7820 - val_loss: 0.8836 - val_acc: 0.7150\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6464 - acc: 0.7831 - val_loss: 0.8835 - val_acc: 0.7161\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6457 - acc: 0.7836 - val_loss: 0.8827 - val_acc: 0.7154\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6449 - acc: 0.7832 - val_loss: 0.8834 - val_acc: 0.7154\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6441 - acc: 0.7840 - val_loss: 0.8821 - val_acc: 0.7159\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6434 - acc: 0.7837 - val_loss: 0.8823 - val_acc: 0.7149\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6427 - acc: 0.7844 - val_loss: 0.8819 - val_acc: 0.7157\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6420 - acc: 0.7844 - val_loss: 0.8815 - val_acc: 0.7163\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6415 - acc: 0.7852 - val_loss: 0.8820 - val_acc: 0.7147\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6408 - acc: 0.7850 - val_loss: 0.8815 - val_acc: 0.7153\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6400 - acc: 0.7851 - val_loss: 0.8810 - val_acc: 0.7158\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6392 - acc: 0.7856 - val_loss: 0.8812 - val_acc: 0.7170\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6386 - acc: 0.7860 - val_loss: 0.8803 - val_acc: 0.7155\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.6377 - acc: 0.7860 - val_loss: 0.8810 - val_acc: 0.7157\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6372 - acc: 0.7862 - val_loss: 0.8804 - val_acc: 0.7148\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6365 - acc: 0.7869 - val_loss: 0.8811 - val_acc: 0.7156\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6365 - acc: 0.7865 - val_loss: 0.8798 - val_acc: 0.7164\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6354 - acc: 0.7870 - val_loss: 0.8793 - val_acc: 0.7164\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6345 - acc: 0.7880 - val_loss: 0.8795 - val_acc: 0.7170\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6337 - acc: 0.7874 - val_loss: 0.8791 - val_acc: 0.7168\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6329 - acc: 0.7882 - val_loss: 0.8789 - val_acc: 0.7159\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6325 - acc: 0.7882 - val_loss: 0.8785 - val_acc: 0.7170\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6318 - acc: 0.7883 - val_loss: 0.8789 - val_acc: 0.7169\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6310 - acc: 0.7884 - val_loss: 0.8790 - val_acc: 0.7172\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6302 - acc: 0.7888 - val_loss: 0.8781 - val_acc: 0.7168\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6295 - acc: 0.7887 - val_loss: 0.8785 - val_acc: 0.7178\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6289 - acc: 0.7893 - val_loss: 0.8782 - val_acc: 0.7168\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6282 - acc: 0.7895 - val_loss: 0.8777 - val_acc: 0.7163\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6276 - acc: 0.7894 - val_loss: 0.8783 - val_acc: 0.7163\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6270 - acc: 0.7899 - val_loss: 0.8773 - val_acc: 0.7160\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6261 - acc: 0.7902 - val_loss: 0.8777 - val_acc: 0.7170\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6256 - acc: 0.7905 - val_loss: 0.8778 - val_acc: 0.7154\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6250 - acc: 0.7912 - val_loss: 0.8774 - val_acc: 0.7164\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6243 - acc: 0.7907 - val_loss: 0.8770 - val_acc: 0.7165\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.6237 - acc: 0.7907 - val_loss: 0.8775 - val_acc: 0.7162\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6229 - acc: 0.7915 - val_loss: 0.8769 - val_acc: 0.7177\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6223 - acc: 0.7916 - val_loss: 0.8768 - val_acc: 0.7169\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6217 - acc: 0.7912 - val_loss: 0.8767 - val_acc: 0.7169\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6211 - acc: 0.7917 - val_loss: 0.8766 - val_acc: 0.7170\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6205 - acc: 0.7919 - val_loss: 0.8762 - val_acc: 0.7167\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6199 - acc: 0.7922 - val_loss: 0.8762 - val_acc: 0.7171\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6192 - acc: 0.7922 - val_loss: 0.8761 - val_acc: 0.7179\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6187 - acc: 0.7923 - val_loss: 0.8762 - val_acc: 0.7174\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6181 - acc: 0.7928 - val_loss: 0.8758 - val_acc: 0.7174\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6174 - acc: 0.7921 - val_loss: 0.8759 - val_acc: 0.7176\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6168 - acc: 0.7933 - val_loss: 0.8760 - val_acc: 0.7172\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6161 - acc: 0.7935 - val_loss: 0.8762 - val_acc: 0.7168\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6156 - acc: 0.7934 - val_loss: 0.8758 - val_acc: 0.7165\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6151 - acc: 0.7934 - val_loss: 0.8755 - val_acc: 0.7173\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6144 - acc: 0.7939 - val_loss: 0.8758 - val_acc: 0.7176\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6139 - acc: 0.7936 - val_loss: 0.8756 - val_acc: 0.7175\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6135 - acc: 0.7939 - val_loss: 0.8762 - val_acc: 0.7165\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6129 - acc: 0.7939 - val_loss: 0.8755 - val_acc: 0.7164\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6123 - acc: 0.7942 - val_loss: 0.8752 - val_acc: 0.7170\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.6117 - acc: 0.7941 - val_loss: 0.8754 - val_acc: 0.7175\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6110 - acc: 0.7947 - val_loss: 0.8758 - val_acc: 0.7172\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6105 - acc: 0.7945 - val_loss: 0.8753 - val_acc: 0.7171\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6100 - acc: 0.7948 - val_loss: 0.8755 - val_acc: 0.7177\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6093 - acc: 0.7951 - val_loss: 0.8749 - val_acc: 0.7175\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6088 - acc: 0.7950 - val_loss: 0.8754 - val_acc: 0.7177\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6082 - acc: 0.7953 - val_loss: 0.8753 - val_acc: 0.7174\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6077 - acc: 0.7954 - val_loss: 0.8754 - val_acc: 0.7176\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6072 - acc: 0.7955 - val_loss: 0.8758 - val_acc: 0.7172\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6067 - acc: 0.7956 - val_loss: 0.8753 - val_acc: 0.7175\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6060 - acc: 0.7957 - val_loss: 0.8751 - val_acc: 0.7175\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6055 - acc: 0.7958 - val_loss: 0.8755 - val_acc: 0.7177\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6050 - acc: 0.7958 - val_loss: 0.8753 - val_acc: 0.7173\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6045 - acc: 0.7958 - val_loss: 0.8755 - val_acc: 0.7176\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6039 - acc: 0.7960 - val_loss: 0.8757 - val_acc: 0.7178\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6035 - acc: 0.7960 - val_loss: 0.8757 - val_acc: 0.7176\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6029 - acc: 0.7962 - val_loss: 0.8758 - val_acc: 0.7175\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6024 - acc: 0.7960 - val_loss: 0.8756 - val_acc: 0.7181\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6019 - acc: 0.7966 - val_loss: 0.8750 - val_acc: 0.7174\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6014 - acc: 0.7965 - val_loss: 0.8756 - val_acc: 0.7176\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.6009 - acc: 0.7969 - val_loss: 0.8755 - val_acc: 0.7174\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6004 - acc: 0.7968 - val_loss: 0.8756 - val_acc: 0.7171\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6000 - acc: 0.7970 - val_loss: 0.8760 - val_acc: 0.7170\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5994 - acc: 0.7970 - val_loss: 0.8756 - val_acc: 0.7174\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5989 - acc: 0.7972 - val_loss: 0.8755 - val_acc: 0.7179\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5985 - acc: 0.7973 - val_loss: 0.8760 - val_acc: 0.7174\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5980 - acc: 0.7975 - val_loss: 0.8760 - val_acc: 0.7178\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5975 - acc: 0.7977 - val_loss: 0.8762 - val_acc: 0.7175\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5970 - acc: 0.7975 - val_loss: 0.8759 - val_acc: 0.7174\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5966 - acc: 0.7976 - val_loss: 0.8758 - val_acc: 0.7174\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5961 - acc: 0.7973 - val_loss: 0.8758 - val_acc: 0.7175\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5955 - acc: 0.7978 - val_loss: 0.8761 - val_acc: 0.7172\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5950 - acc: 0.7977 - val_loss: 0.8766 - val_acc: 0.7174\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5945 - acc: 0.7980 - val_loss: 0.8766 - val_acc: 0.7173\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5942 - acc: 0.7977 - val_loss: 0.8762 - val_acc: 0.7167\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5938 - acc: 0.7979 - val_loss: 0.8768 - val_acc: 0.7176\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5933 - acc: 0.7981 - val_loss: 0.8768 - val_acc: 0.7171\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5927 - acc: 0.7985 - val_loss: 0.8770 - val_acc: 0.7171\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5922 - acc: 0.7984 - val_loss: 0.8763 - val_acc: 0.7171\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5917 - acc: 0.7985 - val_loss: 0.8773 - val_acc: 0.7172\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.5911 - acc: 0.7987 - val_loss: 0.8779 - val_acc: 0.7172\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5907 - acc: 0.7987 - val_loss: 0.8776 - val_acc: 0.7172\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5902 - acc: 0.7987 - val_loss: 0.8773 - val_acc: 0.7167\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.5899 - acc: 0.7989 - val_loss: 0.8776 - val_acc: 0.7171\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5894 - acc: 0.7987 - val_loss: 0.8775 - val_acc: 0.7169\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5890 - acc: 0.7987 - val_loss: 0.8784 - val_acc: 0.7169\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5886 - acc: 0.7987 - val_loss: 0.8773 - val_acc: 0.7165\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5881 - acc: 0.7991 - val_loss: 0.8779 - val_acc: 0.7174\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.5876 - acc: 0.7989 - val_loss: 0.8780 - val_acc: 0.7167\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5871 - acc: 0.7993 - val_loss: 0.8779 - val_acc: 0.7171\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5867 - acc: 0.7994 - val_loss: 0.8782 - val_acc: 0.7169\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5864 - acc: 0.7992 - val_loss: 0.8779 - val_acc: 0.7171\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5859 - acc: 0.7989 - val_loss: 0.8788 - val_acc: 0.7170\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5854 - acc: 0.7995 - val_loss: 0.8783 - val_acc: 0.7171\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5849 - acc: 0.7997 - val_loss: 0.8785 - val_acc: 0.7171\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from models import additionalDense\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-3)\n",
        "\n",
        "checkpoint_path = os.path.join(weights_folder, \"additionalDense\", \"checkpoint.hdf5\")\n",
        "history_path = os.path.join(weights_folder, \"additionalDense\", \"history.npy\")\n",
        "\n",
        "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
        "hist_callback = MyHistory(history_path)\n",
        "\n",
        "model = additionalDense(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "model.compile(**compile_args, optimizer=optimizer)\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "history = model.fit(x=x_train_pad,\n",
        "                    y=y_train_pad,\n",
        "                    batch_size=256,\n",
        "                    epochs=500,\n",
        "                    validation_data=(x_val_pad,\n",
        "                                     y_val_pad),\n",
        "                    callbacks=[checkpoint_callback, hist_callback])\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzV6e3URgIpP"
      },
      "source": [
        "# Performance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yzMznPYxgIpP"
      },
      "outputs": [],
      "source": [
        "def flatten_data(list_of_lists):\n",
        "    return [element for sequence in list_of_lists for element in sequence[:padding_length]]\n",
        "\n",
        "def remove_punctuation(y, y_true=None):\n",
        "    if y_true is None:\n",
        "        y_true = y\n",
        "    return [tag for tag, true_tag in zip(y, y_true) if true_tag not in punctuation_tags]\n",
        "\n",
        "x_train_flattened = flatten_data(x_train)\n",
        "x_val_flattened = flatten_data(x_val)\n",
        "x_test_flattened = flatten_data(x_test)\n",
        "\n",
        "y_train_flattened = flatten_data(y_train)\n",
        "y_val_flattened = flatten_data(y_val)\n",
        "y_test_flattened = flatten_data(y_test)\n",
        "\n",
        "y_train_cleaned = remove_punctuation(y_train_flattened)\n",
        "y_val_cleaned = remove_punctuation(y_val_flattened)\n",
        "y_test_cleaned = remove_punctuation(y_test_flattened)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MByAoUW2gIpP"
      },
      "source": [
        "## Dummy Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rZ4iAAn9gIpP"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9ISyU58xgIpQ"
      },
      "outputs": [],
      "source": [
        "majority_classifier = DummyClassifier(strategy=\"prior\")\n",
        "stratified_classifier = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "majority_classifier.fit(x_train_flattened, y_train_flattened);\n",
        "stratified_classifier.fit(x_train_flattened, y_train_flattened);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDEOcuu5gIpR"
      },
      "source": [
        "## Trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Qa81q9VfgIpR"
      },
      "outputs": [],
      "source": [
        "def unpad_result(y_padded, y_true):\n",
        "    return [y[:len(yt)] for y, yt in zip(y_padded, y_true)]\n",
        "\n",
        "def get_model_prediction(model, x, y_true):\n",
        "    output = model.predict(x)\n",
        "    y_pred_model = tag_vocabulary[np.argmax(output, axis=-1)]\n",
        "    y_pred_unpadded = unpad_result(y_pred_model, y_true)\n",
        "    return flatten_data(y_pred_unpadded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kvXR5AHvgIpS"
      },
      "outputs": [],
      "source": [
        "from models import baselineLSTM, GRUModel, additionalLSTM, additionalDense\n",
        "\n",
        "baseline = baselineLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "baseline.load_weights(os.path.join(weights_folder, \"baseline\", \"checkpoint.hdf5\"))\n",
        "\n",
        "gru = GRUModel(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "gru.load_weights(os.path.join(weights_folder, \"gru\", \"checkpoint.hdf5\"))\n",
        "\n",
        "additional_LSTM = additionalLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "additional_LSTM.load_weights(os.path.join(weights_folder, \"additionalLSTM\", \"checkpoint.hdf5\"))\n",
        "\n",
        "additional_dense = additionalDense(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "additional_dense.load_weights(os.path.join(weights_folder, \"additionalDense\", \"checkpoint.hdf5\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL36bBB7gIpS"
      },
      "source": [
        "## Build dictionary with prediction info\n",
        "fill in this dictionary to get all the statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4ASy9u50gIpS"
      },
      "outputs": [],
      "source": [
        "model_prediction_train = partial(get_model_prediction, x=x_train_pad, y_true=y_train)\n",
        "model_prediction_val = partial(get_model_prediction, x=x_val_pad, y_true=y_val)\n",
        "model_prediction_test = partial(get_model_prediction, x=x_test_pad, y_true=y_test)\n",
        "\n",
        "remove_punctuation_train = partial(remove_punctuation, y_true=y_train_flattened)\n",
        "remove_punctuation_val = partial(remove_punctuation, y_true=y_val_flattened)\n",
        "remove_punctuation_test = partial(remove_punctuation, y_true=y_test_flattened)\n",
        "\n",
        "prediction_data = [{\n",
        "    'model_label': 'maj',\n",
        "    'y_pred_train': remove_punctuation_train(majority_classifier.predict(x_train_flattened)),\n",
        "    'y_pred_val': remove_punctuation_val(majority_classifier.predict(x_val_flattened)),\n",
        "    'y_pred_test': remove_punctuation_test(majority_classifier.predict(x_test_flattened))\n",
        "    }, {\n",
        "    'model_label': 'stratified',\n",
        "    'y_pred_train': remove_punctuation_train(stratified_classifier.predict(x_train_flattened)),\n",
        "    'y_pred_val': remove_punctuation_val(stratified_classifier.predict(x_val_flattened)),\n",
        "    'y_pred_test': remove_punctuation_test(stratified_classifier.predict(x_test_flattened))\n",
        "    }, {\n",
        "    'model_label': 'baseline',\n",
        "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=baseline)),\n",
        "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=baseline)),\n",
        "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=baseline))\n",
        "    }, {\n",
        "    'model_label': 'gru',\n",
        "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=gru)),\n",
        "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=gru)),\n",
        "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=gru))\n",
        "    }, {\n",
        "    'model_label': 'additionalDense',\n",
        "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=additional_dense)),\n",
        "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=additional_dense)),\n",
        "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=additional_dense))\n",
        "    }, {\n",
        "    'model_label': 'additionalLSTM',\n",
        "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=additional_LSTM)),\n",
        "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=additional_LSTM)),\n",
        "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=additional_LSTM))\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41bJ4WUbgIpT"
      },
      "source": [
        "## Show analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SQhZ2jCgIpT"
      },
      "source": [
        "Compute F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUmOgOT0gIpT",
        "outputId": "bd7b8a0b-db1a-41d4-b94a-1e490a3927f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "maj train, weighted F1 macro: 0.04\n",
            "maj val, weighted F1 macro: 0.05\n",
            "maj test, weighted F1 macro: 0.05\n",
            "stratified train, weighted F1 macro: 0.08\n",
            "stratified val, weighted F1 macro: 0.08\n",
            "stratified test, weighted F1 macro: 0.08\n",
            "baseline train, weighted F1 macro: 0.73\n",
            "baseline val, weighted F1 macro: 0.70\n",
            "baseline test, weighted F1 macro: 0.74\n",
            "gru train, weighted F1 macro: 0.69\n",
            "gru val, weighted F1 macro: 0.67\n",
            "gru test, weighted F1 macro: 0.70\n",
            "additionalDense train, weighted F1 macro: 0.52\n",
            "additionalDense val, weighted F1 macro: 0.37\n",
            "additionalDense test, weighted F1 macro: 0.39\n",
            "additionalLSTM train, weighted F1 macro: 0.78\n",
            "additionalLSTM val, weighted F1 macro: 0.74\n",
            "additionalLSTM test, weighted F1 macro: 0.78\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def analyze(y_true, y_pred, output_mode=0, model_label=None):\n",
        "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
        "    f1 = report['weighted avg']['f1-score']\n",
        "    if output_mode >= 1:\n",
        "        print(f\"{model_label}, weighted F1 macro: {f1:.2f}\")\n",
        "\n",
        "    if output_mode >= 2:\n",
        "        print(\"Confusion matrix\")\n",
        "        ConfusionMatrixDisplay.from_predictions(y_true, y_pred, cmap='Blues')\n",
        "        plt.show()\n",
        "    return confusion_matrix(y_true, y_pred), f1\n",
        "\n",
        "output_mode = 1\n",
        "for data in prediction_data:\n",
        "    for y, label in zip([y_train_cleaned, y_val_cleaned, y_test_cleaned], ['train', 'val', 'test']):\n",
        "        res = analyze(y, data[f'y_pred_{label}'], output_mode=output_mode, model_label=f\"{data['model_label']} {label}\")\n",
        "        data[f'cm_{label}'], data[f'f1_{label}'] = res\n",
        "\n",
        "f1_train = [data['f1_train'] for data in prediction_data]\n",
        "f1_val = [data['f1_val'] for data in prediction_data]\n",
        "f1_test = [data['f1_test'] for data in prediction_data]\n",
        "\n",
        "model_labels = [data['model_label'] for data in prediction_data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozwpTpmRgIpU"
      },
      "source": [
        "Bar plot of F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "ar7ojAUggIpU",
        "outputId": "e8c97b68-c555-4e71-afdc-d3325fa73dfb"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABBMAAAJLCAYAAAC1y979AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAAPYQAAD2EBqD+naQAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdf7xuZV0n/M8X8OBIgE3AgULkURNJSwaMAmvm9GI0gnmVWQ3065EH06F4eiS0GY5pCqbg1EM5YlqkR3CKqGayMadomPLH6BkYUNBCTes5E6CcRJQf4jnoOdfzx1q33dydvc++9jl73/sc3+/Xa732Wde6rrWuvfd11n3vz32ttaq1FgAAAIClOmDeHQAAAAD2LcIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6HDTvDixFVVWSb0zy4Lz7AgAAAPu5Q5N8urXWFqqwT4QJGYKEu+bdCQAAAPgacWySuxfauK+ECQ8myZ133pnDDjts3n0BAACA/dIDDzyQJzzhCclurgzYV8KEJMlhhx0mTAAAAIA5cwNGAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoMuywoSqurCqtlTVtqq6qapO3U39i6rqE1X1paq6s6p+taoeu7wuAwAAAPPUHSZU1TlJrkxyaZKTk9ye5IaqOmqB+j+W5Iqx/olJXpjknCSvW2afAQAAgDlazsyEi5Nc3Vrb1Fq7I8kFSR5Ocv4C9U9P8oHW2u+01ra01v4syXVJFp3NAAAAAKxNXWFCVa1LckqSGydlrbWd4/ppCzT7YJJTJpdCVNWTkpyV5L8ucpyDq+qwyZLk0J5+AgAAACvnoM76RyQ5MMnWmfKtSZ62qwattd+pqiOS/I+qqvGYb2mtLXaZw8Ykr+rsGwAAALAKVvxpDlW1IcnLk/xMhnssPD/J2VX1ykWaXZ7k8Knl2BXuJgAAALBEvTMT7k2yI8n6mfL1Se5ZoM1rkryjtfZb4/pHq+qQJL9ZVa8dL5N4lNba9iTbJ+vDhAYAAABgLeiamdBaeyTJrUnOmJRV1QHj+uYFmj0uyWxgsGPSvOf4AAAAwPz1zkxIhsdCXlNVtyS5OclFSQ5JsilJquraJHe31jaO9d+V5OKq+nCSm5I8JcNshXe11nbM7hwAAABY27rDhNba9VV1ZJLLkhyd5LYkZ7bWJjdlPC6PnonwS0na+PWbknw2Q8DwC3vQbwAAAGBOqrU27z7s1vh4yPvvv//+HHbYYfPuDgAAAOyXHnjggRx++OFJcnhr7YGF6q340xwAAACA/YswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6HDTvDgAAAHytOP6Sd8+7C6yyLVecPe8urAgzEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALocNO8OALBvOf6Sd8+7C6yiLVecPe8uAABrkJkJAAAAQBdhAgAAANBFmAAAAAB0ESYAAAAAXYQJAAAAQBdhAgAAANBFmAAAAAB0ESYAAAAAXYQJAAAAQBdhAgAAANBFmAAAAAB0ESYAAAAAXYQJAAAAQBdhAgAAANBFmAAAAAB0ESYAAAAAXYQJAAAAQBdhAgAAANBlWWFCVV1YVVuqaltV3VRVpy5S9z1V1XaxvHv53QYAAADmpTtMqKpzklyZ5NIkJye5PckNVXXUAk2en+SYqeUZSXYk+f3ldBgAAACYr4OW0ebiJFe31jYlSVVdkOTsJOcnuWK2cmvtvun1qjo3ycMRJgAAizj+EpMYv9ZsueLseXcBgCXqmplQVeuSnJLkxklZa23nuH7aEnfzwiS/21r7Ys+xAQAAgLWhd2bCEUkOTLJ1pnxrkqftrvF4b4VnZAgUFqt3cJKDp4oO7esmAAAAsFJW+2kOL0zy0dbazbuptzHJ/VPLXSvdMQAAAGBpesOEezPcPHH9TPn6JPcs1rCqDklybpK3LuE4lyc5fGo5trOfAAAAwArpChNaa48kuTXJGZOyqjpgXN+8m+Y/kuHShf+4hONsb609MFmSPNjTTwAAAGDlLOdpDlcmuaaqbklyc5KLkhySZPJ0h2uT3N1a2zjT7oVJ3tla+9we9BcAAACYs+4wobV2fVUdmeSyJEcnuS3Jma21yU0Zj0uyc7pNVZ2Q5LuSPHfPugsAAADM23JmJqS1dlWSqxbYtmEXZZ9IUss5FgAAALC2rPbTHAAAAIB9nDABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuywoTqurCqtpSVduq6qaqOnU39R9fVW+qqs9U1faq+uuqOmt5XQYAAADm6aDeBlV1TpIrk1yQ5KYkFyW5oapOaK39/S7qr0vy35L8fZIfTnJ3kicm+cIe9BsAAACYk+4wIcnFSa5urW1Kkqq6IMnZSc5PcsUu6p+f5J8mOb219uWxbMsyjgsAAACsAV2XOYyzDE5JcuOkrLW2c1w/bYFm359kc5I3VdXWqvrLqnp5VR24yHEOrqrDJkuSQ3v6CQAAAKyc3nsmHJHkwCRbZ8q3Jjl6gTZPynB5w4FJzkrymiQvTfKKRY6zMcn9U8tdnf0EAAAAVshqPM3hgAz3S3hxa+3W1tr1SV6b4Z4LC7k8yeFTy7Er3ksAAABgSXrvmXBvkh1J1s+Ur09yzwJtPpPky621HVNlH0tydFWta609MtugtbY9yfbJelV1dhMAAABYKV0zE8Y//G9NcsakrKoOGNc3L9DsA0meMtabeGqSz+wqSAAAAADWtuVc5nBlkhdV1Quq6sQkb05ySJLJ0x2urarLp+q/OcPTHN5QVU+tqrOTvDzJm/as6wAAAMA8dD8asrV2fVUdmeSyDDddvC3Jma21yU0Zj0uyc6r+nVX1vUl+NclHktyd5A1JXr+HfQcAAADmoDtMSJLW2lVJrlpg24ZdlG1O8p3LORYAAACwtqzG0xwAAACA/YgwAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6LCtMqKoLq2pLVW2rqpuq6tRF6p5XVW1m2bb8LgMAAADz1B0mVNU5Sa5McmmSk5PcnuSGqjpqkWYPJDlmanlif1cBAACAtWA5MxMuTnJ1a21Ta+2OJBckeTjJ+Yu0aa21e6aWrcvpLAAAADB/XWFCVa1LckqSGydlrbWd4/ppizT9uqr631V1Z1X9UVU9fTfHObiqDpssSQ7t6ScAAACwcnpnJhyR5MAkszMLtiY5eoE2n8gwa+EHkvzEeMwPVtWxixxnY5L7p5a7OvsJAAAArJAVf5pDa21za+3a1tptrbX3Jnl+ks8m+TeLNLs8yeFTy2LBAwAAALCKDuqsf2+SHUnWz5SvT3LPUnbQWvtyVX04yVMWqbM9yfbJelV1dhMAAABYKV0zE1prjyS5NckZk7KqOmBc37yUfVTVgUm+Nclneo4NAAAArA29MxOS4bGQ11TVLUluTnJRkkOSbEqSqro2yd2ttY3j+i8m+Z9JPpXk8Ul+PsOjIX9rj3sPAAAArLruMKG1dn1VHZnksgw3XbwtyZlTj3s8LsnOqSZfn+Tqse7nM8xsOH18rCQAAACwj1nOzIS01q5KctUC2zbMrP9ckp9bznEAAACAtWfFn+YAAAAA7F+ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdFlWmFBVF1bVlqraVlU3VdWpS2x3blW1qnrnco4LAAAAzF93mFBV5yS5MsmlSU5OcnuSG6rqqN20Oz7JryR5f3cvAQAAgDVjOTMTLk5ydWttU2vtjiQXJHk4yfkLNaiqA5P8dpJXJfnb5XQUAAAAWBu6woSqWpfklCQ3TspaazvH9dMWafqLSf6+tfbWJR7n4Ko6bLIkObSnnwAAAMDK6Z2ZcESSA5NsnSnfmuToXTWoqu9K8sIkL+o4zsYk908td3X2EwAAAFghK/o0h6o6NMk7kryotXZvR9PLkxw+tRy7At0DAAAAluGgzvr3JtmRZP1M+fok9+yi/pOTHJ/kXVU1KTsgSarqK0lOaK39zWyj1tr2JNsn61NtAQAAgDnrmpnQWnskya1JzpiUVdUB4/rmXTT5eJJvTXLS1PJfkvzF+O87l9VrAAAAYG56ZyYkw2Mhr6mqW5LcnOSiJIck2ZQkVXVtkrtbaxtba9uS/OV046r6QpK01h5VDgAAAOwbusOE1tr1VXVkkssy3HTxtiRnttYmN2U8LsnOvddFAAAAYC1ZzsyEtNauSnLVAts27Kbtecs5JgAArJTjL3n3vLvAKtpyxdnz7gLs81b0aQ4AAADA/keYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdhAkAAABAF2ECAAAA0EWYAAAAAHQRJgAAAABdlhUmVNWFVbWlqrZV1U1VdeoidZ9fVbdU1Req6otVdVtV/eTyuwwAAADMU3eYUFXnJLkyyaVJTk5ye5IbquqoBZrcl+S1SU5L8m1JNiXZVFXfu6weAwAAAHO1nJkJFye5urW2qbV2R5ILkjyc5PxdVW6tvae19oettY+11v6mtfaGJB9J8l3L7jUAAAAwN11hQlWtS3JKkhsnZa21neP6aUtoX1V1RpITkrxvkXoHV9VhkyXJoT39BAAAAFZO78yEI5IcmGTrTPnWJEcv1KiqDq+qh5I8kuTdSX62tfbfFjnOxiT3Ty13dfYTAAAAWCGr9TSHB5OclOTbk/xCkiurasMi9S9PcvjUcuxKdxAAAABYmoM669+bZEeS9TPl65Pcs1Cj8VKIT42rt1XViRlmH7xngfrbk2yfrFdVZzcBAACAldI1M6G19kiSW5OcMSmrqgPG9c2dxz2459gAAADA2tA7MyEZHgt5TVXdkuTmJBclOSTDIx9TVdcmubu1tnFc35jkliR/kyFAOCvJTyb56T3uPQAAALDqusOE1tr1VXVkkssy3HTxtiRnttYmN2U8LsnOqSaHJPn1DPc9+FKSjyf5idba9XvScQAAAGA+ljMzIa21q5JctcC2DTPrr0jyiuUcBwAAAFh7VutpDgAAAMB+QpgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2ECQAAAEAXYQIAAADQRZgAAAAAdBEmAAAAAF2WFSZU1YVVtaWqtlXVTVV16iJ1X1RV76+qz4/LjYvVBwAAANa27jChqs5JcmWSS5OcnOT2JDdU1VELNNmQ5Lok35PktCR3Jvmzqvqm5XQYAAAAmK/lzEy4OMnVrbVNrbU7klyQ5OEk5++qcmvtx1trv95au6219vEkPzUe94zldhoAAACYn64woarWJTklyY2TstbaznH9tCXu5nFJHpPkvp5jAwAAAGvDQZ31j0hyYJKtM+Vbkzxtift4fZJPZyqQmFVVByc5eKro0I4+AgAAACtoVZ/mUFWXJDk3yQ+21rYtUnVjkvunlrtWoXsAAADAEvSGCfcm2ZFk/Uz5+iT3LNawql6W5JIkz22tfWQ3x7k8yeFTy7Gd/QQAAABWSFeY0Fp7JMmtmbp5YlVNbqa4eaF2VfVvk7wyyZmttVuWcJztrbUHJkuSB3v6CQAAAKyc3nsmJMNjIa+pqluS3JzkoiSHJNmUJFV1bZK7W2sbx/V/l+SyJD+WZEtVHT3u56HW2kN72H8AAABglXWHCa2166vqyAwBwdFJbssw42ByU8bjkuycavLTSdYl+YOZXV2a5NW9xwcAAADmazkzE9JauyrJVQts2zCzfvxyjgEAAACsTav6NAcAAABg3ydMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgy7LChKq6sKq2VNW2qrqpqk5dpO7Tq+o/jfVbVV20/O4CAAAA89YdJlTVOUmuTHJpkpOT3J7khqo6aoEmj0vyt0kuSXLPMvsJAAAArBHLmZlwcZKrW2ubWmt3JLkgycNJzt9V5dba/2qt/Xxr7XeTbF9+VwEAAIC1oCtMqKp1SU5JcuOkrLW2c1w/bW91qqoOrqrDJkuSQ/fWvgEAAIA90zsz4YgkBybZOlO+NcnRe6VHg41J7p9a7tqL+wYAAAD2wFp9msPlSQ6fWo6db3cAAACAiYM669+bZEeS9TPl67MXb67YWtueqfsrVNXe2jUAAACwh7pmJrTWHklya5IzJmVVdcC4vnnvdg0AAABYi3pnJiTDYyGvqapbktyc5KIkhyTZlCRVdW2Su1trG8f1dUm+ZWy7Lsk3VdVJSR5qrX1qD/sPAAAArLLuMKG1dn1VHZnksgw3XbwtyZmttclNGY9LsnOqyTcm+fDU+svG5b1JNiyjzwAAAMAcLWdmQlprVyW5aoFtG2bWtyRx0wMAAADYT6zVpzkAAAAAa5QwAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoMtB8+4AsOeOv+Td8+4Cq2zLFWfPuwsAAHwNMzMBAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgizABAAAA6CJMAAAAALoIEwAAAIAuwgQAAACgy0Hz7sD+7PhL3j3vLrCKtlxx9ry7AAAAsCrMTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOgiTAAAAAC6CBMAAACALsIEAAAAoIswAQAAAOiyrDChqi6sqi1Vta2qbqqqU3dT/0eq6uNj/Y9W1VnL6y4AAAAwb91hQlWdk+TKJJcmOTnJ7UluqKqjFqh/epLrkrw1yT9L8s4k76yqZyy30wAAAMD8LGdmwsVJrm6tbWqt3ZHkgiQPJzl/gfovSfKnrbVfbq19rLX2yiQfSvJ/L6vHAAAAwFwd1FO5qtYlOSXJ5ZOy1trOqroxyWkLNDstw0yGaTcked4ixzk4ycFTRYcmyQMPPNDT3bnbuf3heXeBVTTP8Wmsfe0x3lgtxhqryXhjtRhrrKZ97e/Ypfa3WmtL3mlVfWOSu5Oc3lrbPFX+75P8i9bad+yizSNJXtBau26q7GeSvKq1tn6B47w6yauW3DEAAABgbzq2tXb3Qhu7Ziasosvzj2cz/NMk982hL/Q5NMldSY5N8uCc+8L+zVhjNRlvrBZjjdVkvLFajLV9z6FJPr1Yhd4w4d4kO5LMzihYn+SeBdrc01k/rbXtSbbPFO9bc0O+RlXV5J8Pttb8zlgxxhqryXhjtRhrrCbjjdVirO2Tdvt76roBY2vtkSS3JjljUlZVB4zrmxdotnm6/ug5i9QHAAAA1rDlXOZwZZJrquqWJDcnuSjJIUk2JUlVXZvk7tbaxrH+G5K8t6pemuTdSc5N8qwkL97DvgMAAABz0B0mtNaur6ojk1yW5OgktyU5s7W2daxyXJKdU/U/WFU/luSXkrwuySeTPK+19pd72nnWpO1JLs0/vkwF9jZjjdVkvLFajDVWk/HGajHW9kNdT3MAAAAA6LpnAgAAAIAwAQAAAOgiTAAAAAC6CBOYi6p6dVXdNu9+sH+oqg1V1arq8VNlz6uqT1XVjqr6tao6r6q+sBeO1arqeXu6H/ZcVb2nqn5tjsd/e1W9c630B1g7qur48fXipEXqPOq1a6mvU/N4HdrV6yxrk7HHahImMC+/kuSMeXeClTf7B9de2N+u/mD7YJJjktw/VfYbSf4gyROSvDLJ9Umeurf6Abvw/AxjDWA5HvU6tcgHL8ck+ZNV69UuTP2B16pqZ1XdX1Ufrqp/X1XHzLNvLMu+OPZ2GS5U1eOq6vKq+puq2lZVn62q91bVD0wFLYst500d4/NV9diZ/X/7pO7qfMdrW/ejIWFvaK09lOShefeDtaOqHtNa+/Jy2rbWHklyz9S+vi7JUUluaK19eqrql/asl7Cw1tp98+4D+5+qWjee49jPtda+lCW8TrXW7tldnVV0QpIHkhyW5OQk/zbJC6tqQ2vto3PtGUu2j469hbwlyXck+dkkdyT5hiSnj1/vzBCITLwsyZlJ/uVU2f1j+yR5MMkPJrluavsLk/xdkuNWoO/7HDMT2K3xk+A3jpat8uYAAA2YSURBVFPFP19VW6vqRVV1SFVtqqoHx+nk3zfWP7Cq3lpV/19VfamqPlFVL5nZp8sc9jNV9cNV9dHxd/65qrqxqn45yQuS/MBU4rthKhk+Z0yLtyX58ar6hqq6rqrurqqHx/396NQx3p7kXyR5ydT+jp9OqatqQ4aTf5L8+dQx/9EUvjGl/tCYXP9tVb2qqg6a2v7NVfW+cfsdVfWcFf4x0u+gqrpq/FTs3qp6TVVVklTVT1bVLeM56p6q+p2qOmrSsKq+vqp+e/zU4ktV9cmq+r+mtj+hqn6vqr5QVfdV1R9V1fELdaRmZs1U1ZaqenlVvW3sw99V1Ytn2nQdg31fVR06jrsvVtVnqurnpsfOOG5eWVXXVtUDSX6zdn0p10mTc+CcvpWvKVV1ZlX9j/H/6ueq6o+r6slT20+t4ZP5bVV1S5J/tot9nFVVfz2eb/4iyfEz27/6OlVV5yV5VZJnTr3enTdue9RU86r61qr686nX39+sIVSfbH97Vb2zql42jrnPVdWbquoxU3UWPV8u4u9ba/e01v66tfa7SZ6d5LNJ3jzzvf1UVX1s/Pl8vKp+Zmrb5D3B86vqL2p4/b+9qk6bqvPEqnpXDe9Dv1hVf1VVZ01tf0ZV/UlVPVTD+9R3VNURS+j/mmfsdfv+JK9rrf3X1tqW1tqtrbU3ttbe1lrbMY7Xe8Zg5KEkX5kuG4OViWuSnD/V13+S5NyxnAgTWLoXJLk3yalJ3pjhReL3M0wvPznJnyV5R1U9LsO4uivJjyT5liSXJXldVf3rOfSbVVDDlMbrkrwtyYlJNiT5z0kuTfJ7Sf40QxJ8TIYxM3FFkjeMbW5I8tgktyY5O8kzkvxmhnF16lj/JUk2J7l6an93znTngxk+KUmSH9rFMSd9/u4k147H/5Yk/ybJeUl+Ydx+wPg9PJIhob4gyeuX/ENhtbwgyVcynJtekuTiJD81bntMhssOnpnkeRnePL19qu1rMvzuvy/DGPzpDOe5jG90bsgQTH13hjfIDyX506pa19G/lyaZvLn79SRvrqoT9vIx2LdcmeF3/f1JnpPhd3/yTJ2XJbk9w7h5zar2joUckuF396wMl2nuTPKHVXXA+MfTH2f4FPSUJK/OcDnnV1XVEzK8prwryUlJfivDa+BCrk/y/yb5q/zD6931s5Wq6pAM55HPJ/n2DO+9/mWSq2aqfk+SJ49fX5Dh9e68qe27O18uyfiH2FuSPHvyB2FV/XiG94K/kOFc+/Ikr6mqF8w0f22Gn9tJSf46yXX1DwH/m5IcnOSfJ/nWJP8u4wzXGkK2P0/y4Qy/nzOTrM/w/mN/YOz1uSfJWVV16B7sY+IdSb67qiazEH4oyZYkH9oL+94/tNYslkWXJO9J8v6p9QMznMCvnSo7OklL8p0L7OOqJH8wtf7qJLfN+3uz7LUxcvL4+3/iLra9Pck7Z8qOH+u/ZAn7/uMkvzK1/p4kvzZTZ8O4v8eP648f1zdM1TkvyRem1m9MsnFmPz+R5NPjv5+b5MtJvnFq+5njfp8375+55atj4Y4kNVV2RZI7Fqj/rPH393Xj+n9J8rYF6v5Eko/P7HtdkoeTPHdcf9TYnh2bGd5wvGNqvZJsTXLBUo9h2b+WJIdmCCh/eKrs8CRfnIydcdz84Uy7R53jxrKTxrLj5/19fS0uSY4Yf/7PSPLiDEHkY6e2XzBuP2lcf12Sv5rZxxUzr12zr1Ovzi7eK02/DiV5UZL7khwytf2sJDuSrB/X3z6OqwOn6vxekt9d5PubPV8+agzuakxOtZ28Vp46rn8qyY/O1HlFkg+O/z5+rP/Cqe3fMpY9bVz/SJJXLdDXV2S4rHG67Nix/VPnPVaMvdUbe+P2f57hg6ZHkvyvJL+a5NkL1F3o+/zqMZL8YZJfHMv/PMn/kyH0aPMeC2thMTOBpfrI5B+ttR1JPpdk+lq4rePXSQp9YVXdWsP04YcynOxcW7T/uj3Jf0/y0ar6/Roug/n6JbS7ZXqlhktkXlnD5Q33jWPne7MyY+eZSX5xnBL50Hisq5McM86wOTHJne3R91zYvAL9YM/8zza+wo82J/nmcSydMk6L/buqejDJe8c6k/H05iTnVtVtNdw07PSp/TwzyVOSPDg1Pu7LMHvmyVm66XNny/CJyWT65t46BvuOJ2X4FO7mSUFr7f4kn5ipd0tYU2q47O26Gi6JeyDDH0jJcD45MclHWmvbpprMvl6cmOSmmbK98ZpyYpLbW2tfnCr7QIZZoidMlf3V+P5t4jP5h3NRlnC+7FHj1zZ+ev3kJG+deb19Rf7xee4jU//+zPh10sf/kOQVVfWBqrq0qr5tqu4zk3zPzP4/Pm7b58+lxl6f1tr7Mpxrz8hwI+6nJ3l/VS33BslvS3JeVT0pyWlJfnuZ+9kvuQEjSzV7Y7w2XdZaazVcpnxAVZ2bYYrVSzOcrB5M8vP5h5uZsJ9pre2o4X4Cp2f4RP9nk7y2qnb3O//izPrPZ5iqflGGsOqLSX4tw6e1e9vXZbgm8D/vYtu2XZSxb3lshumXNyT58QzX8B43rq9Lktban1TVEzN8kvKcJP+9qt7UWntZhvFx69h21mc7+rGrc+ckyN9bx2D/M3tu3Dl+ramyx4TV9K4k/zvDp7GfzvD/+C+zMq9PK2HBc9HUdPUFz5edThy/bslwnkuGn9vsH7Q7Ztan+zgJiQ9Iktbab1XVDRkug3xuko1V9dLW2hvHY7wrw6UPsz6zi7J9jbHXqQ039H7/uLy+ql6R4QOk17f+G9r+SYbLbt+a5F2ttc+Nf/MQYQIr49kZpq79+qSgpm4Uw/5p/NT1A0k+UFWXZXjh+8EM08wOXOJunp3kj1pr/zH56n0LnpphKvtEz/4W86EkJ7TWPrWrjVX1sSRPqKpjWmuTNyPfuReOy941G1h9Z5JPJnlahjs3X9JauzNJqupZs41ba5/NcCOla6rq/Ul+OcP16h9Kck6Gm4s9sEJ9X41jsLb8bYY31t+e4W7gqarDM5zn3rdIu0m4dEyG65OT4TIHVkFVfUOGT1pf1Fp7/1j2XVNVPpbkJ6vqsVOfEM++Xnwsw30ypu3uNWUpr3cfy/Cp6SFTnxA/O0MANTvjZSFLOl8uxXiDuhcned94fk1VfTrJk1pre/SJ7ti3tyR5S1VdnuGP6zdmOJf+UJItrbWv7Mkx1hpjb6+5I8PfvY/N8L0tWWvtK1V1bYYnlXzfCvRtn+YyB1bCJ5M8q6q+t6qeWlWvyfDGif1UVX1HDXetf9Z4k5rnJzkywwvNliTfVlUnVNURNXUH3134ZJLnVNXpVXVikt/IcBOlaVuSfEcNd38+YgwcluOyJP9nDU9weHpVnVhV51bVL43bb8xwA6hrquqZNdyw8bXLPBYr57iqunIcXz+aYVbMGzL8ofZIkp+tqidV1fdnuMHTV1XVZTU80eMpVfX0JP8qw5hNhmmM9yb5o6r67qr6P2q4o/5/qKpj91LfV+MYrCGttQczhFe/XFXfM467t2Z4873YM8s/lf+/vfsJsSkM4zj+e7JAFopJlmQnkyg7FizMQspyxspskKSMEQv/FhMLdpryZyREWShKGI0mU0o0TaHRrGiKyBRJFrPwWvzeO8M1/86MuXeM76fu5t5z733v3DPvPec5z/O8rgE+kVOet8jZf6iMz3J55848X2ySG+KV3JC/v4sRsTK8ykBz2Wuck0uwTuf5art+b0I3kreSlodX7qiJiLkjbHNdzqa7El7RYKN8gn0tpfRxhO1HMu58OYYlEbE075f18kWFGrmhbclxOZNgXz4urI2IxohomuB7KLyiWF2eJ9fKzfxK83WrpEVyw8Z1EbEib3s5Iv7GxYdqYt8bXW0eX+m2WhpaWWlXuHxiWf6bnJTUOYXA/VH5uLZ9ks+ftQgmYDqcl1PHb8opbYvlLuaYvb7KDW/uySfgLZIOpJTuy30I+uQa4E9y1Ho0LfIVhna5md0HSbfLtjkjp0b2ajgdrrCUUrt88rhZbtDzVNJ+OaNCKaUfcmbFfLm+uU15pQfMKFc1/B21yoGEC/mK2A65u3SvpMP68wBrUNIpuU63S96v6iUppfRd3qf75fnstXzSN0/e36esEu+BGalJLgG8Kwctn8jf/ajlVTllt0G+ivdCTuc+Mu0jhaSh34N6uVv+K7mh28FfHv8maau8ykCPHHg+VPYa/fLV821yn6Hd8qoGY7klr4bUKf/eNZRvkOeROvlk+rlcI/5I0t4Cn28i8+Vo+uTU++78vA5Jq1JKQxmFKaU2eZWdRrmE8XF+vzcTHaN8lbxV/l95IB9r7Mmv/14+tpgjry72Ui6R/KLhEqF/EvvemLrkz1y6def72+VVIx7K+8vZfN+kV5VLKQ2mlAbKejRBuYM0UGk5PW1DSmn9uBsDADBLhWuG38kB2EvVHg8AABNFzwRUVESEhjus9lR5OAAAVFRErJEzDJ7Jy0Ieyw/dqdqgAACYBMocUGkL5TSmQbl+CQCA/02znG7cIWmBnKk3UN0hAQBQDGUOAAAAAACgEDITAAAAAABAIQQTAAAAAABAIQQTAAAAAABAIQQTAAAAAABAIQQTAAAAAABAIQQTAAAAAABAIQQTAAAAAABAIQQTAAAAAABAIQQTAAAAAABAIT8BtKeW5mx4gHIAAAAASUVORK5CYII=",
            "text/plain": [
              "<Figure size 1280x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "w, h, dpi = 1280, 720, 100\n",
        "fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
        "\n",
        "ax.bar(model_labels, height=f1_test, width=0.8)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "716c34c06793e5cf93c7b330bdfcb45c40eb89e5efd6d32b0d2191c531a6c3c3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
