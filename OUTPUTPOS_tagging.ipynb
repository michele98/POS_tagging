{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_u8E5ItNgIpB"
      },
      "source": [
        "Uncomment and execute in Colab Notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "om_Ab2NNgIpF",
        "outputId": "3da3c2fb-6295-44de-bfef-3a342c7526ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting gensim==4.2.0\n",
            "  Downloading gensim-4.2.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (24.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.1 MB 21.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.8/dist-packages (from gensim==4.2.0) (1.7.3)\n",
            "Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.8/dist-packages (from gensim==4.2.0) (1.21.6)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.8/dist-packages (from gensim==4.2.0) (5.2.1)\n",
            "Installing collected packages: gensim\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "Successfully installed gensim-4.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting keras==2.8.0\n",
            "  Downloading keras-2.8.0-py2.py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 7.9 MB/s \n",
            "\u001b[?25hInstalling collected packages: keras\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.9.2 requires keras<2.10.0,>=2.9.0rc0, but you have keras 2.8.0 which is incompatible.\u001b[0m\n",
            "Successfully installed keras-2.8.0\n",
            "Cloning into 'POS_tagging'...\n",
            "remote: Enumerating objects: 122, done.\u001b[K\n",
            "remote: Counting objects: 100% (122/122), done.\u001b[K\n",
            "remote: Compressing objects: 100% (81/81), done.\u001b[K\n",
            "remote: Total 122 (delta 68), reused 88 (delta 38), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (122/122), 150.66 KiB | 10.04 MiB/s, done.\n",
            "Resolving deltas: 100% (68/68), done.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# execute this cell when loading the notebook for the first time\n",
        "! pip install gensim==4.2.0\n",
        "! pip install keras==2.8.0\n",
        "\n",
        "! git clone https://github.com/michele98/POS_tagging\n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "drive_folder = '/content/drive/MyDrive'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhmZ3YCHgIpG",
        "outputId": "66040ad5-76a7-4af0-c801-2fac3c5a343c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/POS_tagging\n"
          ]
        }
      ],
      "source": [
        "# execute this cell each time the runtime is restarted\n",
        "\n",
        "%cd -0\n",
        "%cd POS_tagging\n",
        "\n",
        "import os\n",
        "os.environ['TF_DETERMINISTIC_OPS'] = '1'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUPCryODgIpG"
      },
      "source": [
        "Main Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JK_zI4TwgIpH"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import urllib.request\n",
        "\n",
        "from zipfile import ZipFile\n",
        "\n",
        "random_seed = 42\n",
        "np.random.seed(random_seed)\n",
        "tf.random.set_seed(random_seed)\n",
        "#os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k91cP9wWgIpH"
      },
      "source": [
        "# Create Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GH2gBvrzgIpH"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbxohvOigIpI",
        "outputId": "5d447aba-e701-4c63-9c90-724573bcf2b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successful download\n"
          ]
        }
      ],
      "source": [
        "dataset_folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\")\n",
        "\n",
        "if not os.path.exists(dataset_folder):\n",
        "    os.makedirs(dataset_folder)\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
        "\n",
        "dataset_path = os.path.join(dataset_folder, \"data.zip\")\n",
        "\n",
        "if not os.path.exists(dataset_path):\n",
        "    urllib.request.urlretrieve(url, dataset_path)\n",
        "    print(\"Successful download\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-lsMoB8gIpI"
      },
      "source": [
        "## Create Dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 441
        },
        "id": "TE0cWkqOgIpI",
        "outputId": "bf70fa4e-28ce-41ad-d658-68b2ec199716"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataframe created.                                \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      file_id                                               text  \\\n",
              "0           1  (Pierre, Vinken, ,, 61, years, old, ,, will, j...   \n",
              "1           1  (Mr., Vinken, is, chairman, of, Elsevier, N.V....   \n",
              "2           2  (Rudolph, Agnew, ,, 55, years, old, and, forme...   \n",
              "3           3  (``, There, 's, no, question, that, some, of, ...   \n",
              "4           3  (Workers, described, ``, clouds, of, blue, dus...   \n",
              "...       ...                                                ...   \n",
              "3909      198  (A, line-item, veto, is, a, procedure, that, w...   \n",
              "3910      198  (Sen., Kennedy, said, in, a, separate, stateme...   \n",
              "3911      199  (Trinity, Industries, Inc., said, it, reached,...   \n",
              "3912      199                   (Terms, were, n't, disclosed, .)   \n",
              "3913      199  (Trinity, said, it, plans, to, begin, delivery...   \n",
              "\n",
              "                                                   tags  split  \n",
              "0     (NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  train  \n",
              "1     (NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  train  \n",
              "2     (NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  train  \n",
              "3     (``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...  train  \n",
              "4     (NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...  train  \n",
              "...                                                 ...    ...  \n",
              "3909  (DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...   test  \n",
              "3910  (NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...   test  \n",
              "3911  (NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...   test  \n",
              "3912                             (NNS, VBD, RB, VBN, .)   test  \n",
              "3913  (NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...   test  \n",
              "\n",
              "[3914 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-44c470ce-3b39-413f-8ba1-98bac399c822\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>(Pierre, Vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>(NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>(Mr., Vinken, is, chairman, of, Elsevier, N.V....</td>\n",
              "      <td>(NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>(Rudolph, Agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>(NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>(``, There, 's, no, question, that, some, of, ...</td>\n",
              "      <td>(``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>(Workers, described, ``, clouds, of, blue, dus...</td>\n",
              "      <td>(NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>198</td>\n",
              "      <td>(A, line-item, veto, is, a, procedure, that, w...</td>\n",
              "      <td>(DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>198</td>\n",
              "      <td>(Sen., Kennedy, said, in, a, separate, stateme...</td>\n",
              "      <td>(NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3911</th>\n",
              "      <td>199</td>\n",
              "      <td>(Trinity, Industries, Inc., said, it, reached,...</td>\n",
              "      <td>(NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3912</th>\n",
              "      <td>199</td>\n",
              "      <td>(Terms, were, n't, disclosed, .)</td>\n",
              "      <td>(NNS, VBD, RB, VBN, .)</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>199</td>\n",
              "      <td>(Trinity, said, it, plans, to, begin, delivery...</td>\n",
              "      <td>(NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3914 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-44c470ce-3b39-413f-8ba1-98bac399c822')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-44c470ce-3b39-413f-8ba1-98bac399c822 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-44c470ce-3b39-413f-8ba1-98bac399c822');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_range = (1, 101)\n",
        "val_range = (101, 151)\n",
        "test_range = (151, 200)\n",
        "\n",
        "split_sentences = True\n",
        "\n",
        "dataframe_rows = []\n",
        "with ZipFile(dataset_path, 'r') as myzip:\n",
        "    for i, filename in enumerate(myzip.namelist()[1:]):\n",
        "        print(\"Extracting\", filename, end='\\r')\n",
        "\n",
        "        with myzip.open(filename) as myfile:\n",
        "            file_id = int(filename.split('.')[0][-4:])\n",
        "\n",
        "            split = 'train'\n",
        "            if file_id in range(*val_range):\n",
        "                split = 'val'\n",
        "            elif file_id in range(*test_range):\n",
        "                split = 'test'\n",
        "\n",
        "            content_string = myfile.read().decode('utf-8')\n",
        "            if split_sentences:\n",
        "                sentences = content_string.split('\\n\\n')\n",
        "            else:\n",
        "                sentences = [content_string]\n",
        "\n",
        "            for sentence in sentences:\n",
        "                content = sentence.split('\\n')\n",
        "                content = [line.split('\\t') for line in content if len(line.split('\\t')) == 3]\n",
        "\n",
        "                words, tags, _ = zip(*content)\n",
        "\n",
        "                dataframe_rows.append({'file_id': file_id,\n",
        "                                       'text': words,\n",
        "                                       'tags': tags,\n",
        "                                       'split': split\n",
        "                                       })\n",
        "\n",
        "df = pd.DataFrame(dataframe_rows).sort_values('file_id').reset_index(drop=True)\n",
        "print(\"Dataframe created.\".ljust(50))\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZKeTNqw4gIpJ"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKryqoILgIpJ"
      },
      "source": [
        "Convert to lowercase"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "WL4B-3oOgIpJ",
        "outputId": "aa85e523-ae4f-4c23-daf0-4d9d904503e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      file_id                                               text  \\\n",
              "0           1  [pierre, vinken, ,, 61, years, old, ,, will, j...   \n",
              "1           1  [mr., vinken, is, chairman, of, elsevier, n.v....   \n",
              "2           2  [rudolph, agnew, ,, 55, years, old, and, forme...   \n",
              "3           3  [``, there, 's, no, question, that, some, of, ...   \n",
              "4           3  [workers, described, ``, clouds, of, blue, dus...   \n",
              "...       ...                                                ...   \n",
              "3909      198  [a, line-item, veto, is, a, procedure, that, w...   \n",
              "3910      198  [sen., kennedy, said, in, a, separate, stateme...   \n",
              "3911      199  [trinity, industries, inc., said, it, reached,...   \n",
              "3912      199                   [terms, were, n't, disclosed, .]   \n",
              "3913      199  [trinity, said, it, plans, to, begin, delivery...   \n",
              "\n",
              "                                                   tags  split  \n",
              "0     (NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  train  \n",
              "1     (NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  train  \n",
              "2     (NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  train  \n",
              "3     (``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...  train  \n",
              "4     (NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...  train  \n",
              "...                                                 ...    ...  \n",
              "3909  (DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...   test  \n",
              "3910  (NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...   test  \n",
              "3911  (NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...   test  \n",
              "3912                             (NNS, VBD, RB, VBN, .)   test  \n",
              "3913  (NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...   test  \n",
              "\n",
              "[3914 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb2bce4e-83db-4565-b386-3e1dfc246f63\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>file_id</th>\n",
              "      <th>text</th>\n",
              "      <th>tags</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>[pierre, vinken, ,, 61, years, old, ,, will, j...</td>\n",
              "      <td>(NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>[mr., vinken, is, chairman, of, elsevier, n.v....</td>\n",
              "      <td>(NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>[rudolph, agnew, ,, 55, years, old, and, forme...</td>\n",
              "      <td>(NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>[``, there, 's, no, question, that, some, of, ...</td>\n",
              "      <td>(``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>[workers, described, ``, clouds, of, blue, dus...</td>\n",
              "      <td>(NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...</td>\n",
              "      <td>train</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3909</th>\n",
              "      <td>198</td>\n",
              "      <td>[a, line-item, veto, is, a, procedure, that, w...</td>\n",
              "      <td>(DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3910</th>\n",
              "      <td>198</td>\n",
              "      <td>[sen., kennedy, said, in, a, separate, stateme...</td>\n",
              "      <td>(NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3911</th>\n",
              "      <td>199</td>\n",
              "      <td>[trinity, industries, inc., said, it, reached,...</td>\n",
              "      <td>(NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3912</th>\n",
              "      <td>199</td>\n",
              "      <td>[terms, were, n't, disclosed, .]</td>\n",
              "      <td>(NNS, VBD, RB, VBN, .)</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3913</th>\n",
              "      <td>199</td>\n",
              "      <td>[trinity, said, it, plans, to, begin, delivery...</td>\n",
              "      <td>(NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3914 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb2bce4e-83db-4565-b386-3e1dfc246f63')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb2bce4e-83db-4565-b386-3e1dfc246f63 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb2bce4e-83db-4565-b386-3e1dfc246f63');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df['text'] = df['text'].apply(lambda l: [element.lower() for element in l])\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "igBEseAqgIpK"
      },
      "source": [
        "## Data Splitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qya3qo9QgIpK",
        "outputId": "9ef7ce31-0da7-48ef-fe10-de22a05e74f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset splits statistics: \n",
            "Train data: (1963,)\n",
            "Validation data: (1299,)\n",
            "Test data: (652,)\n"
          ]
        }
      ],
      "source": [
        "train_data = df[df['split'] == 'train']\n",
        "val_data = df[df['split'] == 'val']\n",
        "test_data = df[df['split'] == 'test']\n",
        "\n",
        "x_train = train_data['text'].values\n",
        "y_train = train_data['tags'].values\n",
        "\n",
        "x_val = val_data['text'].values\n",
        "y_val = val_data['tags'].values\n",
        "\n",
        "x_test = test_data['text'].values\n",
        "y_test = test_data['tags'].values\n",
        "\n",
        "print('Dataset splits statistics: ')\n",
        "print(f'Train data: {x_train.shape}')\n",
        "print(f'Validation data: {x_val.shape}')\n",
        "print(f'Test data: {x_test.shape}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SIFpQxIKgIpK"
      },
      "source": [
        "## Add OOV words to GloVe embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZ9I7HVNgIpK",
        "outputId": "5e2a7395-5f58-4041-fc1e-00ee002bcb36"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading GloVe embedding.\n",
            "[=================================================-] 98.1% 64.7/66.0MB downloaded\n"
          ]
        }
      ],
      "source": [
        "from utils.preprocessing import load_embedding_model, add_OOV_embeddings\n",
        "\n",
        "print(\"Loading GloVe embedding.\")\n",
        "my_embedding_dimension = 50\n",
        "my_embedding_model = load_embedding_model('glove', my_embedding_dimension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCqQiHAjgIpK",
        "outputId": "5f9345d7-2680-4fd3-d4a0-913b8b036cce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GLOVE vocabulary size:  400000\n",
            "Add unknown token [UNK] and padding token \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2/2 [00:00<00:00, 33.20it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V1 size:  400002\n",
            "\n",
            "Creating V2 using training set (V1 + OOV1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 359/359 [00:07<00:00, 46.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V2 size:  400361\n",
            "\n",
            "Creating V3 using validation set (V2 + OOV2)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 189/189 [00:03<00:00, 48.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V3 size:  400550\n",
            "\n",
            "Creating V4 using validation set (V3 + OOV3)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 128/128 [00:02<00:00, 46.21it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "V4 size:  400678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "print(\"GLOVE vocabulary size: \", len(my_embedding_model))\n",
        "\n",
        "unknown_token = '[UNK]'\n",
        "padding_token = ''\n",
        "\n",
        "print(f\"Add unknown token {unknown_token} and padding token {padding_token}\")\n",
        "add_OOV_embeddings(my_embedding_model, [unknown_token, padding_token], my_embedding_dimension)\n",
        "print(\"V1 size: \", len(my_embedding_model))\n",
        "\n",
        "print(\"\\nCreating V2 using training set (V1 + OOV1)\")\n",
        "add_OOV_embeddings(my_embedding_model, x_train, my_embedding_dimension)\n",
        "print(\"V2 size: \", len(my_embedding_model))\n",
        "\n",
        "print(\"\\nCreating V3 using validation set (V2 + OOV2)\")\n",
        "add_OOV_embeddings(my_embedding_model, x_val, my_embedding_dimension)\n",
        "print(\"V3 size: \", len(my_embedding_model))\n",
        "\n",
        "print(\"\\nCreating V4 using validation set (V3 + OOV3)\")\n",
        "add_OOV_embeddings(my_embedding_model, x_test, my_embedding_dimension)\n",
        "print(\"V4 size: \", len(my_embedding_model))\n",
        "\n",
        "# build vocabulary for x\n",
        "dataset_vocabulary = np.unique([word for sentence in df['text'] for word in sentence])\n",
        "dataset_vocabulary = np.concatenate([[unknown_token], dataset_vocabulary])\n",
        "\n",
        "# build vocabulary for y\n",
        "tags_s = ' '.join([' '.join(y) for y in df['tags']])\n",
        "tag_vocabulary = pd.DataFrame(tags_s.split())[0].unique()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JhUXQOQOgIpL"
      },
      "source": [
        "## Explore Tags and define punctuation tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElFVcIWjgIpL",
        "outputId": "0b720bb5-09e5-4d25-af68-5708239a7b6a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['NNP', ',', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', '.',\n",
              "       'VBZ', 'VBG', 'CC', 'VBD', 'VBN', '``', 'EX', \"''\", 'WDT', 'RB',\n",
              "       'RP', 'TO', 'WRB', 'RBR', 'VBP', 'JJR', 'WP', 'JJS', 'PRP', ':',\n",
              "       'POS', 'PRP$', '$', 'NNPS', 'WP$', '-LRB-', '-RRB-', 'PDT', 'RBS',\n",
              "       'FW', 'UH', 'SYM', 'LS', '#'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "tag_vocabulary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuXAhDi-gIpL"
      },
      "source": [
        "Mmh, there are some interesting looking tags. Let's build a DataFrame with some sentence examples to see what they mean."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Hjt38_VXgIpL"
      },
      "outputs": [],
      "source": [
        "d = {}\n",
        "\n",
        "for tag in tag_vocabulary:\n",
        "    i = df.loc[np.array([tag in t for t in df['tags']])].index[0]\n",
        "    s1 = df['text'][i]\n",
        "    t1 = df['tags'][i]\n",
        "    d[f'{tag} (w)'] = np.pad(s1, (0,90-len(s1)))\n",
        "    d[f'{tag} (t)'] = np.pad(t1, (0,90-len(t1)))\n",
        "\n",
        "with open('phrase_examples.csv', 'w') as f:\n",
        "    f.write(pd.DataFrame(d).to_csv())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VjKb81QgIpM"
      },
      "source": [
        "After examining the resulting file, we know what the punctuation tags are. Let's put them in a list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "plFOBkssgIpM"
      },
      "outputs": [],
      "source": [
        "punctuation_tags = [',',\n",
        "                    '.',\n",
        "                    '``',\n",
        "                    \"''\",\n",
        "                    ':',\n",
        "                    '-LRB-',\n",
        "                    '-RRB-']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2rKisskgIpM"
      },
      "source": [
        "## Padding x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESiLWuI4gIpM",
        "outputId": "f96d4e93-9510-43ca-d2b9-61896173e235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The padding length is 44\n"
          ]
        }
      ],
      "source": [
        "padding_length = int(df['tags'].apply(lambda x: len(x)).quantile(0.95))\n",
        "print(\"The padding length is\", padding_length)\n",
        "\n",
        "dataset_dict = {k: i for i, k in enumerate(dataset_vocabulary)}\n",
        "\n",
        "def tokenize_x(x):\n",
        "    return [[dataset_dict[word] for word in phrase] for phrase in x]\n",
        "\n",
        "x_train_tokenized = tokenize_x(x_train)\n",
        "x_val_tokenized = tokenize_x(x_val)\n",
        "x_test_tokenized = tokenize_x(x_test)\n",
        "\n",
        "x_train_pad = tf.keras.preprocessing.sequence.pad_sequences(x_train_tokenized, maxlen=padding_length, padding=\"post\")\n",
        "x_val_pad = tf.keras.preprocessing.sequence.pad_sequences(x_val_tokenized, maxlen=padding_length, padding=\"post\")\n",
        "x_test_pad = tf.keras.preprocessing.sequence.pad_sequences(x_test_tokenized, maxlen=padding_length, padding=\"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NsGEMRh-gIpM"
      },
      "source": [
        "## Padding y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tznLopnrgIpM"
      },
      "outputs": [],
      "source": [
        "tag_dict = {k: i for i, k in enumerate(tag_vocabulary)}\n",
        "\n",
        "def tokenize_y(y):\n",
        "    return [[tag_dict[tag] for tag in phrase] for phrase in y]\n",
        "\n",
        "y_train_tokenized = tokenize_y(y_train)\n",
        "y_val_tokenized = tokenize_y(y_val)\n",
        "y_test_tokenized = tokenize_y(y_test)\n",
        "\n",
        "y_train_pad = tf.keras.preprocessing.sequence.pad_sequences(y_train_tokenized, maxlen=padding_length, padding=\"post\")\n",
        "y_val_pad = tf.keras.preprocessing.sequence.pad_sequences(y_val_tokenized, maxlen=padding_length, padding=\"post\")\n",
        "y_test_pad = tf.keras.preprocessing.sequence.pad_sequences(y_test_tokenized, maxlen=padding_length, padding=\"post\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "21U5S5GYgIpN"
      },
      "source": [
        "# Train Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bVXtGu6dgIpN"
      },
      "outputs": [],
      "source": [
        "from keras.optimizer_v2.adam import Adam\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from functools import partial\n",
        "\n",
        "from utils.training_utils import MyHistory, plot_history\n",
        "from models import embedding_layer\n",
        "\n",
        "embedding_func = partial(embedding_layer,\n",
        "                         vocabulary=dataset_vocabulary,\n",
        "                         embedding_model=my_embedding_model,\n",
        "                         embedding_dimension=my_embedding_dimension)\n",
        "\n",
        "try:\n",
        "    weights_folder = os.path.join(drive_folder, \"weights\")\n",
        "except NameError as e:\n",
        "    weights_folder = \"weights\"\n",
        "\n",
        "checkpoint_partial = partial(ModelCheckpoint, monitor=\"val_loss\", mode=\"auto\")#, save_format=\"tf\")\n",
        "compile_args = dict(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
        "\n",
        "input_shape = (padding_length, my_embedding_dimension)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llojTn_UgIpN"
      },
      "source": [
        "## Baseline LSTM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hfa8_PBLgIpN",
        "outputId": "fda13aa4-490a-48b6-eaed-5f060a981560"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 4s 132ms/step - loss: 3.7878 - acc: 0.0684 - val_loss: 3.7559 - val_acc: 0.2263\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.7388 - acc: 0.3667 - val_loss: 3.7079 - val_acc: 0.4647\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 3.6892 - acc: 0.4811 - val_loss: 3.6584 - val_acc: 0.5092\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 3.6374 - acc: 0.5160 - val_loss: 3.6058 - val_acc: 0.5332\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 3.5811 - acc: 0.5332 - val_loss: 3.5475 - val_acc: 0.5430\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 3.5180 - acc: 0.5395 - val_loss: 3.4804 - val_acc: 0.5443\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 3.4436 - acc: 0.5402 - val_loss: 3.4000 - val_acc: 0.5425\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 3.3533 - acc: 0.5383 - val_loss: 3.3000 - val_acc: 0.5391\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 3.2393 - acc: 0.5355 - val_loss: 3.1725 - val_acc: 0.5353\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 3.0941 - acc: 0.5325 - val_loss: 3.0092 - val_acc: 0.5300\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 2.9115 - acc: 0.5294 - val_loss: 2.8128 - val_acc: 0.5269\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.7066 - acc: 0.5274 - val_loss: 2.6083 - val_acc: 0.5246\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.5125 - acc: 0.5262 - val_loss: 2.4308 - val_acc: 0.5230\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.3534 - acc: 0.5253 - val_loss: 2.2915 - val_acc: 0.5220\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 2.2287 - acc: 0.5247 - val_loss: 2.1831 - val_acc: 0.5217\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 2.1309 - acc: 0.5243 - val_loss: 2.0959 - val_acc: 0.5218\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 2.0519 - acc: 0.5243 - val_loss: 2.0242 - val_acc: 0.5225\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.9863 - acc: 0.5247 - val_loss: 1.9641 - val_acc: 0.5237\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.9313 - acc: 0.5257 - val_loss: 1.9125 - val_acc: 0.5248\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.8838 - acc: 0.5266 - val_loss: 1.8675 - val_acc: 0.5265\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.8424 - acc: 0.5279 - val_loss: 1.8282 - val_acc: 0.5288\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.8063 - acc: 0.5302 - val_loss: 1.7939 - val_acc: 0.5313\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.7750 - acc: 0.5325 - val_loss: 1.7642 - val_acc: 0.5342\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.7477 - acc: 0.5350 - val_loss: 1.7388 - val_acc: 0.5370\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.7239 - acc: 0.5374 - val_loss: 1.7164 - val_acc: 0.5399\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.7027 - acc: 0.5400 - val_loss: 1.6965 - val_acc: 0.5429\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.6836 - acc: 0.5432 - val_loss: 1.6787 - val_acc: 0.5467\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.6664 - acc: 0.5459 - val_loss: 1.6625 - val_acc: 0.5503\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.6507 - acc: 0.5492 - val_loss: 1.6476 - val_acc: 0.5541\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.6362 - acc: 0.5529 - val_loss: 1.6338 - val_acc: 0.5577\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.6228 - acc: 0.5565 - val_loss: 1.6208 - val_acc: 0.5609\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.6102 - acc: 0.5596 - val_loss: 1.6086 - val_acc: 0.5641\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5982 - acc: 0.5627 - val_loss: 1.5971 - val_acc: 0.5665\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5868 - acc: 0.5655 - val_loss: 1.5861 - val_acc: 0.5693\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5759 - acc: 0.5686 - val_loss: 1.5755 - val_acc: 0.5731\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.5654 - acc: 0.5721 - val_loss: 1.5652 - val_acc: 0.5765\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5552 - acc: 0.5749 - val_loss: 1.5553 - val_acc: 0.5782\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.5454 - acc: 0.5776 - val_loss: 1.5458 - val_acc: 0.5820\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.5359 - acc: 0.5807 - val_loss: 1.5366 - val_acc: 0.5847\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.5266 - acc: 0.5836 - val_loss: 1.5276 - val_acc: 0.5878\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.5176 - acc: 0.5873 - val_loss: 1.5188 - val_acc: 0.5913\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.5088 - acc: 0.5899 - val_loss: 1.5102 - val_acc: 0.5936\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5002 - acc: 0.5924 - val_loss: 1.5017 - val_acc: 0.5964\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.4917 - acc: 0.5949 - val_loss: 1.4934 - val_acc: 0.5990\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.4834 - acc: 0.5975 - val_loss: 1.4852 - val_acc: 0.6024\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.4752 - acc: 0.6008 - val_loss: 1.4771 - val_acc: 0.6049\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.4672 - acc: 0.6034 - val_loss: 1.4691 - val_acc: 0.6079\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.4592 - acc: 0.6067 - val_loss: 1.4613 - val_acc: 0.6110\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4513 - acc: 0.6095 - val_loss: 1.4536 - val_acc: 0.6136\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.4436 - acc: 0.6123 - val_loss: 1.4458 - val_acc: 0.6164\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.4359 - acc: 0.6148 - val_loss: 1.4383 - val_acc: 0.6189\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.4283 - acc: 0.6180 - val_loss: 1.4308 - val_acc: 0.6218\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.4208 - acc: 0.6203 - val_loss: 1.4235 - val_acc: 0.6247\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.4134 - acc: 0.6231 - val_loss: 1.4160 - val_acc: 0.6270\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.4061 - acc: 0.6266 - val_loss: 1.4086 - val_acc: 0.6306\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3988 - acc: 0.6288 - val_loss: 1.4016 - val_acc: 0.6338\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3916 - acc: 0.6321 - val_loss: 1.3943 - val_acc: 0.6365\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3844 - acc: 0.6352 - val_loss: 1.3872 - val_acc: 0.6396\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.3773 - acc: 0.6387 - val_loss: 1.3801 - val_acc: 0.6428\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3703 - acc: 0.6414 - val_loss: 1.3731 - val_acc: 0.6456\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3633 - acc: 0.6442 - val_loss: 1.3661 - val_acc: 0.6490\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3563 - acc: 0.6479 - val_loss: 1.3591 - val_acc: 0.6517\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3493 - acc: 0.6512 - val_loss: 1.3523 - val_acc: 0.6548\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3425 - acc: 0.6540 - val_loss: 1.3454 - val_acc: 0.6573\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.3356 - acc: 0.6569 - val_loss: 1.3386 - val_acc: 0.6606\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.3288 - acc: 0.6597 - val_loss: 1.3317 - val_acc: 0.6635\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.3220 - acc: 0.6620 - val_loss: 1.3250 - val_acc: 0.6658\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.3152 - acc: 0.6645 - val_loss: 1.3182 - val_acc: 0.6686\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.3084 - acc: 0.6675 - val_loss: 1.3115 - val_acc: 0.6711\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.3017 - acc: 0.6697 - val_loss: 1.3049 - val_acc: 0.6731\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.2950 - acc: 0.6718 - val_loss: 1.2982 - val_acc: 0.6753\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.2883 - acc: 0.6747 - val_loss: 1.2915 - val_acc: 0.6777\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.2817 - acc: 0.6771 - val_loss: 1.2849 - val_acc: 0.6802\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.2750 - acc: 0.6795 - val_loss: 1.2783 - val_acc: 0.6824\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.2684 - acc: 0.6815 - val_loss: 1.2719 - val_acc: 0.6848\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.2618 - acc: 0.6834 - val_loss: 1.2652 - val_acc: 0.6870\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.2553 - acc: 0.6863 - val_loss: 1.2587 - val_acc: 0.6890\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.2487 - acc: 0.6883 - val_loss: 1.2524 - val_acc: 0.6903\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.2422 - acc: 0.6906 - val_loss: 1.2458 - val_acc: 0.6936\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.2357 - acc: 0.6927 - val_loss: 1.2395 - val_acc: 0.6943\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.2294 - acc: 0.6940 - val_loss: 1.2330 - val_acc: 0.6960\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.2229 - acc: 0.6962 - val_loss: 1.2271 - val_acc: 0.6983\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.2165 - acc: 0.6983 - val_loss: 1.2206 - val_acc: 0.6998\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.2101 - acc: 0.7002 - val_loss: 1.2143 - val_acc: 0.7014\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.2037 - acc: 0.7018 - val_loss: 1.2080 - val_acc: 0.7031\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1974 - acc: 0.7035 - val_loss: 1.2017 - val_acc: 0.7047\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.1911 - acc: 0.7051 - val_loss: 1.1954 - val_acc: 0.7060\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.1848 - acc: 0.7067 - val_loss: 1.1893 - val_acc: 0.7073\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1786 - acc: 0.7080 - val_loss: 1.1832 - val_acc: 0.7085\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1723 - acc: 0.7099 - val_loss: 1.1770 - val_acc: 0.7099\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1661 - acc: 0.7114 - val_loss: 1.1710 - val_acc: 0.7112\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.1599 - acc: 0.7126 - val_loss: 1.1649 - val_acc: 0.7125\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1538 - acc: 0.7138 - val_loss: 1.1589 - val_acc: 0.7140\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1477 - acc: 0.7150 - val_loss: 1.1530 - val_acc: 0.7151\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1417 - acc: 0.7164 - val_loss: 1.1471 - val_acc: 0.7166\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.1357 - acc: 0.7178 - val_loss: 1.1413 - val_acc: 0.7177\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.1297 - acc: 0.7192 - val_loss: 1.1353 - val_acc: 0.7190\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.1237 - acc: 0.7203 - val_loss: 1.1296 - val_acc: 0.7197\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.1177 - acc: 0.7217 - val_loss: 1.1238 - val_acc: 0.7211\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1119 - acc: 0.7237 - val_loss: 1.1180 - val_acc: 0.7230\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.1061 - acc: 0.7249 - val_loss: 1.1124 - val_acc: 0.7241\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1002 - acc: 0.7262 - val_loss: 1.1068 - val_acc: 0.7253\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0945 - acc: 0.7281 - val_loss: 1.1010 - val_acc: 0.7269\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.0887 - acc: 0.7296 - val_loss: 1.0956 - val_acc: 0.7283\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0830 - acc: 0.7305 - val_loss: 1.0900 - val_acc: 0.7293\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.0773 - acc: 0.7320 - val_loss: 1.0845 - val_acc: 0.7309\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.0717 - acc: 0.7335 - val_loss: 1.0793 - val_acc: 0.7328\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.0661 - acc: 0.7349 - val_loss: 1.0736 - val_acc: 0.7331\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.0606 - acc: 0.7361 - val_loss: 1.0684 - val_acc: 0.7341\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.0551 - acc: 0.7370 - val_loss: 1.0629 - val_acc: 0.7360\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 1.0496 - acc: 0.7386 - val_loss: 1.0577 - val_acc: 0.7373\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.0442 - acc: 0.7401 - val_loss: 1.0525 - val_acc: 0.7387\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.0388 - acc: 0.7415 - val_loss: 1.0472 - val_acc: 0.7401\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.0335 - acc: 0.7425 - val_loss: 1.0421 - val_acc: 0.7414\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.0282 - acc: 0.7439 - val_loss: 1.0372 - val_acc: 0.7419\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0231 - acc: 0.7450 - val_loss: 1.0320 - val_acc: 0.7435\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.0177 - acc: 0.7463 - val_loss: 1.0269 - val_acc: 0.7449\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.0126 - acc: 0.7476 - val_loss: 1.0219 - val_acc: 0.7464\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.0074 - acc: 0.7491 - val_loss: 1.0171 - val_acc: 0.7470\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.0024 - acc: 0.7501 - val_loss: 1.0121 - val_acc: 0.7482\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9973 - acc: 0.7514 - val_loss: 1.0073 - val_acc: 0.7494\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9923 - acc: 0.7524 - val_loss: 1.0025 - val_acc: 0.7503\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9874 - acc: 0.7538 - val_loss: 0.9977 - val_acc: 0.7511\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9825 - acc: 0.7548 - val_loss: 0.9931 - val_acc: 0.7521\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9776 - acc: 0.7560 - val_loss: 0.9883 - val_acc: 0.7535\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9728 - acc: 0.7571 - val_loss: 0.9837 - val_acc: 0.7543\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9680 - acc: 0.7582 - val_loss: 0.9791 - val_acc: 0.7559\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9633 - acc: 0.7591 - val_loss: 0.9747 - val_acc: 0.7566\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9586 - acc: 0.7602 - val_loss: 0.9702 - val_acc: 0.7580\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9540 - acc: 0.7618 - val_loss: 0.9656 - val_acc: 0.7588\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9494 - acc: 0.7629 - val_loss: 0.9615 - val_acc: 0.7592\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9448 - acc: 0.7640 - val_loss: 0.9568 - val_acc: 0.7606\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9402 - acc: 0.7653 - val_loss: 0.9524 - val_acc: 0.7619\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9357 - acc: 0.7664 - val_loss: 0.9483 - val_acc: 0.7635\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9313 - acc: 0.7677 - val_loss: 0.9441 - val_acc: 0.7646\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9268 - acc: 0.7688 - val_loss: 0.9396 - val_acc: 0.7651\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9225 - acc: 0.7696 - val_loss: 0.9354 - val_acc: 0.7657\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9181 - acc: 0.7708 - val_loss: 0.9312 - val_acc: 0.7667\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9138 - acc: 0.7719 - val_loss: 0.9271 - val_acc: 0.7683\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9095 - acc: 0.7731 - val_loss: 0.9231 - val_acc: 0.7693\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.9052 - acc: 0.7743 - val_loss: 0.9190 - val_acc: 0.7703\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9011 - acc: 0.7755 - val_loss: 0.9150 - val_acc: 0.7713\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8969 - acc: 0.7764 - val_loss: 0.9109 - val_acc: 0.7721\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8928 - acc: 0.7775 - val_loss: 0.9070 - val_acc: 0.7731\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8887 - acc: 0.7787 - val_loss: 0.9031 - val_acc: 0.7737\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8846 - acc: 0.7798 - val_loss: 0.8992 - val_acc: 0.7746\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8806 - acc: 0.7809 - val_loss: 0.8953 - val_acc: 0.7754\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8766 - acc: 0.7817 - val_loss: 0.8916 - val_acc: 0.7768\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8727 - acc: 0.7826 - val_loss: 0.8878 - val_acc: 0.7775\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8688 - acc: 0.7840 - val_loss: 0.8839 - val_acc: 0.7785\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8649 - acc: 0.7850 - val_loss: 0.8803 - val_acc: 0.7789\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8610 - acc: 0.7858 - val_loss: 0.8766 - val_acc: 0.7798\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8572 - acc: 0.7868 - val_loss: 0.8729 - val_acc: 0.7807\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8534 - acc: 0.7880 - val_loss: 0.8693 - val_acc: 0.7817\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8497 - acc: 0.7889 - val_loss: 0.8657 - val_acc: 0.7823\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8460 - acc: 0.7896 - val_loss: 0.8621 - val_acc: 0.7831\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8423 - acc: 0.7907 - val_loss: 0.8586 - val_acc: 0.7840\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8387 - acc: 0.7917 - val_loss: 0.8551 - val_acc: 0.7848\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.8350 - acc: 0.7929 - val_loss: 0.8517 - val_acc: 0.7855\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8314 - acc: 0.7939 - val_loss: 0.8481 - val_acc: 0.7867\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8278 - acc: 0.7946 - val_loss: 0.8447 - val_acc: 0.7877\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8243 - acc: 0.7954 - val_loss: 0.8413 - val_acc: 0.7886\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8209 - acc: 0.7962 - val_loss: 0.8379 - val_acc: 0.7893\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8173 - acc: 0.7967 - val_loss: 0.8347 - val_acc: 0.7901\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8139 - acc: 0.7978 - val_loss: 0.8313 - val_acc: 0.7905\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8105 - acc: 0.7988 - val_loss: 0.8282 - val_acc: 0.7911\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.8071 - acc: 0.7997 - val_loss: 0.8247 - val_acc: 0.7921\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8037 - acc: 0.8003 - val_loss: 0.8215 - val_acc: 0.7929\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8004 - acc: 0.8011 - val_loss: 0.8183 - val_acc: 0.7934\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7971 - acc: 0.8018 - val_loss: 0.8152 - val_acc: 0.7941\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7938 - acc: 0.8025 - val_loss: 0.8120 - val_acc: 0.7956\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7906 - acc: 0.8035 - val_loss: 0.8089 - val_acc: 0.7965\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7873 - acc: 0.8047 - val_loss: 0.8057 - val_acc: 0.7973\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7841 - acc: 0.8053 - val_loss: 0.8027 - val_acc: 0.7977\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7810 - acc: 0.8065 - val_loss: 0.7996 - val_acc: 0.7984\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7778 - acc: 0.8075 - val_loss: 0.7966 - val_acc: 0.7991\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7748 - acc: 0.8078 - val_loss: 0.7936 - val_acc: 0.8003\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7717 - acc: 0.8083 - val_loss: 0.7906 - val_acc: 0.8014\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7686 - acc: 0.8096 - val_loss: 0.7877 - val_acc: 0.8018\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7655 - acc: 0.8106 - val_loss: 0.7847 - val_acc: 0.8025\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7625 - acc: 0.8112 - val_loss: 0.7818 - val_acc: 0.8034\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7595 - acc: 0.8120 - val_loss: 0.7789 - val_acc: 0.8041\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7565 - acc: 0.8128 - val_loss: 0.7760 - val_acc: 0.8048\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7535 - acc: 0.8134 - val_loss: 0.7732 - val_acc: 0.8056\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7506 - acc: 0.8141 - val_loss: 0.7703 - val_acc: 0.8063\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7477 - acc: 0.8151 - val_loss: 0.7676 - val_acc: 0.8074\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7449 - acc: 0.8159 - val_loss: 0.7648 - val_acc: 0.8079\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7420 - acc: 0.8165 - val_loss: 0.7621 - val_acc: 0.8089\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7392 - acc: 0.8173 - val_loss: 0.7594 - val_acc: 0.8094\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7364 - acc: 0.8180 - val_loss: 0.7566 - val_acc: 0.8103\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7336 - acc: 0.8188 - val_loss: 0.7539 - val_acc: 0.8107\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.7309 - acc: 0.8198 - val_loss: 0.7512 - val_acc: 0.8115\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7281 - acc: 0.8201 - val_loss: 0.7486 - val_acc: 0.8123\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7254 - acc: 0.8210 - val_loss: 0.7460 - val_acc: 0.8127\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7227 - acc: 0.8220 - val_loss: 0.7434 - val_acc: 0.8135\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7200 - acc: 0.8227 - val_loss: 0.7407 - val_acc: 0.8144\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7174 - acc: 0.8232 - val_loss: 0.7382 - val_acc: 0.8151\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7148 - acc: 0.8242 - val_loss: 0.7357 - val_acc: 0.8158\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7122 - acc: 0.8250 - val_loss: 0.7332 - val_acc: 0.8162\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7096 - acc: 0.8255 - val_loss: 0.7307 - val_acc: 0.8169\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7070 - acc: 0.8264 - val_loss: 0.7282 - val_acc: 0.8176\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.7045 - acc: 0.8272 - val_loss: 0.7257 - val_acc: 0.8181\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7019 - acc: 0.8279 - val_loss: 0.7233 - val_acc: 0.8187\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6994 - acc: 0.8284 - val_loss: 0.7208 - val_acc: 0.8195\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6969 - acc: 0.8290 - val_loss: 0.7185 - val_acc: 0.8200\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6945 - acc: 0.8298 - val_loss: 0.7161 - val_acc: 0.8206\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6920 - acc: 0.8302 - val_loss: 0.7136 - val_acc: 0.8213\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.6896 - acc: 0.8308 - val_loss: 0.7113 - val_acc: 0.8219\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6871 - acc: 0.8316 - val_loss: 0.7090 - val_acc: 0.8223\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6848 - acc: 0.8321 - val_loss: 0.7067 - val_acc: 0.8228\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6824 - acc: 0.8325 - val_loss: 0.7044 - val_acc: 0.8235\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6800 - acc: 0.8331 - val_loss: 0.7021 - val_acc: 0.8239\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6777 - acc: 0.8337 - val_loss: 0.6998 - val_acc: 0.8244\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6754 - acc: 0.8343 - val_loss: 0.6976 - val_acc: 0.8247\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6731 - acc: 0.8348 - val_loss: 0.6953 - val_acc: 0.8254\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6708 - acc: 0.8353 - val_loss: 0.6931 - val_acc: 0.8258\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6685 - acc: 0.8359 - val_loss: 0.6909 - val_acc: 0.8263\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6663 - acc: 0.8366 - val_loss: 0.6887 - val_acc: 0.8268\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6641 - acc: 0.8371 - val_loss: 0.6866 - val_acc: 0.8272\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6619 - acc: 0.8376 - val_loss: 0.6845 - val_acc: 0.8277\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6596 - acc: 0.8379 - val_loss: 0.6824 - val_acc: 0.8282\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6574 - acc: 0.8384 - val_loss: 0.6802 - val_acc: 0.8289\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6553 - acc: 0.8389 - val_loss: 0.6782 - val_acc: 0.8294\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6532 - acc: 0.8392 - val_loss: 0.6761 - val_acc: 0.8296\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6510 - acc: 0.8396 - val_loss: 0.6740 - val_acc: 0.8301\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6489 - acc: 0.8400 - val_loss: 0.6720 - val_acc: 0.8305\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6468 - acc: 0.8403 - val_loss: 0.6699 - val_acc: 0.8312\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6447 - acc: 0.8407 - val_loss: 0.6679 - val_acc: 0.8317\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6426 - acc: 0.8411 - val_loss: 0.6659 - val_acc: 0.8321\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6406 - acc: 0.8419 - val_loss: 0.6640 - val_acc: 0.8325\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6386 - acc: 0.8422 - val_loss: 0.6619 - val_acc: 0.8331\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6366 - acc: 0.8427 - val_loss: 0.6600 - val_acc: 0.8333\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.6345 - acc: 0.8433 - val_loss: 0.6580 - val_acc: 0.8337\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6325 - acc: 0.8435 - val_loss: 0.6561 - val_acc: 0.8341\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6306 - acc: 0.8440 - val_loss: 0.6543 - val_acc: 0.8345\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6286 - acc: 0.8445 - val_loss: 0.6523 - val_acc: 0.8351\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.6267 - acc: 0.8449 - val_loss: 0.6505 - val_acc: 0.8354\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6247 - acc: 0.8453 - val_loss: 0.6485 - val_acc: 0.8360\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6228 - acc: 0.8457 - val_loss: 0.6467 - val_acc: 0.8361\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6209 - acc: 0.8462 - val_loss: 0.6448 - val_acc: 0.8366\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6190 - acc: 0.8466 - val_loss: 0.6430 - val_acc: 0.8369\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6171 - acc: 0.8469 - val_loss: 0.6412 - val_acc: 0.8377\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6152 - acc: 0.8473 - val_loss: 0.6394 - val_acc: 0.8380\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6134 - acc: 0.8478 - val_loss: 0.6375 - val_acc: 0.8385\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6116 - acc: 0.8480 - val_loss: 0.6358 - val_acc: 0.8389\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6097 - acc: 0.8485 - val_loss: 0.6340 - val_acc: 0.8394\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6079 - acc: 0.8491 - val_loss: 0.6322 - val_acc: 0.8397\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6062 - acc: 0.8495 - val_loss: 0.6305 - val_acc: 0.8402\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6043 - acc: 0.8499 - val_loss: 0.6288 - val_acc: 0.8404\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6026 - acc: 0.8501 - val_loss: 0.6270 - val_acc: 0.8406\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6008 - acc: 0.8503 - val_loss: 0.6254 - val_acc: 0.8408\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5991 - acc: 0.8506 - val_loss: 0.6237 - val_acc: 0.8415\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.5973 - acc: 0.8511 - val_loss: 0.6220 - val_acc: 0.8418\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5956 - acc: 0.8514 - val_loss: 0.6203 - val_acc: 0.8422\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5939 - acc: 0.8518 - val_loss: 0.6186 - val_acc: 0.8425\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5922 - acc: 0.8523 - val_loss: 0.6170 - val_acc: 0.8427\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5905 - acc: 0.8525 - val_loss: 0.6154 - val_acc: 0.8431\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5888 - acc: 0.8530 - val_loss: 0.6137 - val_acc: 0.8436\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5872 - acc: 0.8533 - val_loss: 0.6122 - val_acc: 0.8438\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5855 - acc: 0.8536 - val_loss: 0.6106 - val_acc: 0.8441\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5838 - acc: 0.8539 - val_loss: 0.6090 - val_acc: 0.8444\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5822 - acc: 0.8543 - val_loss: 0.6074 - val_acc: 0.8447\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5806 - acc: 0.8545 - val_loss: 0.6058 - val_acc: 0.8452\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5790 - acc: 0.8548 - val_loss: 0.6043 - val_acc: 0.8452\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5774 - acc: 0.8551 - val_loss: 0.6027 - val_acc: 0.8454\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5758 - acc: 0.8556 - val_loss: 0.6012 - val_acc: 0.8458\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5742 - acc: 0.8558 - val_loss: 0.5997 - val_acc: 0.8458\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5726 - acc: 0.8561 - val_loss: 0.5981 - val_acc: 0.8463\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5711 - acc: 0.8565 - val_loss: 0.5966 - val_acc: 0.8465\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5695 - acc: 0.8567 - val_loss: 0.5951 - val_acc: 0.8468\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5680 - acc: 0.8569 - val_loss: 0.5936 - val_acc: 0.8470\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5664 - acc: 0.8576 - val_loss: 0.5922 - val_acc: 0.8473\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.5650 - acc: 0.8577 - val_loss: 0.5908 - val_acc: 0.8476\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5635 - acc: 0.8579 - val_loss: 0.5892 - val_acc: 0.8478\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5620 - acc: 0.8581 - val_loss: 0.5878 - val_acc: 0.8481\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5604 - acc: 0.8584 - val_loss: 0.5863 - val_acc: 0.8485\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5590 - acc: 0.8588 - val_loss: 0.5850 - val_acc: 0.8486\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5575 - acc: 0.8591 - val_loss: 0.5835 - val_acc: 0.8489\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5560 - acc: 0.8593 - val_loss: 0.5821 - val_acc: 0.8492\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5546 - acc: 0.8595 - val_loss: 0.5807 - val_acc: 0.8494\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5531 - acc: 0.8599 - val_loss: 0.5793 - val_acc: 0.8494\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5517 - acc: 0.8603 - val_loss: 0.5779 - val_acc: 0.8497\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5503 - acc: 0.8606 - val_loss: 0.5766 - val_acc: 0.8500\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.5489 - acc: 0.8608 - val_loss: 0.5752 - val_acc: 0.8503\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5475 - acc: 0.8611 - val_loss: 0.5739 - val_acc: 0.8505\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5461 - acc: 0.8612 - val_loss: 0.5725 - val_acc: 0.8508\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5447 - acc: 0.8615 - val_loss: 0.5712 - val_acc: 0.8510\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5433 - acc: 0.8617 - val_loss: 0.5699 - val_acc: 0.8512\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5419 - acc: 0.8621 - val_loss: 0.5686 - val_acc: 0.8513\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5406 - acc: 0.8624 - val_loss: 0.5672 - val_acc: 0.8514\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5392 - acc: 0.8628 - val_loss: 0.5660 - val_acc: 0.8516\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5379 - acc: 0.8630 - val_loss: 0.5647 - val_acc: 0.8518\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5366 - acc: 0.8634 - val_loss: 0.5634 - val_acc: 0.8521\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.5352 - acc: 0.8637 - val_loss: 0.5621 - val_acc: 0.8525\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5339 - acc: 0.8639 - val_loss: 0.5608 - val_acc: 0.8527\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5326 - acc: 0.8642 - val_loss: 0.5595 - val_acc: 0.8528\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5313 - acc: 0.8645 - val_loss: 0.5583 - val_acc: 0.8531\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5300 - acc: 0.8648 - val_loss: 0.5571 - val_acc: 0.8531\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5287 - acc: 0.8650 - val_loss: 0.5558 - val_acc: 0.8535\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5274 - acc: 0.8653 - val_loss: 0.5546 - val_acc: 0.8537\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5261 - acc: 0.8655 - val_loss: 0.5534 - val_acc: 0.8540\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5249 - acc: 0.8657 - val_loss: 0.5521 - val_acc: 0.8542\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5236 - acc: 0.8661 - val_loss: 0.5509 - val_acc: 0.8546\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5224 - acc: 0.8662 - val_loss: 0.5497 - val_acc: 0.8549\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5211 - acc: 0.8666 - val_loss: 0.5486 - val_acc: 0.8552\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5199 - acc: 0.8669 - val_loss: 0.5473 - val_acc: 0.8554\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5186 - acc: 0.8672 - val_loss: 0.5462 - val_acc: 0.8557\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5174 - acc: 0.8670 - val_loss: 0.5450 - val_acc: 0.8557\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5162 - acc: 0.8674 - val_loss: 0.5438 - val_acc: 0.8562\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5150 - acc: 0.8678 - val_loss: 0.5427 - val_acc: 0.8566\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5138 - acc: 0.8680 - val_loss: 0.5415 - val_acc: 0.8567\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5126 - acc: 0.8683 - val_loss: 0.5404 - val_acc: 0.8571\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5114 - acc: 0.8686 - val_loss: 0.5392 - val_acc: 0.8572\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5102 - acc: 0.8688 - val_loss: 0.5381 - val_acc: 0.8574\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5091 - acc: 0.8691 - val_loss: 0.5369 - val_acc: 0.8575\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5079 - acc: 0.8694 - val_loss: 0.5359 - val_acc: 0.8577\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5067 - acc: 0.8697 - val_loss: 0.5347 - val_acc: 0.8579\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5056 - acc: 0.8698 - val_loss: 0.5336 - val_acc: 0.8581\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5044 - acc: 0.8700 - val_loss: 0.5325 - val_acc: 0.8584\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5033 - acc: 0.8703 - val_loss: 0.5314 - val_acc: 0.8587\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5021 - acc: 0.8705 - val_loss: 0.5303 - val_acc: 0.8589\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5010 - acc: 0.8708 - val_loss: 0.5293 - val_acc: 0.8592\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4999 - acc: 0.8709 - val_loss: 0.5283 - val_acc: 0.8593\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4988 - acc: 0.8711 - val_loss: 0.5271 - val_acc: 0.8596\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4977 - acc: 0.8713 - val_loss: 0.5262 - val_acc: 0.8596\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4966 - acc: 0.8716 - val_loss: 0.5250 - val_acc: 0.8596\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4954 - acc: 0.8720 - val_loss: 0.5239 - val_acc: 0.8599\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4943 - acc: 0.8719 - val_loss: 0.5229 - val_acc: 0.8602\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4932 - acc: 0.8721 - val_loss: 0.5219 - val_acc: 0.8603\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4922 - acc: 0.8724 - val_loss: 0.5208 - val_acc: 0.8604\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4911 - acc: 0.8726 - val_loss: 0.5198 - val_acc: 0.8607\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4900 - acc: 0.8729 - val_loss: 0.5187 - val_acc: 0.8609\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4889 - acc: 0.8730 - val_loss: 0.5177 - val_acc: 0.8614\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4878 - acc: 0.8734 - val_loss: 0.5167 - val_acc: 0.8614\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4868 - acc: 0.8736 - val_loss: 0.5157 - val_acc: 0.8616\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4857 - acc: 0.8739 - val_loss: 0.5147 - val_acc: 0.8618\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4847 - acc: 0.8743 - val_loss: 0.5138 - val_acc: 0.8620\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4836 - acc: 0.8744 - val_loss: 0.5128 - val_acc: 0.8624\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4826 - acc: 0.8747 - val_loss: 0.5117 - val_acc: 0.8624\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4816 - acc: 0.8748 - val_loss: 0.5107 - val_acc: 0.8628\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4806 - acc: 0.8750 - val_loss: 0.5098 - val_acc: 0.8627\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4795 - acc: 0.8754 - val_loss: 0.5088 - val_acc: 0.8629\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4785 - acc: 0.8756 - val_loss: 0.5078 - val_acc: 0.8630\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4775 - acc: 0.8756 - val_loss: 0.5069 - val_acc: 0.8633\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.4765 - acc: 0.8756 - val_loss: 0.5059 - val_acc: 0.8638\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.4755 - acc: 0.8760 - val_loss: 0.5050 - val_acc: 0.8640\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4745 - acc: 0.8760 - val_loss: 0.5040 - val_acc: 0.8641\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4735 - acc: 0.8763 - val_loss: 0.5031 - val_acc: 0.8644\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4725 - acc: 0.8766 - val_loss: 0.5022 - val_acc: 0.8646\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4715 - acc: 0.8768 - val_loss: 0.5012 - val_acc: 0.8648\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4706 - acc: 0.8770 - val_loss: 0.5002 - val_acc: 0.8650\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4696 - acc: 0.8771 - val_loss: 0.4993 - val_acc: 0.8651\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4686 - acc: 0.8773 - val_loss: 0.4984 - val_acc: 0.8652\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4677 - acc: 0.8773 - val_loss: 0.4975 - val_acc: 0.8654\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4667 - acc: 0.8775 - val_loss: 0.4967 - val_acc: 0.8655\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4657 - acc: 0.8778 - val_loss: 0.4957 - val_acc: 0.8660\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4648 - acc: 0.8782 - val_loss: 0.4949 - val_acc: 0.8660\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4638 - acc: 0.8783 - val_loss: 0.4939 - val_acc: 0.8663\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4629 - acc: 0.8785 - val_loss: 0.4932 - val_acc: 0.8662\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4620 - acc: 0.8785 - val_loss: 0.4921 - val_acc: 0.8668\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4610 - acc: 0.8787 - val_loss: 0.4912 - val_acc: 0.8669\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4601 - acc: 0.8788 - val_loss: 0.4904 - val_acc: 0.8669\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4591 - acc: 0.8792 - val_loss: 0.4895 - val_acc: 0.8673\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4582 - acc: 0.8794 - val_loss: 0.4887 - val_acc: 0.8674\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4573 - acc: 0.8794 - val_loss: 0.4877 - val_acc: 0.8678\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4564 - acc: 0.8797 - val_loss: 0.4869 - val_acc: 0.8677\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4555 - acc: 0.8799 - val_loss: 0.4860 - val_acc: 0.8684\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4546 - acc: 0.8801 - val_loss: 0.4852 - val_acc: 0.8685\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4537 - acc: 0.8801 - val_loss: 0.4843 - val_acc: 0.8687\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4528 - acc: 0.8804 - val_loss: 0.4835 - val_acc: 0.8690\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.4519 - acc: 0.8804 - val_loss: 0.4826 - val_acc: 0.8692\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4510 - acc: 0.8806 - val_loss: 0.4818 - val_acc: 0.8693\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4501 - acc: 0.8808 - val_loss: 0.4810 - val_acc: 0.8695\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4493 - acc: 0.8810 - val_loss: 0.4801 - val_acc: 0.8698\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4484 - acc: 0.8813 - val_loss: 0.4793 - val_acc: 0.8699\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4475 - acc: 0.8815 - val_loss: 0.4785 - val_acc: 0.8700\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4466 - acc: 0.8816 - val_loss: 0.4777 - val_acc: 0.8701\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4457 - acc: 0.8818 - val_loss: 0.4769 - val_acc: 0.8705\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4449 - acc: 0.8818 - val_loss: 0.4760 - val_acc: 0.8707\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4440 - acc: 0.8820 - val_loss: 0.4752 - val_acc: 0.8708\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4432 - acc: 0.8821 - val_loss: 0.4745 - val_acc: 0.8708\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4423 - acc: 0.8822 - val_loss: 0.4737 - val_acc: 0.8709\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4415 - acc: 0.8824 - val_loss: 0.4728 - val_acc: 0.8713\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4406 - acc: 0.8827 - val_loss: 0.4721 - val_acc: 0.8713\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4398 - acc: 0.8829 - val_loss: 0.4712 - val_acc: 0.8716\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4389 - acc: 0.8831 - val_loss: 0.4705 - val_acc: 0.8716\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4381 - acc: 0.8832 - val_loss: 0.4697 - val_acc: 0.8718\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4372 - acc: 0.8834 - val_loss: 0.4690 - val_acc: 0.8719\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4365 - acc: 0.8834 - val_loss: 0.4681 - val_acc: 0.8722\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4356 - acc: 0.8837 - val_loss: 0.4674 - val_acc: 0.8723\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4348 - acc: 0.8840 - val_loss: 0.4666 - val_acc: 0.8724\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4340 - acc: 0.8841 - val_loss: 0.4659 - val_acc: 0.8725\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4332 - acc: 0.8843 - val_loss: 0.4651 - val_acc: 0.8728\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4324 - acc: 0.8846 - val_loss: 0.4643 - val_acc: 0.8730\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4316 - acc: 0.8848 - val_loss: 0.4637 - val_acc: 0.8729\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4308 - acc: 0.8847 - val_loss: 0.4628 - val_acc: 0.8733\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4299 - acc: 0.8850 - val_loss: 0.4621 - val_acc: 0.8733\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4291 - acc: 0.8852 - val_loss: 0.4613 - val_acc: 0.8734\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4283 - acc: 0.8854 - val_loss: 0.4606 - val_acc: 0.8736\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4275 - acc: 0.8856 - val_loss: 0.4598 - val_acc: 0.8737\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4268 - acc: 0.8857 - val_loss: 0.4592 - val_acc: 0.8738\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4260 - acc: 0.8860 - val_loss: 0.4583 - val_acc: 0.8740\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4252 - acc: 0.8860 - val_loss: 0.4576 - val_acc: 0.8742\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4244 - acc: 0.8862 - val_loss: 0.4569 - val_acc: 0.8743\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4236 - acc: 0.8863 - val_loss: 0.4561 - val_acc: 0.8746\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.4228 - acc: 0.8867 - val_loss: 0.4555 - val_acc: 0.8746\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4221 - acc: 0.8867 - val_loss: 0.4547 - val_acc: 0.8748\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4213 - acc: 0.8871 - val_loss: 0.4541 - val_acc: 0.8749\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.4206 - acc: 0.8872 - val_loss: 0.4533 - val_acc: 0.8752\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4198 - acc: 0.8873 - val_loss: 0.4527 - val_acc: 0.8754\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4190 - acc: 0.8877 - val_loss: 0.4519 - val_acc: 0.8756\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4183 - acc: 0.8878 - val_loss: 0.4512 - val_acc: 0.8757\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4175 - acc: 0.8881 - val_loss: 0.4505 - val_acc: 0.8757\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4168 - acc: 0.8881 - val_loss: 0.4498 - val_acc: 0.8758\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4160 - acc: 0.8883 - val_loss: 0.4491 - val_acc: 0.8761\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4153 - acc: 0.8886 - val_loss: 0.4484 - val_acc: 0.8763\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4145 - acc: 0.8888 - val_loss: 0.4477 - val_acc: 0.8764\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4138 - acc: 0.8890 - val_loss: 0.4471 - val_acc: 0.8763\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4130 - acc: 0.8892 - val_loss: 0.4464 - val_acc: 0.8767\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4123 - acc: 0.8892 - val_loss: 0.4457 - val_acc: 0.8769\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4116 - acc: 0.8896 - val_loss: 0.4451 - val_acc: 0.8770\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4109 - acc: 0.8897 - val_loss: 0.4444 - val_acc: 0.8770\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4101 - acc: 0.8897 - val_loss: 0.4437 - val_acc: 0.8774\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4094 - acc: 0.8900 - val_loss: 0.4431 - val_acc: 0.8774\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4087 - acc: 0.8901 - val_loss: 0.4424 - val_acc: 0.8775\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4080 - acc: 0.8901 - val_loss: 0.4417 - val_acc: 0.8778\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4073 - acc: 0.8903 - val_loss: 0.4411 - val_acc: 0.8776\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4065 - acc: 0.8904 - val_loss: 0.4404 - val_acc: 0.8779\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.4058 - acc: 0.8905 - val_loss: 0.4397 - val_acc: 0.8779\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4051 - acc: 0.8908 - val_loss: 0.4391 - val_acc: 0.8782\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4044 - acc: 0.8909 - val_loss: 0.4384 - val_acc: 0.8786\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4037 - acc: 0.8910 - val_loss: 0.4378 - val_acc: 0.8785\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4030 - acc: 0.8913 - val_loss: 0.4371 - val_acc: 0.8788\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.4023 - acc: 0.8913 - val_loss: 0.4365 - val_acc: 0.8789\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4016 - acc: 0.8914 - val_loss: 0.4358 - val_acc: 0.8790\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4009 - acc: 0.8917 - val_loss: 0.4353 - val_acc: 0.8790\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4003 - acc: 0.8918 - val_loss: 0.4346 - val_acc: 0.8793\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3996 - acc: 0.8920 - val_loss: 0.4340 - val_acc: 0.8793\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3989 - acc: 0.8920 - val_loss: 0.4333 - val_acc: 0.8795\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3982 - acc: 0.8923 - val_loss: 0.4327 - val_acc: 0.8797\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3975 - acc: 0.8925 - val_loss: 0.4322 - val_acc: 0.8800\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3968 - acc: 0.8926 - val_loss: 0.4314 - val_acc: 0.8802\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3962 - acc: 0.8927 - val_loss: 0.4309 - val_acc: 0.8801\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3955 - acc: 0.8929 - val_loss: 0.4303 - val_acc: 0.8803\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3948 - acc: 0.8930 - val_loss: 0.4296 - val_acc: 0.8806\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3941 - acc: 0.8932 - val_loss: 0.4291 - val_acc: 0.8806\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3935 - acc: 0.8932 - val_loss: 0.4284 - val_acc: 0.8807\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3928 - acc: 0.8935 - val_loss: 0.4278 - val_acc: 0.8809\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3922 - acc: 0.8937 - val_loss: 0.4272 - val_acc: 0.8809\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3915 - acc: 0.8939 - val_loss: 0.4266 - val_acc: 0.8811\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3908 - acc: 0.8940 - val_loss: 0.4260 - val_acc: 0.8814\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3902 - acc: 0.8940 - val_loss: 0.4254 - val_acc: 0.8815\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3896 - acc: 0.8942 - val_loss: 0.4248 - val_acc: 0.8815\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3889 - acc: 0.8946 - val_loss: 0.4244 - val_acc: 0.8818\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3883 - acc: 0.8945 - val_loss: 0.4236 - val_acc: 0.8819\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3876 - acc: 0.8947 - val_loss: 0.4231 - val_acc: 0.8820\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.3869 - acc: 0.8950 - val_loss: 0.4224 - val_acc: 0.8822\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.3863 - acc: 0.8952 - val_loss: 0.4219 - val_acc: 0.8824\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3856 - acc: 0.8953 - val_loss: 0.4213 - val_acc: 0.8824\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3850 - acc: 0.8954 - val_loss: 0.4208 - val_acc: 0.8824\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3844 - acc: 0.8955 - val_loss: 0.4201 - val_acc: 0.8827\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3837 - acc: 0.8957 - val_loss: 0.4196 - val_acc: 0.8828\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3831 - acc: 0.8959 - val_loss: 0.4190 - val_acc: 0.8830\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3825 - acc: 0.8961 - val_loss: 0.4184 - val_acc: 0.8830\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3819 - acc: 0.8960 - val_loss: 0.4179 - val_acc: 0.8832\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3812 - acc: 0.8962 - val_loss: 0.4174 - val_acc: 0.8833\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3806 - acc: 0.8963 - val_loss: 0.4167 - val_acc: 0.8834\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3800 - acc: 0.8966 - val_loss: 0.4161 - val_acc: 0.8834\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3794 - acc: 0.8966 - val_loss: 0.4156 - val_acc: 0.8837\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3787 - acc: 0.8968 - val_loss: 0.4150 - val_acc: 0.8837\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3781 - acc: 0.8970 - val_loss: 0.4145 - val_acc: 0.8839\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.3775 - acc: 0.8973 - val_loss: 0.4140 - val_acc: 0.8840\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3769 - acc: 0.8973 - val_loss: 0.4134 - val_acc: 0.8841\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3763 - acc: 0.8975 - val_loss: 0.4129 - val_acc: 0.8842\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3757 - acc: 0.8975 - val_loss: 0.4123 - val_acc: 0.8844\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3751 - acc: 0.8977 - val_loss: 0.4118 - val_acc: 0.8845\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3745 - acc: 0.8977 - val_loss: 0.4112 - val_acc: 0.8846\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.3739 - acc: 0.8979 - val_loss: 0.4107 - val_acc: 0.8848\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3733 - acc: 0.8982 - val_loss: 0.4101 - val_acc: 0.8848\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3727 - acc: 0.8984 - val_loss: 0.4096 - val_acc: 0.8851\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3721 - acc: 0.8984 - val_loss: 0.4090 - val_acc: 0.8852\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3715 - acc: 0.8987 - val_loss: 0.4085 - val_acc: 0.8852\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3709 - acc: 0.8987 - val_loss: 0.4080 - val_acc: 0.8852\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.3704 - acc: 0.8987 - val_loss: 0.4075 - val_acc: 0.8854\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3697 - acc: 0.8990 - val_loss: 0.4070 - val_acc: 0.8856\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3692 - acc: 0.8991 - val_loss: 0.4065 - val_acc: 0.8856\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3686 - acc: 0.8992 - val_loss: 0.4059 - val_acc: 0.8856\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.3680 - acc: 0.8995 - val_loss: 0.4054 - val_acc: 0.8859\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3674 - acc: 0.8994 - val_loss: 0.4048 - val_acc: 0.8860\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3668 - acc: 0.8996 - val_loss: 0.4044 - val_acc: 0.8861\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.3662 - acc: 0.8996 - val_loss: 0.4038 - val_acc: 0.8862\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.3656 - acc: 0.8998 - val_loss: 0.4034 - val_acc: 0.8861\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.3651 - acc: 0.8999 - val_loss: 0.4028 - val_acc: 0.8863\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.3645 - acc: 0.9001 - val_loss: 0.4024 - val_acc: 0.8864\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.3639 - acc: 0.9003 - val_loss: 0.4017 - val_acc: 0.8867\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3634 - acc: 0.9004 - val_loss: 0.4013 - val_acc: 0.8867\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3628 - acc: 0.9003 - val_loss: 0.4008 - val_acc: 0.8868\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3623 - acc: 0.9006 - val_loss: 0.4004 - val_acc: 0.8869\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.3617 - acc: 0.9004 - val_loss: 0.3997 - val_acc: 0.8871\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.3611 - acc: 0.9008 - val_loss: 0.3993 - val_acc: 0.8871\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from models import baselineLSTM\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "checkpoint_path = os.path.join(weights_folder, \"baseline\", \"checkpoint.hdf5\")\n",
        "history_path = os.path.join(weights_folder, \"baseline\", \"history.npy\")\n",
        "\n",
        "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
        "hist_callback = MyHistory(history_path)\n",
        "\n",
        "model = baselineLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "model.compile(**compile_args, optimizer=optimizer)\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "history = model.fit(x=x_train_pad,\n",
        "                    y=y_train_pad,\n",
        "                    batch_size=256,\n",
        "                    epochs=500,\n",
        "                    validation_data=(x_val_pad,\n",
        "                                     y_val_pad),\n",
        "                    callbacks=[checkpoint_callback, hist_callback])\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OUPAV9S4gIpN"
      },
      "source": [
        "## GRU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZF_3KM3qgIpO",
        "outputId": "7248babd-ffc6-4c84-a47e-f0f7734228b8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 3s 79ms/step - loss: 3.8208 - acc: 0.0232 - val_loss: 3.8008 - val_acc: 0.0273\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.7905 - acc: 0.0309 - val_loss: 3.7715 - val_acc: 0.0349\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 3.7605 - acc: 0.0380 - val_loss: 3.7423 - val_acc: 0.0414\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.7306 - acc: 0.0468 - val_loss: 3.7130 - val_acc: 0.0511\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.7004 - acc: 0.0542 - val_loss: 3.6833 - val_acc: 0.0563\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.6697 - acc: 0.2195 - val_loss: 3.6529 - val_acc: 0.3953\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.6380 - acc: 0.4190 - val_loss: 3.6214 - val_acc: 0.4425\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 3.6051 - acc: 0.4576 - val_loss: 3.5884 - val_acc: 0.4697\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 3.5705 - acc: 0.4807 - val_loss: 3.5536 - val_acc: 0.4908\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.5337 - acc: 0.4999 - val_loss: 3.5163 - val_acc: 0.5093\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.4941 - acc: 0.5169 - val_loss: 3.4762 - val_acc: 0.5254\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.4512 - acc: 0.5303 - val_loss: 3.4323 - val_acc: 0.5386\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.4040 - acc: 0.5428 - val_loss: 3.3838 - val_acc: 0.5482\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.3513 - acc: 0.5517 - val_loss: 3.3293 - val_acc: 0.5552\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 3.2917 - acc: 0.5584 - val_loss: 3.2670 - val_acc: 0.5603\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 3.2228 - acc: 0.5627 - val_loss: 3.1943 - val_acc: 0.5634\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 3.1418 - acc: 0.5637 - val_loss: 3.1072 - val_acc: 0.5619\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 3.0431 - acc: 0.5622 - val_loss: 2.9991 - val_acc: 0.5580\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.9192 - acc: 0.5580 - val_loss: 2.8589 - val_acc: 0.5526\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.7569 - acc: 0.5518 - val_loss: 2.6722 - val_acc: 0.5441\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 2.5435 - acc: 0.5441 - val_loss: 2.4428 - val_acc: 0.5343\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 2.3174 - acc: 0.5363 - val_loss: 2.2407 - val_acc: 0.5266\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 2.1514 - acc: 0.5319 - val_loss: 2.1201 - val_acc: 0.5227\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 2.0556 - acc: 0.5298 - val_loss: 2.0502 - val_acc: 0.5209\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.9973 - acc: 0.5290 - val_loss: 2.0044 - val_acc: 0.5201\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.9576 - acc: 0.5290 - val_loss: 1.9703 - val_acc: 0.5203\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.9267 - acc: 0.5295 - val_loss: 1.9425 - val_acc: 0.5207\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.9009 - acc: 0.5300 - val_loss: 1.9184 - val_acc: 0.5212\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.8784 - acc: 0.5308 - val_loss: 1.8969 - val_acc: 0.5223\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.8583 - acc: 0.5317 - val_loss: 1.8774 - val_acc: 0.5237\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.8399 - acc: 0.5328 - val_loss: 1.8594 - val_acc: 0.5248\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.8229 - acc: 0.5336 - val_loss: 1.8426 - val_acc: 0.5257\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.8070 - acc: 0.5347 - val_loss: 1.8268 - val_acc: 0.5272\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7921 - acc: 0.5361 - val_loss: 1.8120 - val_acc: 0.5287\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7781 - acc: 0.5376 - val_loss: 1.7980 - val_acc: 0.5307\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7649 - acc: 0.5393 - val_loss: 1.7847 - val_acc: 0.5330\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.7524 - acc: 0.5411 - val_loss: 1.7722 - val_acc: 0.5358\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.7407 - acc: 0.5428 - val_loss: 1.7604 - val_acc: 0.5384\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.7296 - acc: 0.5446 - val_loss: 1.7493 - val_acc: 0.5414\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.7191 - acc: 0.5470 - val_loss: 1.7387 - val_acc: 0.5439\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.7092 - acc: 0.5490 - val_loss: 1.7286 - val_acc: 0.5466\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.6997 - acc: 0.5511 - val_loss: 1.7191 - val_acc: 0.5498\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.6907 - acc: 0.5539 - val_loss: 1.7100 - val_acc: 0.5526\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.6822 - acc: 0.5566 - val_loss: 1.7013 - val_acc: 0.5553\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.6740 - acc: 0.5590 - val_loss: 1.6929 - val_acc: 0.5577\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6661 - acc: 0.5618 - val_loss: 1.6849 - val_acc: 0.5610\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.6585 - acc: 0.5647 - val_loss: 1.6771 - val_acc: 0.5631\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.6512 - acc: 0.5670 - val_loss: 1.6697 - val_acc: 0.5653\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6442 - acc: 0.5691 - val_loss: 1.6626 - val_acc: 0.5675\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.6373 - acc: 0.5712 - val_loss: 1.6556 - val_acc: 0.5700\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.6307 - acc: 0.5735 - val_loss: 1.6488 - val_acc: 0.5723\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.6242 - acc: 0.5754 - val_loss: 1.6422 - val_acc: 0.5748\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.6179 - acc: 0.5772 - val_loss: 1.6358 - val_acc: 0.5769\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.6117 - acc: 0.5792 - val_loss: 1.6295 - val_acc: 0.5786\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.6056 - acc: 0.5808 - val_loss: 1.6233 - val_acc: 0.5808\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.5997 - acc: 0.5827 - val_loss: 1.6173 - val_acc: 0.5826\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5938 - acc: 0.5845 - val_loss: 1.6113 - val_acc: 0.5841\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.5881 - acc: 0.5859 - val_loss: 1.6055 - val_acc: 0.5851\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5824 - acc: 0.5873 - val_loss: 1.5997 - val_acc: 0.5869\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5767 - acc: 0.5890 - val_loss: 1.5940 - val_acc: 0.5889\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.5711 - acc: 0.5905 - val_loss: 1.5883 - val_acc: 0.5902\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.5656 - acc: 0.5917 - val_loss: 1.5827 - val_acc: 0.5917\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 1.5601 - acc: 0.5934 - val_loss: 1.5771 - val_acc: 0.5929\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5546 - acc: 0.5951 - val_loss: 1.5716 - val_acc: 0.5943\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.5492 - acc: 0.5967 - val_loss: 1.5661 - val_acc: 0.5957\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5438 - acc: 0.5981 - val_loss: 1.5605 - val_acc: 0.5973\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.5383 - acc: 0.5996 - val_loss: 1.5551 - val_acc: 0.5985\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5329 - acc: 0.6008 - val_loss: 1.5496 - val_acc: 0.5996\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.5275 - acc: 0.6022 - val_loss: 1.5441 - val_acc: 0.6010\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5220 - acc: 0.6035 - val_loss: 1.5387 - val_acc: 0.6024\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.5166 - acc: 0.6050 - val_loss: 1.5332 - val_acc: 0.6035\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.5112 - acc: 0.6062 - val_loss: 1.5277 - val_acc: 0.6053\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.5058 - acc: 0.6073 - val_loss: 1.5222 - val_acc: 0.6067\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.5003 - acc: 0.6087 - val_loss: 1.5167 - val_acc: 0.6081\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4948 - acc: 0.6099 - val_loss: 1.5113 - val_acc: 0.6094\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.4893 - acc: 0.6110 - val_loss: 1.5057 - val_acc: 0.6108\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.4838 - acc: 0.6122 - val_loss: 1.5002 - val_acc: 0.6124\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4783 - acc: 0.6138 - val_loss: 1.4947 - val_acc: 0.6137\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4728 - acc: 0.6153 - val_loss: 1.4891 - val_acc: 0.6155\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.4672 - acc: 0.6169 - val_loss: 1.4835 - val_acc: 0.6172\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.4616 - acc: 0.6186 - val_loss: 1.4779 - val_acc: 0.6186\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4560 - acc: 0.6203 - val_loss: 1.4723 - val_acc: 0.6203\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4503 - acc: 0.6227 - val_loss: 1.4667 - val_acc: 0.6227\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4447 - acc: 0.6251 - val_loss: 1.4610 - val_acc: 0.6255\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4390 - acc: 0.6278 - val_loss: 1.4553 - val_acc: 0.6282\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4333 - acc: 0.6314 - val_loss: 1.4496 - val_acc: 0.6328\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.4276 - acc: 0.6348 - val_loss: 1.4439 - val_acc: 0.6353\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.4218 - acc: 0.6373 - val_loss: 1.4382 - val_acc: 0.6380\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.4161 - acc: 0.6402 - val_loss: 1.4324 - val_acc: 0.6409\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.4103 - acc: 0.6427 - val_loss: 1.4266 - val_acc: 0.6436\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.4044 - acc: 0.6453 - val_loss: 1.4208 - val_acc: 0.6462\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.3986 - acc: 0.6475 - val_loss: 1.4150 - val_acc: 0.6485\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.3927 - acc: 0.6495 - val_loss: 1.4091 - val_acc: 0.6504\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3868 - acc: 0.6516 - val_loss: 1.4032 - val_acc: 0.6523\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.3809 - acc: 0.6540 - val_loss: 1.3973 - val_acc: 0.6544\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3750 - acc: 0.6563 - val_loss: 1.3914 - val_acc: 0.6564\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.3690 - acc: 0.6582 - val_loss: 1.3854 - val_acc: 0.6584\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.3630 - acc: 0.6600 - val_loss: 1.3794 - val_acc: 0.6601\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.3570 - acc: 0.6616 - val_loss: 1.3734 - val_acc: 0.6618\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.3510 - acc: 0.6632 - val_loss: 1.3674 - val_acc: 0.6635\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3449 - acc: 0.6644 - val_loss: 1.3614 - val_acc: 0.6649\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.3389 - acc: 0.6657 - val_loss: 1.3554 - val_acc: 0.6662\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 1.3328 - acc: 0.6671 - val_loss: 1.3493 - val_acc: 0.6679\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.3268 - acc: 0.6684 - val_loss: 1.3433 - val_acc: 0.6693\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.3207 - acc: 0.6698 - val_loss: 1.3373 - val_acc: 0.6705\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.3147 - acc: 0.6708 - val_loss: 1.3313 - val_acc: 0.6718\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 1.3087 - acc: 0.6722 - val_loss: 1.3253 - val_acc: 0.6732\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.3027 - acc: 0.6733 - val_loss: 1.3193 - val_acc: 0.6740\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.2967 - acc: 0.6745 - val_loss: 1.3134 - val_acc: 0.6749\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2907 - acc: 0.6758 - val_loss: 1.3074 - val_acc: 0.6762\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.2847 - acc: 0.6770 - val_loss: 1.3016 - val_acc: 0.6773\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2788 - acc: 0.6779 - val_loss: 1.2957 - val_acc: 0.6783\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.2730 - acc: 0.6789 - val_loss: 1.2899 - val_acc: 0.6794\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2671 - acc: 0.6801 - val_loss: 1.2841 - val_acc: 0.6803\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2613 - acc: 0.6812 - val_loss: 1.2783 - val_acc: 0.6813\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2555 - acc: 0.6828 - val_loss: 1.2725 - val_acc: 0.6833\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.2497 - acc: 0.6844 - val_loss: 1.2668 - val_acc: 0.6840\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.2440 - acc: 0.6853 - val_loss: 1.2612 - val_acc: 0.6846\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2382 - acc: 0.6859 - val_loss: 1.2555 - val_acc: 0.6855\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.2325 - acc: 0.6868 - val_loss: 1.2499 - val_acc: 0.6859\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.2269 - acc: 0.6876 - val_loss: 1.2443 - val_acc: 0.6867\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.2212 - acc: 0.6885 - val_loss: 1.2388 - val_acc: 0.6876\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2157 - acc: 0.6895 - val_loss: 1.2332 - val_acc: 0.6883\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2101 - acc: 0.6904 - val_loss: 1.2277 - val_acc: 0.6889\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.2046 - acc: 0.6914 - val_loss: 1.2223 - val_acc: 0.6897\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.1991 - acc: 0.6922 - val_loss: 1.2168 - val_acc: 0.6903\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.1936 - acc: 0.6930 - val_loss: 1.2115 - val_acc: 0.6910\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.1881 - acc: 0.6937 - val_loss: 1.2061 - val_acc: 0.6916\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1827 - acc: 0.6947 - val_loss: 1.2008 - val_acc: 0.6927\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1773 - acc: 0.6955 - val_loss: 1.1955 - val_acc: 0.6936\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1720 - acc: 0.6964 - val_loss: 1.1902 - val_acc: 0.6943\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1667 - acc: 0.6974 - val_loss: 1.1850 - val_acc: 0.6952\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.1614 - acc: 0.6984 - val_loss: 1.1798 - val_acc: 0.6958\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1561 - acc: 0.6991 - val_loss: 1.1746 - val_acc: 0.6965\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1509 - acc: 0.7001 - val_loss: 1.1695 - val_acc: 0.6976\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1457 - acc: 0.7010 - val_loss: 1.1644 - val_acc: 0.6986\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 1.1405 - acc: 0.7021 - val_loss: 1.1593 - val_acc: 0.6995\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1354 - acc: 0.7030 - val_loss: 1.1542 - val_acc: 0.7005\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1303 - acc: 0.7041 - val_loss: 1.1492 - val_acc: 0.7014\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1252 - acc: 0.7051 - val_loss: 1.1443 - val_acc: 0.7024\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.1202 - acc: 0.7062 - val_loss: 1.1393 - val_acc: 0.7033\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.1152 - acc: 0.7075 - val_loss: 1.1345 - val_acc: 0.7045\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1102 - acc: 0.7089 - val_loss: 1.1296 - val_acc: 0.7059\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.1053 - acc: 0.7104 - val_loss: 1.1247 - val_acc: 0.7071\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.1004 - acc: 0.7117 - val_loss: 1.1199 - val_acc: 0.7081\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0955 - acc: 0.7133 - val_loss: 1.1152 - val_acc: 0.7091\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 1.0907 - acc: 0.7146 - val_loss: 1.1105 - val_acc: 0.7104\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0859 - acc: 0.7163 - val_loss: 1.1058 - val_acc: 0.7117\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0812 - acc: 0.7178 - val_loss: 1.1012 - val_acc: 0.7129\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0765 - acc: 0.7192 - val_loss: 1.0965 - val_acc: 0.7145\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.0718 - acc: 0.7204 - val_loss: 1.0920 - val_acc: 0.7159\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0671 - acc: 0.7222 - val_loss: 1.0875 - val_acc: 0.7173\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 1.0626 - acc: 0.7235 - val_loss: 1.0830 - val_acc: 0.7190\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0580 - acc: 0.7251 - val_loss: 1.0785 - val_acc: 0.7203\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 1.0535 - acc: 0.7264 - val_loss: 1.0741 - val_acc: 0.7214\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 1.0490 - acc: 0.7275 - val_loss: 1.0697 - val_acc: 0.7228\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 1.0445 - acc: 0.7291 - val_loss: 1.0653 - val_acc: 0.7247\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0401 - acc: 0.7307 - val_loss: 1.0610 - val_acc: 0.7260\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.0357 - acc: 0.7320 - val_loss: 1.0568 - val_acc: 0.7280\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0314 - acc: 0.7334 - val_loss: 1.0525 - val_acc: 0.7293\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.0271 - acc: 0.7349 - val_loss: 1.0483 - val_acc: 0.7312\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0228 - acc: 0.7365 - val_loss: 1.0441 - val_acc: 0.7328\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0186 - acc: 0.7381 - val_loss: 1.0400 - val_acc: 0.7344\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 1.0144 - acc: 0.7398 - val_loss: 1.0359 - val_acc: 0.7361\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0102 - acc: 0.7415 - val_loss: 1.0318 - val_acc: 0.7380\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 1.0061 - acc: 0.7435 - val_loss: 1.0278 - val_acc: 0.7399\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 1.0020 - acc: 0.7455 - val_loss: 1.0238 - val_acc: 0.7415\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.9979 - acc: 0.7473 - val_loss: 1.0198 - val_acc: 0.7432\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.9939 - acc: 0.7492 - val_loss: 1.0158 - val_acc: 0.7448\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9899 - acc: 0.7510 - val_loss: 1.0119 - val_acc: 0.7462\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9860 - acc: 0.7527 - val_loss: 1.0080 - val_acc: 0.7477\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9820 - acc: 0.7544 - val_loss: 1.0042 - val_acc: 0.7499\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9781 - acc: 0.7561 - val_loss: 1.0003 - val_acc: 0.7514\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9743 - acc: 0.7576 - val_loss: 0.9966 - val_acc: 0.7531\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9704 - acc: 0.7593 - val_loss: 0.9928 - val_acc: 0.7544\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9666 - acc: 0.7608 - val_loss: 0.9891 - val_acc: 0.7559\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.9628 - acc: 0.7619 - val_loss: 0.9854 - val_acc: 0.7570\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9591 - acc: 0.7637 - val_loss: 0.9817 - val_acc: 0.7587\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9554 - acc: 0.7649 - val_loss: 0.9780 - val_acc: 0.7599\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9517 - acc: 0.7663 - val_loss: 0.9744 - val_acc: 0.7612\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9480 - acc: 0.7677 - val_loss: 0.9708 - val_acc: 0.7623\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.9444 - acc: 0.7690 - val_loss: 0.9672 - val_acc: 0.7633\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9408 - acc: 0.7702 - val_loss: 0.9637 - val_acc: 0.7644\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9372 - acc: 0.7711 - val_loss: 0.9602 - val_acc: 0.7654\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9337 - acc: 0.7721 - val_loss: 0.9567 - val_acc: 0.7665\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9302 - acc: 0.7733 - val_loss: 0.9532 - val_acc: 0.7673\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.9267 - acc: 0.7741 - val_loss: 0.9498 - val_acc: 0.7681\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9232 - acc: 0.7751 - val_loss: 0.9464 - val_acc: 0.7690\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9197 - acc: 0.7762 - val_loss: 0.9430 - val_acc: 0.7698\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.9163 - acc: 0.7771 - val_loss: 0.9396 - val_acc: 0.7705\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9129 - acc: 0.7779 - val_loss: 0.9363 - val_acc: 0.7713\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9096 - acc: 0.7790 - val_loss: 0.9329 - val_acc: 0.7722\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.9062 - acc: 0.7800 - val_loss: 0.9296 - val_acc: 0.7727\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.9029 - acc: 0.7811 - val_loss: 0.9264 - val_acc: 0.7736\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.8996 - acc: 0.7821 - val_loss: 0.9231 - val_acc: 0.7742\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8963 - acc: 0.7828 - val_loss: 0.9199 - val_acc: 0.7749\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8931 - acc: 0.7836 - val_loss: 0.9167 - val_acc: 0.7757\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8898 - acc: 0.7849 - val_loss: 0.9135 - val_acc: 0.7770\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8867 - acc: 0.7861 - val_loss: 0.9103 - val_acc: 0.7777\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8835 - acc: 0.7868 - val_loss: 0.9072 - val_acc: 0.7786\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.8803 - acc: 0.7874 - val_loss: 0.9041 - val_acc: 0.7793\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8772 - acc: 0.7882 - val_loss: 0.9010 - val_acc: 0.7800\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.8740 - acc: 0.7891 - val_loss: 0.8979 - val_acc: 0.7804\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8709 - acc: 0.7897 - val_loss: 0.8948 - val_acc: 0.7811\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8678 - acc: 0.7904 - val_loss: 0.8918 - val_acc: 0.7818\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8648 - acc: 0.7912 - val_loss: 0.8888 - val_acc: 0.7826\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.8617 - acc: 0.7920 - val_loss: 0.8857 - val_acc: 0.7833\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8587 - acc: 0.7927 - val_loss: 0.8827 - val_acc: 0.7837\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8557 - acc: 0.7932 - val_loss: 0.8798 - val_acc: 0.7843\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.8527 - acc: 0.7938 - val_loss: 0.8768 - val_acc: 0.7850\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.8497 - acc: 0.7946 - val_loss: 0.8739 - val_acc: 0.7855\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8468 - acc: 0.7951 - val_loss: 0.8710 - val_acc: 0.7860\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8439 - acc: 0.7957 - val_loss: 0.8681 - val_acc: 0.7868\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8409 - acc: 0.7963 - val_loss: 0.8652 - val_acc: 0.7872\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.8381 - acc: 0.7968 - val_loss: 0.8623 - val_acc: 0.7878\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8352 - acc: 0.7974 - val_loss: 0.8595 - val_acc: 0.7883\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.8323 - acc: 0.7979 - val_loss: 0.8567 - val_acc: 0.7887\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8295 - acc: 0.7983 - val_loss: 0.8539 - val_acc: 0.7892\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8267 - acc: 0.7988 - val_loss: 0.8511 - val_acc: 0.7898\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8239 - acc: 0.7994 - val_loss: 0.8483 - val_acc: 0.7904\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.8211 - acc: 0.7999 - val_loss: 0.8456 - val_acc: 0.7908\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.8183 - acc: 0.8002 - val_loss: 0.8428 - val_acc: 0.7913\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8156 - acc: 0.8008 - val_loss: 0.8401 - val_acc: 0.7922\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8129 - acc: 0.8016 - val_loss: 0.8374 - val_acc: 0.7926\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8101 - acc: 0.8021 - val_loss: 0.8348 - val_acc: 0.7933\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.8074 - acc: 0.8029 - val_loss: 0.8321 - val_acc: 0.7938\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8048 - acc: 0.8035 - val_loss: 0.8294 - val_acc: 0.7944\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.8021 - acc: 0.8042 - val_loss: 0.8268 - val_acc: 0.7950\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7995 - acc: 0.8047 - val_loss: 0.8242 - val_acc: 0.7955\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7969 - acc: 0.8051 - val_loss: 0.8216 - val_acc: 0.7959\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.7943 - acc: 0.8059 - val_loss: 0.8190 - val_acc: 0.7966\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7917 - acc: 0.8066 - val_loss: 0.8165 - val_acc: 0.7971\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7891 - acc: 0.8072 - val_loss: 0.8139 - val_acc: 0.7976\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7865 - acc: 0.8077 - val_loss: 0.8114 - val_acc: 0.7982\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7840 - acc: 0.8082 - val_loss: 0.8089 - val_acc: 0.7986\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7815 - acc: 0.8087 - val_loss: 0.8064 - val_acc: 0.7989\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7790 - acc: 0.8093 - val_loss: 0.8039 - val_acc: 0.7993\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7765 - acc: 0.8098 - val_loss: 0.8015 - val_acc: 0.7999\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7741 - acc: 0.8103 - val_loss: 0.7990 - val_acc: 0.8004\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7716 - acc: 0.8108 - val_loss: 0.7966 - val_acc: 0.8009\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.7692 - acc: 0.8111 - val_loss: 0.7942 - val_acc: 0.8014\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7668 - acc: 0.8116 - val_loss: 0.7919 - val_acc: 0.8017\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7644 - acc: 0.8122 - val_loss: 0.7895 - val_acc: 0.8021\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7620 - acc: 0.8126 - val_loss: 0.7871 - val_acc: 0.8024\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7596 - acc: 0.8131 - val_loss: 0.7848 - val_acc: 0.8028\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7573 - acc: 0.8137 - val_loss: 0.7824 - val_acc: 0.8035\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7549 - acc: 0.8141 - val_loss: 0.7801 - val_acc: 0.8037\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7526 - acc: 0.8146 - val_loss: 0.7778 - val_acc: 0.8041\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7503 - acc: 0.8151 - val_loss: 0.7755 - val_acc: 0.8045\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7480 - acc: 0.8156 - val_loss: 0.7733 - val_acc: 0.8050\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7458 - acc: 0.8161 - val_loss: 0.7710 - val_acc: 0.8054\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7435 - acc: 0.8165 - val_loss: 0.7688 - val_acc: 0.8059\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.7413 - acc: 0.8170 - val_loss: 0.7666 - val_acc: 0.8064\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7390 - acc: 0.8173 - val_loss: 0.7643 - val_acc: 0.8070\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7368 - acc: 0.8178 - val_loss: 0.7622 - val_acc: 0.8075\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7346 - acc: 0.8182 - val_loss: 0.7600 - val_acc: 0.8079\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7325 - acc: 0.8188 - val_loss: 0.7578 - val_acc: 0.8082\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7303 - acc: 0.8192 - val_loss: 0.7557 - val_acc: 0.8087\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7281 - acc: 0.8196 - val_loss: 0.7535 - val_acc: 0.8092\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7260 - acc: 0.8200 - val_loss: 0.7514 - val_acc: 0.8095\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7239 - acc: 0.8204 - val_loss: 0.7494 - val_acc: 0.8097\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7218 - acc: 0.8208 - val_loss: 0.7473 - val_acc: 0.8101\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7197 - acc: 0.8212 - val_loss: 0.7452 - val_acc: 0.8105\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.7176 - acc: 0.8216 - val_loss: 0.7431 - val_acc: 0.8110\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7155 - acc: 0.8220 - val_loss: 0.7410 - val_acc: 0.8114\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7135 - acc: 0.8223 - val_loss: 0.7390 - val_acc: 0.8118\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7114 - acc: 0.8226 - val_loss: 0.7370 - val_acc: 0.8121\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.7094 - acc: 0.8229 - val_loss: 0.7350 - val_acc: 0.8125\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.7074 - acc: 0.8232 - val_loss: 0.7329 - val_acc: 0.8130\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.7054 - acc: 0.8235 - val_loss: 0.7310 - val_acc: 0.8134\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7034 - acc: 0.8238 - val_loss: 0.7290 - val_acc: 0.8140\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7014 - acc: 0.8242 - val_loss: 0.7270 - val_acc: 0.8145\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6994 - acc: 0.8247 - val_loss: 0.7250 - val_acc: 0.8148\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6974 - acc: 0.8250 - val_loss: 0.7231 - val_acc: 0.8152\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6955 - acc: 0.8254 - val_loss: 0.7212 - val_acc: 0.8157\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6936 - acc: 0.8258 - val_loss: 0.7193 - val_acc: 0.8161\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6916 - acc: 0.8262 - val_loss: 0.7174 - val_acc: 0.8165\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6897 - acc: 0.8267 - val_loss: 0.7155 - val_acc: 0.8171\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6878 - acc: 0.8271 - val_loss: 0.7136 - val_acc: 0.8176\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6860 - acc: 0.8276 - val_loss: 0.7117 - val_acc: 0.8180\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6841 - acc: 0.8279 - val_loss: 0.7099 - val_acc: 0.8187\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6822 - acc: 0.8283 - val_loss: 0.7080 - val_acc: 0.8192\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6804 - acc: 0.8285 - val_loss: 0.7062 - val_acc: 0.8196\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6785 - acc: 0.8288 - val_loss: 0.7044 - val_acc: 0.8201\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6767 - acc: 0.8291 - val_loss: 0.7025 - val_acc: 0.8205\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6749 - acc: 0.8295 - val_loss: 0.7007 - val_acc: 0.8209\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6731 - acc: 0.8299 - val_loss: 0.6989 - val_acc: 0.8214\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6713 - acc: 0.8303 - val_loss: 0.6971 - val_acc: 0.8217\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6695 - acc: 0.8308 - val_loss: 0.6954 - val_acc: 0.8220\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6677 - acc: 0.8311 - val_loss: 0.6936 - val_acc: 0.8224\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6660 - acc: 0.8315 - val_loss: 0.6919 - val_acc: 0.8226\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6642 - acc: 0.8319 - val_loss: 0.6902 - val_acc: 0.8229\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6625 - acc: 0.8324 - val_loss: 0.6885 - val_acc: 0.8234\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6607 - acc: 0.8327 - val_loss: 0.6867 - val_acc: 0.8238\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6590 - acc: 0.8331 - val_loss: 0.6850 - val_acc: 0.8242\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6573 - acc: 0.8335 - val_loss: 0.6833 - val_acc: 0.8245\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.6556 - acc: 0.8338 - val_loss: 0.6816 - val_acc: 0.8249\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6539 - acc: 0.8341 - val_loss: 0.6799 - val_acc: 0.8252\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6522 - acc: 0.8343 - val_loss: 0.6782 - val_acc: 0.8255\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6505 - acc: 0.8349 - val_loss: 0.6766 - val_acc: 0.8260\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6488 - acc: 0.8353 - val_loss: 0.6749 - val_acc: 0.8265\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6472 - acc: 0.8357 - val_loss: 0.6733 - val_acc: 0.8268\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6455 - acc: 0.8360 - val_loss: 0.6717 - val_acc: 0.8274\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6439 - acc: 0.8363 - val_loss: 0.6700 - val_acc: 0.8277\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6423 - acc: 0.8367 - val_loss: 0.6684 - val_acc: 0.8282\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6406 - acc: 0.8372 - val_loss: 0.6668 - val_acc: 0.8286\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6390 - acc: 0.8376 - val_loss: 0.6652 - val_acc: 0.8291\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6374 - acc: 0.8378 - val_loss: 0.6636 - val_acc: 0.8294\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6358 - acc: 0.8381 - val_loss: 0.6620 - val_acc: 0.8297\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6342 - acc: 0.8384 - val_loss: 0.6604 - val_acc: 0.8302\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6326 - acc: 0.8388 - val_loss: 0.6589 - val_acc: 0.8306\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6311 - acc: 0.8391 - val_loss: 0.6573 - val_acc: 0.8308\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.6295 - acc: 0.8395 - val_loss: 0.6558 - val_acc: 0.8312\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6280 - acc: 0.8400 - val_loss: 0.6542 - val_acc: 0.8318\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6264 - acc: 0.8404 - val_loss: 0.6527 - val_acc: 0.8321\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6249 - acc: 0.8407 - val_loss: 0.6512 - val_acc: 0.8323\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6233 - acc: 0.8410 - val_loss: 0.6496 - val_acc: 0.8327\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6218 - acc: 0.8413 - val_loss: 0.6481 - val_acc: 0.8331\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.6203 - acc: 0.8416 - val_loss: 0.6466 - val_acc: 0.8335\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6188 - acc: 0.8419 - val_loss: 0.6452 - val_acc: 0.8340\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6173 - acc: 0.8422 - val_loss: 0.6437 - val_acc: 0.8344\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.6158 - acc: 0.8423 - val_loss: 0.6422 - val_acc: 0.8347\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6143 - acc: 0.8427 - val_loss: 0.6408 - val_acc: 0.8349\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6128 - acc: 0.8431 - val_loss: 0.6393 - val_acc: 0.8354\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6114 - acc: 0.8434 - val_loss: 0.6378 - val_acc: 0.8358\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.6099 - acc: 0.8437 - val_loss: 0.6364 - val_acc: 0.8364\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6085 - acc: 0.8442 - val_loss: 0.6350 - val_acc: 0.8368\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.6070 - acc: 0.8444 - val_loss: 0.6335 - val_acc: 0.8373\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6056 - acc: 0.8447 - val_loss: 0.6321 - val_acc: 0.8376\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.6041 - acc: 0.8449 - val_loss: 0.6307 - val_acc: 0.8380\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.6027 - acc: 0.8454 - val_loss: 0.6293 - val_acc: 0.8384\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.6013 - acc: 0.8457 - val_loss: 0.6279 - val_acc: 0.8386\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5999 - acc: 0.8460 - val_loss: 0.6265 - val_acc: 0.8390\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5985 - acc: 0.8465 - val_loss: 0.6251 - val_acc: 0.8392\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5971 - acc: 0.8467 - val_loss: 0.6237 - val_acc: 0.8396\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5957 - acc: 0.8471 - val_loss: 0.6224 - val_acc: 0.8399\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5943 - acc: 0.8474 - val_loss: 0.6210 - val_acc: 0.8402\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5929 - acc: 0.8478 - val_loss: 0.6197 - val_acc: 0.8404\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5916 - acc: 0.8482 - val_loss: 0.6183 - val_acc: 0.8409\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5902 - acc: 0.8484 - val_loss: 0.6170 - val_acc: 0.8413\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5888 - acc: 0.8487 - val_loss: 0.6157 - val_acc: 0.8416\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5875 - acc: 0.8491 - val_loss: 0.6143 - val_acc: 0.8419\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5861 - acc: 0.8497 - val_loss: 0.6130 - val_acc: 0.8427\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5848 - acc: 0.8505 - val_loss: 0.6117 - val_acc: 0.8429\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5835 - acc: 0.8508 - val_loss: 0.6104 - val_acc: 0.8431\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5822 - acc: 0.8512 - val_loss: 0.6091 - val_acc: 0.8436\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.5808 - acc: 0.8517 - val_loss: 0.6078 - val_acc: 0.8439\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5795 - acc: 0.8518 - val_loss: 0.6065 - val_acc: 0.8443\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5782 - acc: 0.8521 - val_loss: 0.6052 - val_acc: 0.8448\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5769 - acc: 0.8525 - val_loss: 0.6040 - val_acc: 0.8451\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5756 - acc: 0.8529 - val_loss: 0.6027 - val_acc: 0.8456\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5743 - acc: 0.8534 - val_loss: 0.6014 - val_acc: 0.8459\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5731 - acc: 0.8537 - val_loss: 0.6002 - val_acc: 0.8462\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5718 - acc: 0.8541 - val_loss: 0.5989 - val_acc: 0.8466\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5705 - acc: 0.8545 - val_loss: 0.5977 - val_acc: 0.8470\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5692 - acc: 0.8549 - val_loss: 0.5965 - val_acc: 0.8472\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5680 - acc: 0.8551 - val_loss: 0.5952 - val_acc: 0.8476\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5667 - acc: 0.8555 - val_loss: 0.5940 - val_acc: 0.8479\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5655 - acc: 0.8561 - val_loss: 0.5928 - val_acc: 0.8483\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5643 - acc: 0.8565 - val_loss: 0.5916 - val_acc: 0.8486\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5630 - acc: 0.8569 - val_loss: 0.5904 - val_acc: 0.8489\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5618 - acc: 0.8572 - val_loss: 0.5892 - val_acc: 0.8492\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5606 - acc: 0.8574 - val_loss: 0.5880 - val_acc: 0.8494\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5594 - acc: 0.8579 - val_loss: 0.5868 - val_acc: 0.8499\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5581 - acc: 0.8582 - val_loss: 0.5856 - val_acc: 0.8503\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5569 - acc: 0.8585 - val_loss: 0.5844 - val_acc: 0.8504\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5557 - acc: 0.8588 - val_loss: 0.5833 - val_acc: 0.8506\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 21ms/step - loss: 0.5545 - acc: 0.8592 - val_loss: 0.5821 - val_acc: 0.8508\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5534 - acc: 0.8594 - val_loss: 0.5810 - val_acc: 0.8510\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.5522 - acc: 0.8598 - val_loss: 0.5798 - val_acc: 0.8513\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5510 - acc: 0.8602 - val_loss: 0.5787 - val_acc: 0.8516\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5498 - acc: 0.8605 - val_loss: 0.5775 - val_acc: 0.8518\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5487 - acc: 0.8608 - val_loss: 0.5764 - val_acc: 0.8521\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5475 - acc: 0.8611 - val_loss: 0.5753 - val_acc: 0.8526\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5463 - acc: 0.8614 - val_loss: 0.5742 - val_acc: 0.8528\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5452 - acc: 0.8616 - val_loss: 0.5730 - val_acc: 0.8530\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.5440 - acc: 0.8619 - val_loss: 0.5719 - val_acc: 0.8531\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5429 - acc: 0.8620 - val_loss: 0.5708 - val_acc: 0.8534\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5418 - acc: 0.8623 - val_loss: 0.5697 - val_acc: 0.8536\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5406 - acc: 0.8626 - val_loss: 0.5686 - val_acc: 0.8539\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5395 - acc: 0.8628 - val_loss: 0.5675 - val_acc: 0.8541\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5384 - acc: 0.8630 - val_loss: 0.5665 - val_acc: 0.8543\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5373 - acc: 0.8633 - val_loss: 0.5654 - val_acc: 0.8547\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5362 - acc: 0.8635 - val_loss: 0.5643 - val_acc: 0.8550\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5351 - acc: 0.8638 - val_loss: 0.5632 - val_acc: 0.8552\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5340 - acc: 0.8641 - val_loss: 0.5622 - val_acc: 0.8553\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5329 - acc: 0.8643 - val_loss: 0.5611 - val_acc: 0.8555\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5318 - acc: 0.8644 - val_loss: 0.5601 - val_acc: 0.8556\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5307 - acc: 0.8646 - val_loss: 0.5590 - val_acc: 0.8559\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5296 - acc: 0.8648 - val_loss: 0.5580 - val_acc: 0.8562\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5285 - acc: 0.8650 - val_loss: 0.5569 - val_acc: 0.8563\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5275 - acc: 0.8652 - val_loss: 0.5559 - val_acc: 0.8565\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5264 - acc: 0.8654 - val_loss: 0.5549 - val_acc: 0.8567\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5253 - acc: 0.8657 - val_loss: 0.5539 - val_acc: 0.8570\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5243 - acc: 0.8659 - val_loss: 0.5528 - val_acc: 0.8573\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5232 - acc: 0.8661 - val_loss: 0.5519 - val_acc: 0.8573\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5222 - acc: 0.8661 - val_loss: 0.5508 - val_acc: 0.8576\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5211 - acc: 0.8665 - val_loss: 0.5499 - val_acc: 0.8577\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5201 - acc: 0.8667 - val_loss: 0.5489 - val_acc: 0.8578\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.5191 - acc: 0.8668 - val_loss: 0.5479 - val_acc: 0.8580\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5181 - acc: 0.8669 - val_loss: 0.5469 - val_acc: 0.8580\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5170 - acc: 0.8672 - val_loss: 0.5459 - val_acc: 0.8582\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5160 - acc: 0.8673 - val_loss: 0.5449 - val_acc: 0.8586\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5150 - acc: 0.8676 - val_loss: 0.5439 - val_acc: 0.8588\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5140 - acc: 0.8677 - val_loss: 0.5430 - val_acc: 0.8589\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5130 - acc: 0.8679 - val_loss: 0.5420 - val_acc: 0.8590\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5120 - acc: 0.8681 - val_loss: 0.5410 - val_acc: 0.8591\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.5110 - acc: 0.8683 - val_loss: 0.5401 - val_acc: 0.8593\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5100 - acc: 0.8684 - val_loss: 0.5391 - val_acc: 0.8596\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5090 - acc: 0.8686 - val_loss: 0.5382 - val_acc: 0.8597\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5080 - acc: 0.8687 - val_loss: 0.5372 - val_acc: 0.8598\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5070 - acc: 0.8689 - val_loss: 0.5363 - val_acc: 0.8600\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5060 - acc: 0.8692 - val_loss: 0.5354 - val_acc: 0.8603\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5051 - acc: 0.8695 - val_loss: 0.5344 - val_acc: 0.8605\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5041 - acc: 0.8697 - val_loss: 0.5335 - val_acc: 0.8607\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.5031 - acc: 0.8699 - val_loss: 0.5326 - val_acc: 0.8609\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5022 - acc: 0.8700 - val_loss: 0.5317 - val_acc: 0.8609\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.5012 - acc: 0.8702 - val_loss: 0.5308 - val_acc: 0.8613\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5003 - acc: 0.8705 - val_loss: 0.5299 - val_acc: 0.8614\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4993 - acc: 0.8707 - val_loss: 0.5290 - val_acc: 0.8615\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.4984 - acc: 0.8708 - val_loss: 0.5281 - val_acc: 0.8617\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4974 - acc: 0.8711 - val_loss: 0.5272 - val_acc: 0.8619\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4965 - acc: 0.8712 - val_loss: 0.5263 - val_acc: 0.8624\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4956 - acc: 0.8714 - val_loss: 0.5254 - val_acc: 0.8625\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4946 - acc: 0.8716 - val_loss: 0.5245 - val_acc: 0.8627\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4937 - acc: 0.8717 - val_loss: 0.5236 - val_acc: 0.8630\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4928 - acc: 0.8719 - val_loss: 0.5228 - val_acc: 0.8631\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4919 - acc: 0.8721 - val_loss: 0.5219 - val_acc: 0.8632\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4909 - acc: 0.8724 - val_loss: 0.5210 - val_acc: 0.8634\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4900 - acc: 0.8724 - val_loss: 0.5201 - val_acc: 0.8635\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4891 - acc: 0.8727 - val_loss: 0.5193 - val_acc: 0.8637\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 25ms/step - loss: 0.4882 - acc: 0.8729 - val_loss: 0.5185 - val_acc: 0.8639\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4873 - acc: 0.8729 - val_loss: 0.5176 - val_acc: 0.8641\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4864 - acc: 0.8733 - val_loss: 0.5168 - val_acc: 0.8641\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4855 - acc: 0.8734 - val_loss: 0.5159 - val_acc: 0.8641\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4847 - acc: 0.8736 - val_loss: 0.5151 - val_acc: 0.8642\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.4838 - acc: 0.8737 - val_loss: 0.5142 - val_acc: 0.8644\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4829 - acc: 0.8739 - val_loss: 0.5134 - val_acc: 0.8648\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4820 - acc: 0.8740 - val_loss: 0.5126 - val_acc: 0.8649\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4811 - acc: 0.8741 - val_loss: 0.5118 - val_acc: 0.8651\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4803 - acc: 0.8743 - val_loss: 0.5109 - val_acc: 0.8653\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4794 - acc: 0.8745 - val_loss: 0.5101 - val_acc: 0.8657\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4785 - acc: 0.8745 - val_loss: 0.5093 - val_acc: 0.8657\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4777 - acc: 0.8747 - val_loss: 0.5085 - val_acc: 0.8659\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4768 - acc: 0.8749 - val_loss: 0.5077 - val_acc: 0.8660\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4760 - acc: 0.8752 - val_loss: 0.5069 - val_acc: 0.8662\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.4751 - acc: 0.8754 - val_loss: 0.5061 - val_acc: 0.8663\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4743 - acc: 0.8756 - val_loss: 0.5053 - val_acc: 0.8665\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4734 - acc: 0.8758 - val_loss: 0.5045 - val_acc: 0.8667\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4726 - acc: 0.8759 - val_loss: 0.5037 - val_acc: 0.8669\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4717 - acc: 0.8760 - val_loss: 0.5029 - val_acc: 0.8671\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4709 - acc: 0.8762 - val_loss: 0.5021 - val_acc: 0.8672\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4701 - acc: 0.8762 - val_loss: 0.5013 - val_acc: 0.8672\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4692 - acc: 0.8764 - val_loss: 0.5006 - val_acc: 0.8675\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4684 - acc: 0.8765 - val_loss: 0.4998 - val_acc: 0.8676\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4676 - acc: 0.8768 - val_loss: 0.4990 - val_acc: 0.8678\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4668 - acc: 0.8768 - val_loss: 0.4982 - val_acc: 0.8678\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4660 - acc: 0.8771 - val_loss: 0.4975 - val_acc: 0.8681\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 27ms/step - loss: 0.4652 - acc: 0.8773 - val_loss: 0.4967 - val_acc: 0.8683\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4643 - acc: 0.8773 - val_loss: 0.4960 - val_acc: 0.8684\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4635 - acc: 0.8776 - val_loss: 0.4952 - val_acc: 0.8685\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4627 - acc: 0.8777 - val_loss: 0.4945 - val_acc: 0.8686\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4619 - acc: 0.8779 - val_loss: 0.4937 - val_acc: 0.8687\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4611 - acc: 0.8780 - val_loss: 0.4930 - val_acc: 0.8688\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4604 - acc: 0.8782 - val_loss: 0.4923 - val_acc: 0.8690\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4596 - acc: 0.8783 - val_loss: 0.4915 - val_acc: 0.8693\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4588 - acc: 0.8784 - val_loss: 0.4908 - val_acc: 0.8694\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4580 - acc: 0.8787 - val_loss: 0.4901 - val_acc: 0.8696\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4572 - acc: 0.8788 - val_loss: 0.4894 - val_acc: 0.8698\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4564 - acc: 0.8790 - val_loss: 0.4886 - val_acc: 0.8699\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4557 - acc: 0.8792 - val_loss: 0.4879 - val_acc: 0.8700\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4549 - acc: 0.8794 - val_loss: 0.4872 - val_acc: 0.8701\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4541 - acc: 0.8796 - val_loss: 0.4865 - val_acc: 0.8703\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4534 - acc: 0.8798 - val_loss: 0.4858 - val_acc: 0.8704\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4526 - acc: 0.8799 - val_loss: 0.4850 - val_acc: 0.8706\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4518 - acc: 0.8800 - val_loss: 0.4843 - val_acc: 0.8710\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.4511 - acc: 0.8803 - val_loss: 0.4836 - val_acc: 0.8710\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4503 - acc: 0.8804 - val_loss: 0.4829 - val_acc: 0.8713\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4496 - acc: 0.8806 - val_loss: 0.4823 - val_acc: 0.8714\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4488 - acc: 0.8807 - val_loss: 0.4815 - val_acc: 0.8716\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4481 - acc: 0.8808 - val_loss: 0.4808 - val_acc: 0.8717\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4473 - acc: 0.8809 - val_loss: 0.4802 - val_acc: 0.8718\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.4466 - acc: 0.8811 - val_loss: 0.4795 - val_acc: 0.8719\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4459 - acc: 0.8812 - val_loss: 0.4788 - val_acc: 0.8720\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4451 - acc: 0.8814 - val_loss: 0.4781 - val_acc: 0.8722\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4444 - acc: 0.8815 - val_loss: 0.4775 - val_acc: 0.8722\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.4437 - acc: 0.8816 - val_loss: 0.4768 - val_acc: 0.8723\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4429 - acc: 0.8818 - val_loss: 0.4761 - val_acc: 0.8725\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4422 - acc: 0.8820 - val_loss: 0.4754 - val_acc: 0.8725\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4415 - acc: 0.8821 - val_loss: 0.4748 - val_acc: 0.8727\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4408 - acc: 0.8822 - val_loss: 0.4741 - val_acc: 0.8736\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4400 - acc: 0.8833 - val_loss: 0.4735 - val_acc: 0.8737\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 26ms/step - loss: 0.4393 - acc: 0.8834 - val_loss: 0.4728 - val_acc: 0.8737\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4386 - acc: 0.8837 - val_loss: 0.4721 - val_acc: 0.8739\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4379 - acc: 0.8839 - val_loss: 0.4715 - val_acc: 0.8739\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 22ms/step - loss: 0.4372 - acc: 0.8839 - val_loss: 0.4708 - val_acc: 0.8740\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.4365 - acc: 0.8841 - val_loss: 0.4702 - val_acc: 0.8741\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4358 - acc: 0.8842 - val_loss: 0.4695 - val_acc: 0.8744\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 24ms/step - loss: 0.4351 - acc: 0.8844 - val_loss: 0.4689 - val_acc: 0.8745\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 23ms/step - loss: 0.4344 - acc: 0.8845 - val_loss: 0.4683 - val_acc: 0.8745\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from models import GRUModel\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "checkpoint_path = os.path.join(weights_folder, \"gru\", \"checkpoint.hdf5\")\n",
        "history_path = os.path.join(weights_folder, \"gru\", \"history.npy\")\n",
        "\n",
        "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
        "hist_callback = MyHistory(history_path)\n",
        "\n",
        "model = GRUModel(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "model.compile(**compile_args, optimizer=optimizer)\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "history = model.fit(x=x_train_pad,\n",
        "                    y=y_train_pad,\n",
        "                    batch_size=256,\n",
        "                    epochs=500,\n",
        "                    validation_data=(x_val_pad,\n",
        "                                     y_val_pad),\n",
        "                    callbacks=[checkpoint_callback, hist_callback])\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U3z8B9GIgIpO"
      },
      "source": [
        "## Additional LSTM layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5AnRrcXngIpO",
        "outputId": "3d8156d4-b345-41c7-a9f8-e19e66a50e53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 7s 275ms/step - loss: 3.7498 - acc: 0.3156 - val_loss: 3.7001 - val_acc: 0.4764\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 3.6554 - acc: 0.4971 - val_loss: 3.6062 - val_acc: 0.5010\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 3.5547 - acc: 0.5157 - val_loss: 3.5016 - val_acc: 0.5091\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 3.4392 - acc: 0.5200 - val_loss: 3.3772 - val_acc: 0.5097\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 3.2986 - acc: 0.5204 - val_loss: 3.2219 - val_acc: 0.5099\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 3.1221 - acc: 0.5205 - val_loss: 3.0232 - val_acc: 0.5100\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 2.8958 - acc: 0.5200 - val_loss: 2.7724 - val_acc: 0.5099\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 2.6208 - acc: 0.5184 - val_loss: 2.4817 - val_acc: 0.5104\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 2.3318 - acc: 0.5174 - val_loss: 2.2121 - val_acc: 0.5115\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 2.0985 - acc: 0.5182 - val_loss: 2.0238 - val_acc: 0.5143\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.9495 - acc: 0.5201 - val_loss: 1.9075 - val_acc: 0.5197\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.8594 - acc: 0.5246 - val_loss: 1.8348 - val_acc: 0.5273\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.8016 - acc: 0.5294 - val_loss: 1.7878 - val_acc: 0.5317\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.7628 - acc: 0.5310 - val_loss: 1.7548 - val_acc: 0.5339\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.7344 - acc: 0.5322 - val_loss: 1.7300 - val_acc: 0.5350\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.7121 - acc: 0.5331 - val_loss: 1.7104 - val_acc: 0.5359\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.6942 - acc: 0.5341 - val_loss: 1.6943 - val_acc: 0.5368\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.6790 - acc: 0.5353 - val_loss: 1.6804 - val_acc: 0.5378\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.6656 - acc: 0.5365 - val_loss: 1.6680 - val_acc: 0.5391\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.6534 - acc: 0.5379 - val_loss: 1.6565 - val_acc: 0.5407\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.6421 - acc: 0.5396 - val_loss: 1.6460 - val_acc: 0.5422\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.6317 - acc: 0.5411 - val_loss: 1.6362 - val_acc: 0.5443\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.6220 - acc: 0.5435 - val_loss: 1.6268 - val_acc: 0.5459\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.6130 - acc: 0.5459 - val_loss: 1.6186 - val_acc: 0.5488\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.6045 - acc: 0.5485 - val_loss: 1.6107 - val_acc: 0.5502\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5966 - acc: 0.5510 - val_loss: 1.6033 - val_acc: 0.5516\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.5891 - acc: 0.5515 - val_loss: 1.5962 - val_acc: 0.5528\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5820 - acc: 0.5527 - val_loss: 1.5897 - val_acc: 0.5528\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5753 - acc: 0.5543 - val_loss: 1.5835 - val_acc: 0.5543\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5686 - acc: 0.5553 - val_loss: 1.5770 - val_acc: 0.5554\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.5623 - acc: 0.5559 - val_loss: 1.5711 - val_acc: 0.5564\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5561 - acc: 0.5583 - val_loss: 1.5653 - val_acc: 0.5572\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5501 - acc: 0.5578 - val_loss: 1.5594 - val_acc: 0.5578\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5442 - acc: 0.5595 - val_loss: 1.5540 - val_acc: 0.5607\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5386 - acc: 0.5612 - val_loss: 1.5484 - val_acc: 0.5604\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5329 - acc: 0.5614 - val_loss: 1.5430 - val_acc: 0.5616\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.5274 - acc: 0.5632 - val_loss: 1.5377 - val_acc: 0.5619\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.5219 - acc: 0.5650 - val_loss: 1.5322 - val_acc: 0.5629\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.5164 - acc: 0.5646 - val_loss: 1.5270 - val_acc: 0.5649\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5111 - acc: 0.5689 - val_loss: 1.5219 - val_acc: 0.5677\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.5058 - acc: 0.5677 - val_loss: 1.5168 - val_acc: 0.5693\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.5006 - acc: 0.5704 - val_loss: 1.5114 - val_acc: 0.5707\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4953 - acc: 0.5727 - val_loss: 1.5062 - val_acc: 0.5709\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4899 - acc: 0.5734 - val_loss: 1.5012 - val_acc: 0.5721\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4846 - acc: 0.5763 - val_loss: 1.4959 - val_acc: 0.5759\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4793 - acc: 0.5766 - val_loss: 1.4905 - val_acc: 0.5761\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 1.4740 - acc: 0.5787 - val_loss: 1.4855 - val_acc: 0.5783\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.4687 - acc: 0.5809 - val_loss: 1.4802 - val_acc: 0.5791\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4633 - acc: 0.5808 - val_loss: 1.4746 - val_acc: 0.5824\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4580 - acc: 0.5845 - val_loss: 1.4694 - val_acc: 0.5835\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4525 - acc: 0.5838 - val_loss: 1.4641 - val_acc: 0.5866\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4469 - acc: 0.5879 - val_loss: 1.4583 - val_acc: 0.5874\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4412 - acc: 0.5879 - val_loss: 1.4527 - val_acc: 0.5895\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.4357 - acc: 0.5907 - val_loss: 1.4471 - val_acc: 0.5922\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.4300 - acc: 0.5915 - val_loss: 1.4413 - val_acc: 0.5937\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4242 - acc: 0.5953 - val_loss: 1.4355 - val_acc: 0.5951\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 1.4183 - acc: 0.5956 - val_loss: 1.4296 - val_acc: 0.5959\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.4123 - acc: 0.5980 - val_loss: 1.4237 - val_acc: 0.5971\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.4063 - acc: 0.6002 - val_loss: 1.4176 - val_acc: 0.6011\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.4003 - acc: 0.6022 - val_loss: 1.4116 - val_acc: 0.6019\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.3942 - acc: 0.6040 - val_loss: 1.4055 - val_acc: 0.6053\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3881 - acc: 0.6061 - val_loss: 1.3995 - val_acc: 0.6066\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3819 - acc: 0.6086 - val_loss: 1.3933 - val_acc: 0.6077\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3756 - acc: 0.6107 - val_loss: 1.3870 - val_acc: 0.6082\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3692 - acc: 0.6126 - val_loss: 1.3810 - val_acc: 0.6107\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3630 - acc: 0.6151 - val_loss: 1.3743 - val_acc: 0.6135\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 1.3564 - acc: 0.6177 - val_loss: 1.3678 - val_acc: 0.6171\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3498 - acc: 0.6201 - val_loss: 1.3614 - val_acc: 0.6211\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3432 - acc: 0.6231 - val_loss: 1.3548 - val_acc: 0.6219\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3364 - acc: 0.6250 - val_loss: 1.3484 - val_acc: 0.6264\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.3298 - acc: 0.6290 - val_loss: 1.3414 - val_acc: 0.6284\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.3231 - acc: 0.6313 - val_loss: 1.3349 - val_acc: 0.6283\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.3162 - acc: 0.6345 - val_loss: 1.3280 - val_acc: 0.6323\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.3094 - acc: 0.6378 - val_loss: 1.3217 - val_acc: 0.6331\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.3025 - acc: 0.6394 - val_loss: 1.3143 - val_acc: 0.6380\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.2953 - acc: 0.6444 - val_loss: 1.3071 - val_acc: 0.6429\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 1.2882 - acc: 0.6473 - val_loss: 1.3001 - val_acc: 0.6461\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.2810 - acc: 0.6496 - val_loss: 1.2932 - val_acc: 0.6513\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 1.2739 - acc: 0.6542 - val_loss: 1.2859 - val_acc: 0.6517\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.2665 - acc: 0.6562 - val_loss: 1.2784 - val_acc: 0.6548\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.2591 - acc: 0.6600 - val_loss: 1.2714 - val_acc: 0.6574\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.2517 - acc: 0.6641 - val_loss: 1.2637 - val_acc: 0.6619\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.2442 - acc: 0.6670 - val_loss: 1.2564 - val_acc: 0.6637\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.2367 - acc: 0.6710 - val_loss: 1.2489 - val_acc: 0.6678\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.2291 - acc: 0.6742 - val_loss: 1.2411 - val_acc: 0.6706\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.2214 - acc: 0.6777 - val_loss: 1.2337 - val_acc: 0.6750\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 1.2139 - acc: 0.6811 - val_loss: 1.2259 - val_acc: 0.6767\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.2061 - acc: 0.6831 - val_loss: 1.2185 - val_acc: 0.6787\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1983 - acc: 0.6875 - val_loss: 1.2107 - val_acc: 0.6819\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1904 - acc: 0.6895 - val_loss: 1.2027 - val_acc: 0.6847\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1826 - acc: 0.6922 - val_loss: 1.1948 - val_acc: 0.6882\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1746 - acc: 0.6957 - val_loss: 1.1870 - val_acc: 0.6910\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1668 - acc: 0.6984 - val_loss: 1.1790 - val_acc: 0.6931\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1587 - acc: 0.7011 - val_loss: 1.1712 - val_acc: 0.6952\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1507 - acc: 0.7037 - val_loss: 1.1632 - val_acc: 0.6971\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1429 - acc: 0.7059 - val_loss: 1.1553 - val_acc: 0.7000\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 1.1348 - acc: 0.7090 - val_loss: 1.1472 - val_acc: 0.7029\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.1268 - acc: 0.7103 - val_loss: 1.1394 - val_acc: 0.7056\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.1187 - acc: 0.7134 - val_loss: 1.1313 - val_acc: 0.7075\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.1106 - acc: 0.7153 - val_loss: 1.1235 - val_acc: 0.7096\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 1.1026 - acc: 0.7167 - val_loss: 1.1153 - val_acc: 0.7122\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0946 - acc: 0.7195 - val_loss: 1.1074 - val_acc: 0.7140\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0866 - acc: 0.7210 - val_loss: 1.0996 - val_acc: 0.7154\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.0786 - acc: 0.7230 - val_loss: 1.0916 - val_acc: 0.7179\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.0707 - acc: 0.7250 - val_loss: 1.0838 - val_acc: 0.7208\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0627 - acc: 0.7278 - val_loss: 1.0758 - val_acc: 0.7224\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 1.0548 - acc: 0.7298 - val_loss: 1.0680 - val_acc: 0.7236\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0469 - acc: 0.7314 - val_loss: 1.0605 - val_acc: 0.7258\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 1.0390 - acc: 0.7338 - val_loss: 1.0528 - val_acc: 0.7270\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0313 - acc: 0.7352 - val_loss: 1.0452 - val_acc: 0.7289\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 1.0236 - acc: 0.7374 - val_loss: 1.0379 - val_acc: 0.7307\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0161 - acc: 0.7384 - val_loss: 1.0303 - val_acc: 0.7323\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 1.0085 - acc: 0.7404 - val_loss: 1.0229 - val_acc: 0.7346\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 1.0010 - acc: 0.7421 - val_loss: 1.0156 - val_acc: 0.7362\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9936 - acc: 0.7436 - val_loss: 1.0088 - val_acc: 0.7375\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9864 - acc: 0.7458 - val_loss: 1.0015 - val_acc: 0.7388\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.9792 - acc: 0.7473 - val_loss: 0.9944 - val_acc: 0.7400\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9721 - acc: 0.7491 - val_loss: 0.9876 - val_acc: 0.7426\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9650 - acc: 0.7499 - val_loss: 0.9808 - val_acc: 0.7435\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9581 - acc: 0.7518 - val_loss: 0.9742 - val_acc: 0.7450\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.9513 - acc: 0.7536 - val_loss: 0.9673 - val_acc: 0.7462\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9445 - acc: 0.7543 - val_loss: 0.9611 - val_acc: 0.7468\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9379 - acc: 0.7558 - val_loss: 0.9546 - val_acc: 0.7488\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.9314 - acc: 0.7570 - val_loss: 0.9483 - val_acc: 0.7493\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.9249 - acc: 0.7582 - val_loss: 0.9421 - val_acc: 0.7509\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.9186 - acc: 0.7602 - val_loss: 0.9361 - val_acc: 0.7520\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.9122 - acc: 0.7610 - val_loss: 0.9302 - val_acc: 0.7530\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.9061 - acc: 0.7619 - val_loss: 0.9242 - val_acc: 0.7546\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8999 - acc: 0.7634 - val_loss: 0.9183 - val_acc: 0.7556\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8939 - acc: 0.7648 - val_loss: 0.9125 - val_acc: 0.7566\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8880 - acc: 0.7658 - val_loss: 0.9068 - val_acc: 0.7579\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8822 - acc: 0.7677 - val_loss: 0.9013 - val_acc: 0.7588\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8764 - acc: 0.7688 - val_loss: 0.8960 - val_acc: 0.7605\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8708 - acc: 0.7703 - val_loss: 0.8904 - val_acc: 0.7616\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8652 - acc: 0.7712 - val_loss: 0.8850 - val_acc: 0.7626\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8598 - acc: 0.7728 - val_loss: 0.8797 - val_acc: 0.7639\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8544 - acc: 0.7735 - val_loss: 0.8745 - val_acc: 0.7650\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.8489 - acc: 0.7749 - val_loss: 0.8694 - val_acc: 0.7664\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8436 - acc: 0.7763 - val_loss: 0.8643 - val_acc: 0.7673\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8384 - acc: 0.7768 - val_loss: 0.8593 - val_acc: 0.7687\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8332 - acc: 0.7783 - val_loss: 0.8544 - val_acc: 0.7699\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.8281 - acc: 0.7794 - val_loss: 0.8495 - val_acc: 0.7705\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8232 - acc: 0.7796 - val_loss: 0.8446 - val_acc: 0.7712\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8182 - acc: 0.7813 - val_loss: 0.8401 - val_acc: 0.7729\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8133 - acc: 0.7824 - val_loss: 0.8352 - val_acc: 0.7734\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8084 - acc: 0.7832 - val_loss: 0.8307 - val_acc: 0.7747\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8036 - acc: 0.7843 - val_loss: 0.8260 - val_acc: 0.7758\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7990 - acc: 0.7854 - val_loss: 0.8215 - val_acc: 0.7774\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.7943 - acc: 0.7862 - val_loss: 0.8171 - val_acc: 0.7780\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7898 - acc: 0.7873 - val_loss: 0.8127 - val_acc: 0.7788\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7852 - acc: 0.7883 - val_loss: 0.8083 - val_acc: 0.7798\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7808 - acc: 0.7889 - val_loss: 0.8041 - val_acc: 0.7813\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7764 - acc: 0.7906 - val_loss: 0.7997 - val_acc: 0.7820\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7720 - acc: 0.7915 - val_loss: 0.7956 - val_acc: 0.7831\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7676 - acc: 0.7925 - val_loss: 0.7913 - val_acc: 0.7839\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.7634 - acc: 0.7935 - val_loss: 0.7873 - val_acc: 0.7851\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.7592 - acc: 0.7951 - val_loss: 0.7833 - val_acc: 0.7856\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7551 - acc: 0.7957 - val_loss: 0.7790 - val_acc: 0.7868\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7509 - acc: 0.7969 - val_loss: 0.7752 - val_acc: 0.7880\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7467 - acc: 0.7977 - val_loss: 0.7711 - val_acc: 0.7887\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7426 - acc: 0.7990 - val_loss: 0.7674 - val_acc: 0.7898\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7387 - acc: 0.8003 - val_loss: 0.7633 - val_acc: 0.7910\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7346 - acc: 0.8016 - val_loss: 0.7596 - val_acc: 0.7923\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7308 - acc: 0.8027 - val_loss: 0.7557 - val_acc: 0.7935\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7268 - acc: 0.8040 - val_loss: 0.7520 - val_acc: 0.7945\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.7230 - acc: 0.8050 - val_loss: 0.7483 - val_acc: 0.7955\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7192 - acc: 0.8063 - val_loss: 0.7446 - val_acc: 0.7965\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.7155 - acc: 0.8071 - val_loss: 0.7410 - val_acc: 0.7974\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.7116 - acc: 0.8085 - val_loss: 0.7375 - val_acc: 0.7987\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7080 - acc: 0.8096 - val_loss: 0.7339 - val_acc: 0.7997\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7043 - acc: 0.8110 - val_loss: 0.7303 - val_acc: 0.8007\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7007 - acc: 0.8121 - val_loss: 0.7267 - val_acc: 0.8023\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.6971 - acc: 0.8133 - val_loss: 0.7233 - val_acc: 0.8031\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6936 - acc: 0.8144 - val_loss: 0.7202 - val_acc: 0.8042\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.6901 - acc: 0.8155 - val_loss: 0.7165 - val_acc: 0.8050\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 57ms/step - loss: 0.6867 - acc: 0.8165 - val_loss: 0.7131 - val_acc: 0.8059\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 52ms/step - loss: 0.6833 - acc: 0.8178 - val_loss: 0.7101 - val_acc: 0.8071\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 60ms/step - loss: 0.6799 - acc: 0.8188 - val_loss: 0.7066 - val_acc: 0.8080\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.6766 - acc: 0.8200 - val_loss: 0.7035 - val_acc: 0.8092\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6733 - acc: 0.8208 - val_loss: 0.7002 - val_acc: 0.8098\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.6700 - acc: 0.8219 - val_loss: 0.6971 - val_acc: 0.8109\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6669 - acc: 0.8230 - val_loss: 0.6939 - val_acc: 0.8120\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.6636 - acc: 0.8243 - val_loss: 0.6911 - val_acc: 0.8127\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.6605 - acc: 0.8254 - val_loss: 0.6877 - val_acc: 0.8137\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6574 - acc: 0.8263 - val_loss: 0.6846 - val_acc: 0.8144\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.6543 - acc: 0.8272 - val_loss: 0.6818 - val_acc: 0.8151\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6513 - acc: 0.8277 - val_loss: 0.6787 - val_acc: 0.8159\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.6482 - acc: 0.8293 - val_loss: 0.6758 - val_acc: 0.8174\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6452 - acc: 0.8302 - val_loss: 0.6730 - val_acc: 0.8179\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6423 - acc: 0.8311 - val_loss: 0.6699 - val_acc: 0.8189\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.6394 - acc: 0.8318 - val_loss: 0.6671 - val_acc: 0.8194\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6365 - acc: 0.8331 - val_loss: 0.6644 - val_acc: 0.8203\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6337 - acc: 0.8339 - val_loss: 0.6617 - val_acc: 0.8208\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6308 - acc: 0.8343 - val_loss: 0.6587 - val_acc: 0.8219\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6280 - acc: 0.8358 - val_loss: 0.6561 - val_acc: 0.8225\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6252 - acc: 0.8360 - val_loss: 0.6531 - val_acc: 0.8233\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6225 - acc: 0.8371 - val_loss: 0.6506 - val_acc: 0.8240\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 55ms/step - loss: 0.6197 - acc: 0.8382 - val_loss: 0.6481 - val_acc: 0.8246\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.6171 - acc: 0.8386 - val_loss: 0.6453 - val_acc: 0.8254\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6144 - acc: 0.8393 - val_loss: 0.6427 - val_acc: 0.8261\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6117 - acc: 0.8400 - val_loss: 0.6401 - val_acc: 0.8266\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6091 - acc: 0.8408 - val_loss: 0.6376 - val_acc: 0.8276\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.6065 - acc: 0.8413 - val_loss: 0.6350 - val_acc: 0.8283\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6040 - acc: 0.8420 - val_loss: 0.6325 - val_acc: 0.8290\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6014 - acc: 0.8429 - val_loss: 0.6302 - val_acc: 0.8298\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5989 - acc: 0.8432 - val_loss: 0.6274 - val_acc: 0.8305\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5964 - acc: 0.8442 - val_loss: 0.6251 - val_acc: 0.8309\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.5939 - acc: 0.8449 - val_loss: 0.6228 - val_acc: 0.8316\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5915 - acc: 0.8451 - val_loss: 0.6203 - val_acc: 0.8320\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5891 - acc: 0.8458 - val_loss: 0.6182 - val_acc: 0.8328\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5867 - acc: 0.8464 - val_loss: 0.6156 - val_acc: 0.8335\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5843 - acc: 0.8471 - val_loss: 0.6133 - val_acc: 0.8341\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5820 - acc: 0.8479 - val_loss: 0.6110 - val_acc: 0.8348\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5796 - acc: 0.8482 - val_loss: 0.6087 - val_acc: 0.8350\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5773 - acc: 0.8488 - val_loss: 0.6064 - val_acc: 0.8358\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5750 - acc: 0.8498 - val_loss: 0.6043 - val_acc: 0.8364\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5727 - acc: 0.8499 - val_loss: 0.6019 - val_acc: 0.8364\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5705 - acc: 0.8509 - val_loss: 0.5997 - val_acc: 0.8377\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5682 - acc: 0.8513 - val_loss: 0.5977 - val_acc: 0.8381\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5660 - acc: 0.8518 - val_loss: 0.5953 - val_acc: 0.8388\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5638 - acc: 0.8522 - val_loss: 0.5933 - val_acc: 0.8391\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.5616 - acc: 0.8531 - val_loss: 0.5912 - val_acc: 0.8400\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5595 - acc: 0.8535 - val_loss: 0.5891 - val_acc: 0.8407\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5573 - acc: 0.8543 - val_loss: 0.5869 - val_acc: 0.8409\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5552 - acc: 0.8547 - val_loss: 0.5849 - val_acc: 0.8415\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5532 - acc: 0.8554 - val_loss: 0.5829 - val_acc: 0.8420\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.5511 - acc: 0.8558 - val_loss: 0.5809 - val_acc: 0.8427\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 51ms/step - loss: 0.5489 - acc: 0.8562 - val_loss: 0.5787 - val_acc: 0.8432\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5470 - acc: 0.8569 - val_loss: 0.5768 - val_acc: 0.8438\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5449 - acc: 0.8574 - val_loss: 0.5750 - val_acc: 0.8441\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5429 - acc: 0.8580 - val_loss: 0.5727 - val_acc: 0.8449\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5409 - acc: 0.8581 - val_loss: 0.5710 - val_acc: 0.8453\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5389 - acc: 0.8588 - val_loss: 0.5690 - val_acc: 0.8459\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5369 - acc: 0.8594 - val_loss: 0.5670 - val_acc: 0.8461\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5350 - acc: 0.8599 - val_loss: 0.5652 - val_acc: 0.8466\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5330 - acc: 0.8603 - val_loss: 0.5632 - val_acc: 0.8472\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5311 - acc: 0.8608 - val_loss: 0.5614 - val_acc: 0.8478\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5292 - acc: 0.8613 - val_loss: 0.5596 - val_acc: 0.8484\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5273 - acc: 0.8615 - val_loss: 0.5577 - val_acc: 0.8486\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5254 - acc: 0.8620 - val_loss: 0.5558 - val_acc: 0.8493\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5236 - acc: 0.8624 - val_loss: 0.5542 - val_acc: 0.8495\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5218 - acc: 0.8631 - val_loss: 0.5522 - val_acc: 0.8501\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.5199 - acc: 0.8633 - val_loss: 0.5506 - val_acc: 0.8505\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5182 - acc: 0.8636 - val_loss: 0.5486 - val_acc: 0.8508\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5162 - acc: 0.8644 - val_loss: 0.5469 - val_acc: 0.8515\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5144 - acc: 0.8645 - val_loss: 0.5450 - val_acc: 0.8518\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5126 - acc: 0.8650 - val_loss: 0.5435 - val_acc: 0.8522\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5110 - acc: 0.8652 - val_loss: 0.5418 - val_acc: 0.8526\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.5091 - acc: 0.8658 - val_loss: 0.5399 - val_acc: 0.8530\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5074 - acc: 0.8661 - val_loss: 0.5384 - val_acc: 0.8532\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5057 - acc: 0.8664 - val_loss: 0.5367 - val_acc: 0.8536\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5040 - acc: 0.8670 - val_loss: 0.5351 - val_acc: 0.8541\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5022 - acc: 0.8672 - val_loss: 0.5334 - val_acc: 0.8546\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.5005 - acc: 0.8676 - val_loss: 0.5317 - val_acc: 0.8551\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4989 - acc: 0.8681 - val_loss: 0.5301 - val_acc: 0.8558\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4972 - acc: 0.8686 - val_loss: 0.5285 - val_acc: 0.8559\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4955 - acc: 0.8691 - val_loss: 0.5268 - val_acc: 0.8565\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4938 - acc: 0.8693 - val_loss: 0.5252 - val_acc: 0.8568\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.4922 - acc: 0.8697 - val_loss: 0.5238 - val_acc: 0.8572\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4907 - acc: 0.8701 - val_loss: 0.5221 - val_acc: 0.8575\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4891 - acc: 0.8707 - val_loss: 0.5204 - val_acc: 0.8581\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4874 - acc: 0.8711 - val_loss: 0.5192 - val_acc: 0.8586\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4859 - acc: 0.8714 - val_loss: 0.5174 - val_acc: 0.8589\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4842 - acc: 0.8718 - val_loss: 0.5159 - val_acc: 0.8594\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4827 - acc: 0.8719 - val_loss: 0.5145 - val_acc: 0.8598\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4811 - acc: 0.8724 - val_loss: 0.5130 - val_acc: 0.8600\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4795 - acc: 0.8730 - val_loss: 0.5114 - val_acc: 0.8603\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4780 - acc: 0.8729 - val_loss: 0.5099 - val_acc: 0.8609\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.4764 - acc: 0.8736 - val_loss: 0.5085 - val_acc: 0.8612\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4749 - acc: 0.8737 - val_loss: 0.5070 - val_acc: 0.8613\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4734 - acc: 0.8741 - val_loss: 0.5055 - val_acc: 0.8622\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4719 - acc: 0.8745 - val_loss: 0.5041 - val_acc: 0.8623\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4704 - acc: 0.8751 - val_loss: 0.5027 - val_acc: 0.8627\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4689 - acc: 0.8754 - val_loss: 0.5011 - val_acc: 0.8631\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.4674 - acc: 0.8756 - val_loss: 0.4999 - val_acc: 0.8634\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4660 - acc: 0.8760 - val_loss: 0.4983 - val_acc: 0.8635\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4645 - acc: 0.8765 - val_loss: 0.4970 - val_acc: 0.8640\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4630 - acc: 0.8768 - val_loss: 0.4956 - val_acc: 0.8642\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 53ms/step - loss: 0.4617 - acc: 0.8770 - val_loss: 0.4944 - val_acc: 0.8647\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4602 - acc: 0.8775 - val_loss: 0.4928 - val_acc: 0.8647\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4588 - acc: 0.8779 - val_loss: 0.4915 - val_acc: 0.8651\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4574 - acc: 0.8782 - val_loss: 0.4902 - val_acc: 0.8656\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4560 - acc: 0.8785 - val_loss: 0.4888 - val_acc: 0.8658\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4546 - acc: 0.8791 - val_loss: 0.4876 - val_acc: 0.8662\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4532 - acc: 0.8794 - val_loss: 0.4861 - val_acc: 0.8666\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4518 - acc: 0.8797 - val_loss: 0.4848 - val_acc: 0.8670\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4505 - acc: 0.8800 - val_loss: 0.4835 - val_acc: 0.8673\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4491 - acc: 0.8805 - val_loss: 0.4824 - val_acc: 0.8673\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.4478 - acc: 0.8805 - val_loss: 0.4810 - val_acc: 0.8678\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4464 - acc: 0.8809 - val_loss: 0.4797 - val_acc: 0.8681\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4451 - acc: 0.8811 - val_loss: 0.4785 - val_acc: 0.8684\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4438 - acc: 0.8814 - val_loss: 0.4772 - val_acc: 0.8686\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4424 - acc: 0.8817 - val_loss: 0.4759 - val_acc: 0.8692\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4412 - acc: 0.8823 - val_loss: 0.4748 - val_acc: 0.8691\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4398 - acc: 0.8825 - val_loss: 0.4734 - val_acc: 0.8697\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4386 - acc: 0.8828 - val_loss: 0.4723 - val_acc: 0.8697\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4373 - acc: 0.8832 - val_loss: 0.4710 - val_acc: 0.8702\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4360 - acc: 0.8834 - val_loss: 0.4698 - val_acc: 0.8702\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.4347 - acc: 0.8836 - val_loss: 0.4686 - val_acc: 0.8709\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4335 - acc: 0.8841 - val_loss: 0.4675 - val_acc: 0.8710\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4322 - acc: 0.8844 - val_loss: 0.4662 - val_acc: 0.8716\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4310 - acc: 0.8848 - val_loss: 0.4650 - val_acc: 0.8716\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4297 - acc: 0.8851 - val_loss: 0.4638 - val_acc: 0.8722\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4285 - acc: 0.8853 - val_loss: 0.4628 - val_acc: 0.8724\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4273 - acc: 0.8856 - val_loss: 0.4617 - val_acc: 0.8726\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4261 - acc: 0.8858 - val_loss: 0.4603 - val_acc: 0.8729\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4248 - acc: 0.8862 - val_loss: 0.4594 - val_acc: 0.8733\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4237 - acc: 0.8865 - val_loss: 0.4581 - val_acc: 0.8737\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4225 - acc: 0.8867 - val_loss: 0.4570 - val_acc: 0.8737\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4213 - acc: 0.8870 - val_loss: 0.4561 - val_acc: 0.8742\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.4201 - acc: 0.8874 - val_loss: 0.4547 - val_acc: 0.8744\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.4190 - acc: 0.8876 - val_loss: 0.4539 - val_acc: 0.8748\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4178 - acc: 0.8879 - val_loss: 0.4525 - val_acc: 0.8749\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4166 - acc: 0.8881 - val_loss: 0.4515 - val_acc: 0.8751\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.4155 - acc: 0.8883 - val_loss: 0.4504 - val_acc: 0.8758\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4144 - acc: 0.8886 - val_loss: 0.4494 - val_acc: 0.8757\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4132 - acc: 0.8888 - val_loss: 0.4484 - val_acc: 0.8760\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4121 - acc: 0.8890 - val_loss: 0.4472 - val_acc: 0.8763\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4109 - acc: 0.8894 - val_loss: 0.4462 - val_acc: 0.8766\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.4098 - acc: 0.8896 - val_loss: 0.4452 - val_acc: 0.8765\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4087 - acc: 0.8899 - val_loss: 0.4440 - val_acc: 0.8769\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4076 - acc: 0.8902 - val_loss: 0.4431 - val_acc: 0.8773\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4065 - acc: 0.8906 - val_loss: 0.4420 - val_acc: 0.8773\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4054 - acc: 0.8907 - val_loss: 0.4409 - val_acc: 0.8777\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4043 - acc: 0.8911 - val_loss: 0.4401 - val_acc: 0.8777\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.4032 - acc: 0.8912 - val_loss: 0.4389 - val_acc: 0.8778\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.4022 - acc: 0.8916 - val_loss: 0.4380 - val_acc: 0.8783\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.4011 - acc: 0.8918 - val_loss: 0.4371 - val_acc: 0.8783\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.4001 - acc: 0.8920 - val_loss: 0.4362 - val_acc: 0.8787\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3990 - acc: 0.8923 - val_loss: 0.4349 - val_acc: 0.8786\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3980 - acc: 0.8926 - val_loss: 0.4341 - val_acc: 0.8792\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3969 - acc: 0.8928 - val_loss: 0.4329 - val_acc: 0.8794\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3958 - acc: 0.8928 - val_loss: 0.4321 - val_acc: 0.8794\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3948 - acc: 0.8933 - val_loss: 0.4311 - val_acc: 0.8796\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3938 - acc: 0.8934 - val_loss: 0.4301 - val_acc: 0.8802\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3927 - acc: 0.8938 - val_loss: 0.4292 - val_acc: 0.8802\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3917 - acc: 0.8939 - val_loss: 0.4283 - val_acc: 0.8803\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3907 - acc: 0.8940 - val_loss: 0.4273 - val_acc: 0.8807\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3897 - acc: 0.8946 - val_loss: 0.4264 - val_acc: 0.8810\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3887 - acc: 0.8946 - val_loss: 0.4254 - val_acc: 0.8808\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3878 - acc: 0.8949 - val_loss: 0.4246 - val_acc: 0.8813\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3867 - acc: 0.8949 - val_loss: 0.4236 - val_acc: 0.8817\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3857 - acc: 0.8955 - val_loss: 0.4227 - val_acc: 0.8820\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3848 - acc: 0.8957 - val_loss: 0.4217 - val_acc: 0.8820\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3838 - acc: 0.8956 - val_loss: 0.4210 - val_acc: 0.8823\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3828 - acc: 0.8963 - val_loss: 0.4200 - val_acc: 0.8826\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3819 - acc: 0.8964 - val_loss: 0.4192 - val_acc: 0.8828\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3809 - acc: 0.8966 - val_loss: 0.4183 - val_acc: 0.8829\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3800 - acc: 0.8967 - val_loss: 0.4173 - val_acc: 0.8832\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3790 - acc: 0.8968 - val_loss: 0.4165 - val_acc: 0.8833\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3780 - acc: 0.8972 - val_loss: 0.4155 - val_acc: 0.8836\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3771 - acc: 0.8973 - val_loss: 0.4147 - val_acc: 0.8838\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3761 - acc: 0.8977 - val_loss: 0.4140 - val_acc: 0.8841\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3753 - acc: 0.8977 - val_loss: 0.4130 - val_acc: 0.8842\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3743 - acc: 0.8980 - val_loss: 0.4122 - val_acc: 0.8845\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3734 - acc: 0.8983 - val_loss: 0.4113 - val_acc: 0.8850\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3724 - acc: 0.8984 - val_loss: 0.4106 - val_acc: 0.8852\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3715 - acc: 0.8988 - val_loss: 0.4096 - val_acc: 0.8852\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3706 - acc: 0.8990 - val_loss: 0.4089 - val_acc: 0.8855\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 45ms/step - loss: 0.3697 - acc: 0.8993 - val_loss: 0.4080 - val_acc: 0.8858\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3688 - acc: 0.8993 - val_loss: 0.4070 - val_acc: 0.8860\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3679 - acc: 0.8998 - val_loss: 0.4064 - val_acc: 0.8862\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3670 - acc: 0.8998 - val_loss: 0.4055 - val_acc: 0.8864\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3662 - acc: 0.9001 - val_loss: 0.4047 - val_acc: 0.8866\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3652 - acc: 0.9004 - val_loss: 0.4038 - val_acc: 0.8868\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3644 - acc: 0.9006 - val_loss: 0.4030 - val_acc: 0.8868\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3635 - acc: 0.9010 - val_loss: 0.4023 - val_acc: 0.8872\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3627 - acc: 0.9009 - val_loss: 0.4016 - val_acc: 0.8874\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3618 - acc: 0.9012 - val_loss: 0.4006 - val_acc: 0.8877\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3609 - acc: 0.9015 - val_loss: 0.3999 - val_acc: 0.8878\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3600 - acc: 0.9018 - val_loss: 0.3991 - val_acc: 0.8880\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3592 - acc: 0.9021 - val_loss: 0.3982 - val_acc: 0.8883\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3583 - acc: 0.9024 - val_loss: 0.3976 - val_acc: 0.8884\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.3574 - acc: 0.9024 - val_loss: 0.3967 - val_acc: 0.8886\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3567 - acc: 0.9025 - val_loss: 0.3962 - val_acc: 0.8887\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.3558 - acc: 0.9030 - val_loss: 0.3952 - val_acc: 0.8889\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3549 - acc: 0.9032 - val_loss: 0.3945 - val_acc: 0.8891\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3541 - acc: 0.9035 - val_loss: 0.3938 - val_acc: 0.8893\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3533 - acc: 0.9040 - val_loss: 0.3930 - val_acc: 0.8894\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.3524 - acc: 0.9040 - val_loss: 0.3923 - val_acc: 0.8895\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3516 - acc: 0.9041 - val_loss: 0.3915 - val_acc: 0.8899\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.3508 - acc: 0.9046 - val_loss: 0.3909 - val_acc: 0.8898\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 50ms/step - loss: 0.3500 - acc: 0.9046 - val_loss: 0.3899 - val_acc: 0.8901\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.3492 - acc: 0.9047 - val_loss: 0.3896 - val_acc: 0.8904\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 62ms/step - loss: 0.3484 - acc: 0.9051 - val_loss: 0.3885 - val_acc: 0.8904\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 1s 95ms/step - loss: 0.3475 - acc: 0.9053 - val_loss: 0.3880 - val_acc: 0.8906\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3467 - acc: 0.9055 - val_loss: 0.3871 - val_acc: 0.8910\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3459 - acc: 0.9059 - val_loss: 0.3865 - val_acc: 0.8911\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3452 - acc: 0.9058 - val_loss: 0.3856 - val_acc: 0.8912\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 46ms/step - loss: 0.3443 - acc: 0.9060 - val_loss: 0.3850 - val_acc: 0.8912\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3436 - acc: 0.9062 - val_loss: 0.3842 - val_acc: 0.8914\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3428 - acc: 0.9065 - val_loss: 0.3837 - val_acc: 0.8914\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3420 - acc: 0.9067 - val_loss: 0.3828 - val_acc: 0.8918\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3412 - acc: 0.9067 - val_loss: 0.3822 - val_acc: 0.8917\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3405 - acc: 0.9070 - val_loss: 0.3815 - val_acc: 0.8920\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3398 - acc: 0.9070 - val_loss: 0.3809 - val_acc: 0.8921\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3390 - acc: 0.9073 - val_loss: 0.3803 - val_acc: 0.8922\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3381 - acc: 0.9076 - val_loss: 0.3794 - val_acc: 0.8924\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3373 - acc: 0.9077 - val_loss: 0.3789 - val_acc: 0.8926\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.3365 - acc: 0.9080 - val_loss: 0.3780 - val_acc: 0.8929\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3359 - acc: 0.9079 - val_loss: 0.3776 - val_acc: 0.8930\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3351 - acc: 0.9081 - val_loss: 0.3765 - val_acc: 0.8933\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3343 - acc: 0.9085 - val_loss: 0.3759 - val_acc: 0.8932\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3336 - acc: 0.9086 - val_loss: 0.3755 - val_acc: 0.8935\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3328 - acc: 0.9086 - val_loss: 0.3745 - val_acc: 0.8936\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3320 - acc: 0.9091 - val_loss: 0.3742 - val_acc: 0.8938\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3314 - acc: 0.9091 - val_loss: 0.3734 - val_acc: 0.8940\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3306 - acc: 0.9093 - val_loss: 0.3727 - val_acc: 0.8941\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3298 - acc: 0.9098 - val_loss: 0.3721 - val_acc: 0.8941\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3291 - acc: 0.9097 - val_loss: 0.3714 - val_acc: 0.8944\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3283 - acc: 0.9101 - val_loss: 0.3708 - val_acc: 0.8945\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3276 - acc: 0.9101 - val_loss: 0.3701 - val_acc: 0.8946\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3269 - acc: 0.9104 - val_loss: 0.3696 - val_acc: 0.8948\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3262 - acc: 0.9106 - val_loss: 0.3687 - val_acc: 0.8951\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3254 - acc: 0.9108 - val_loss: 0.3684 - val_acc: 0.8948\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.3247 - acc: 0.9109 - val_loss: 0.3675 - val_acc: 0.8955\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3240 - acc: 0.9113 - val_loss: 0.3669 - val_acc: 0.8953\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3233 - acc: 0.9114 - val_loss: 0.3664 - val_acc: 0.8959\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3225 - acc: 0.9117 - val_loss: 0.3658 - val_acc: 0.8957\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3219 - acc: 0.9117 - val_loss: 0.3650 - val_acc: 0.8959\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3211 - acc: 0.9118 - val_loss: 0.3645 - val_acc: 0.8963\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3204 - acc: 0.9121 - val_loss: 0.3639 - val_acc: 0.8962\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3197 - acc: 0.9122 - val_loss: 0.3632 - val_acc: 0.8966\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3190 - acc: 0.9123 - val_loss: 0.3627 - val_acc: 0.8965\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3183 - acc: 0.9127 - val_loss: 0.3621 - val_acc: 0.8967\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3176 - acc: 0.9125 - val_loss: 0.3612 - val_acc: 0.8972\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3169 - acc: 0.9131 - val_loss: 0.3608 - val_acc: 0.8972\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3162 - acc: 0.9131 - val_loss: 0.3602 - val_acc: 0.8975\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3156 - acc: 0.9133 - val_loss: 0.3595 - val_acc: 0.8975\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3148 - acc: 0.9135 - val_loss: 0.3590 - val_acc: 0.8977\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3142 - acc: 0.9137 - val_loss: 0.3584 - val_acc: 0.8977\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3135 - acc: 0.9139 - val_loss: 0.3577 - val_acc: 0.8979\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3128 - acc: 0.9140 - val_loss: 0.3573 - val_acc: 0.8981\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3121 - acc: 0.9143 - val_loss: 0.3565 - val_acc: 0.8983\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3114 - acc: 0.9143 - val_loss: 0.3559 - val_acc: 0.8983\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.3107 - acc: 0.9147 - val_loss: 0.3555 - val_acc: 0.8984\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3101 - acc: 0.9146 - val_loss: 0.3548 - val_acc: 0.8985\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3095 - acc: 0.9151 - val_loss: 0.3543 - val_acc: 0.8988\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3087 - acc: 0.9152 - val_loss: 0.3536 - val_acc: 0.8990\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3081 - acc: 0.9153 - val_loss: 0.3531 - val_acc: 0.8993\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3074 - acc: 0.9156 - val_loss: 0.3525 - val_acc: 0.8996\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.3067 - acc: 0.9160 - val_loss: 0.3518 - val_acc: 0.8997\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3061 - acc: 0.9158 - val_loss: 0.3515 - val_acc: 0.8997\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3054 - acc: 0.9161 - val_loss: 0.3508 - val_acc: 0.9000\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3047 - acc: 0.9164 - val_loss: 0.3503 - val_acc: 0.9001\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3041 - acc: 0.9163 - val_loss: 0.3498 - val_acc: 0.9003\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3034 - acc: 0.9167 - val_loss: 0.3492 - val_acc: 0.9005\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3028 - acc: 0.9168 - val_loss: 0.3485 - val_acc: 0.9009\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3022 - acc: 0.9171 - val_loss: 0.3482 - val_acc: 0.9008\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.3015 - acc: 0.9173 - val_loss: 0.3475 - val_acc: 0.9010\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.3009 - acc: 0.9174 - val_loss: 0.3469 - val_acc: 0.9011\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.3002 - acc: 0.9176 - val_loss: 0.3465 - val_acc: 0.9015\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.2996 - acc: 0.9177 - val_loss: 0.3460 - val_acc: 0.9014\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2989 - acc: 0.9178 - val_loss: 0.3453 - val_acc: 0.9017\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2983 - acc: 0.9181 - val_loss: 0.3448 - val_acc: 0.9015\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2977 - acc: 0.9182 - val_loss: 0.3442 - val_acc: 0.9018\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2970 - acc: 0.9183 - val_loss: 0.3437 - val_acc: 0.9021\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2965 - acc: 0.9187 - val_loss: 0.3433 - val_acc: 0.9021\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2958 - acc: 0.9187 - val_loss: 0.3425 - val_acc: 0.9023\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2951 - acc: 0.9188 - val_loss: 0.3422 - val_acc: 0.9027\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 56ms/step - loss: 0.2945 - acc: 0.9191 - val_loss: 0.3416 - val_acc: 0.9027\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2939 - acc: 0.9191 - val_loss: 0.3409 - val_acc: 0.9027\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.2933 - acc: 0.9193 - val_loss: 0.3406 - val_acc: 0.9029\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2927 - acc: 0.9194 - val_loss: 0.3400 - val_acc: 0.9030\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2920 - acc: 0.9196 - val_loss: 0.3396 - val_acc: 0.9030\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2915 - acc: 0.9199 - val_loss: 0.3389 - val_acc: 0.9033\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2909 - acc: 0.9199 - val_loss: 0.3384 - val_acc: 0.9034\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2902 - acc: 0.9202 - val_loss: 0.3380 - val_acc: 0.9035\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2896 - acc: 0.9203 - val_loss: 0.3377 - val_acc: 0.9038\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2890 - acc: 0.9205 - val_loss: 0.3368 - val_acc: 0.9039\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 49ms/step - loss: 0.2884 - acc: 0.9206 - val_loss: 0.3364 - val_acc: 0.9037\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.2878 - acc: 0.9207 - val_loss: 0.3359 - val_acc: 0.9042\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2871 - acc: 0.9208 - val_loss: 0.3354 - val_acc: 0.9043\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2866 - acc: 0.9211 - val_loss: 0.3348 - val_acc: 0.9045\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2859 - acc: 0.9213 - val_loss: 0.3345 - val_acc: 0.9045\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2854 - acc: 0.9216 - val_loss: 0.3340 - val_acc: 0.9046\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2848 - acc: 0.9216 - val_loss: 0.3334 - val_acc: 0.9048\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2842 - acc: 0.9217 - val_loss: 0.3329 - val_acc: 0.9048\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2836 - acc: 0.9219 - val_loss: 0.3325 - val_acc: 0.9049\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2830 - acc: 0.9221 - val_loss: 0.3319 - val_acc: 0.9052\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 54ms/step - loss: 0.2824 - acc: 0.9223 - val_loss: 0.3313 - val_acc: 0.9054\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2818 - acc: 0.9224 - val_loss: 0.3309 - val_acc: 0.9053\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2812 - acc: 0.9225 - val_loss: 0.3305 - val_acc: 0.9054\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2807 - acc: 0.9229 - val_loss: 0.3300 - val_acc: 0.9056\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2801 - acc: 0.9228 - val_loss: 0.3296 - val_acc: 0.9058\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2796 - acc: 0.9231 - val_loss: 0.3290 - val_acc: 0.9058\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2789 - acc: 0.9233 - val_loss: 0.3286 - val_acc: 0.9060\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2783 - acc: 0.9236 - val_loss: 0.3281 - val_acc: 0.9061\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2778 - acc: 0.9235 - val_loss: 0.3275 - val_acc: 0.9065\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2772 - acc: 0.9238 - val_loss: 0.3273 - val_acc: 0.9062\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2766 - acc: 0.9240 - val_loss: 0.3267 - val_acc: 0.9066\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.2760 - acc: 0.9241 - val_loss: 0.3262 - val_acc: 0.9064\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2755 - acc: 0.9242 - val_loss: 0.3257 - val_acc: 0.9069\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2750 - acc: 0.9245 - val_loss: 0.3253 - val_acc: 0.9069\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.2743 - acc: 0.9245 - val_loss: 0.3247 - val_acc: 0.9069\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2738 - acc: 0.9247 - val_loss: 0.3244 - val_acc: 0.9069\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2732 - acc: 0.9248 - val_loss: 0.3238 - val_acc: 0.9074\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.2727 - acc: 0.9248 - val_loss: 0.3237 - val_acc: 0.9072\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2721 - acc: 0.9250 - val_loss: 0.3228 - val_acc: 0.9076\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.2716 - acc: 0.9253 - val_loss: 0.3227 - val_acc: 0.9077\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "from models import additionalLSTM\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-4)\n",
        "\n",
        "checkpoint_path = os.path.join(weights_folder, \"additionalLSTM\", \"checkpoint.hdf5\")\n",
        "history_path = os.path.join(weights_folder, \"additionalLSTM\", \"history.npy\")\n",
        "\n",
        "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
        "hist_callback = MyHistory(history_path)\n",
        "\n",
        "model = additionalLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "model.compile(**compile_args, optimizer=optimizer)\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "history = model.fit(x=x_train_pad,\n",
        "                    y=y_train_pad,\n",
        "                    batch_size=256,\n",
        "                    epochs=500,\n",
        "                    validation_data=(x_val_pad,\n",
        "                                     y_val_pad),\n",
        "                    callbacks=[checkpoint_callback, hist_callback])\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ybT7-EN2gIpO"
      },
      "source": [
        "## Additional Dense"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WzvrTGU3gIpP",
        "outputId": "c68ed51b-4bfd-48a5-b53e-3fd612e64ba8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "8/8 [==============================] - 4s 145ms/step - loss: 0.9876 - acc: 0.6895 - val_loss: 1.0824 - val_acc: 0.6538\n",
            "Epoch 2/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.9849 - acc: 0.6859 - val_loss: 1.0817 - val_acc: 0.6681\n",
            "Epoch 3/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9830 - acc: 0.6902 - val_loss: 1.0801 - val_acc: 0.6680\n",
            "Epoch 4/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9818 - acc: 0.6920 - val_loss: 1.0800 - val_acc: 0.6637\n",
            "Epoch 5/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9807 - acc: 0.6918 - val_loss: 1.0788 - val_acc: 0.6674\n",
            "Epoch 6/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9797 - acc: 0.6920 - val_loss: 1.0783 - val_acc: 0.6683\n",
            "Epoch 7/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9787 - acc: 0.6924 - val_loss: 1.0778 - val_acc: 0.6679\n",
            "Epoch 8/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9778 - acc: 0.6924 - val_loss: 1.0773 - val_acc: 0.6679\n",
            "Epoch 9/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9770 - acc: 0.6925 - val_loss: 1.0765 - val_acc: 0.6681\n",
            "Epoch 10/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9761 - acc: 0.6926 - val_loss: 1.0761 - val_acc: 0.6678\n",
            "Epoch 11/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9752 - acc: 0.6926 - val_loss: 1.0754 - val_acc: 0.6682\n",
            "Epoch 12/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9744 - acc: 0.6927 - val_loss: 1.0752 - val_acc: 0.6677\n",
            "Epoch 13/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9736 - acc: 0.6927 - val_loss: 1.0744 - val_acc: 0.6681\n",
            "Epoch 14/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9728 - acc: 0.6928 - val_loss: 1.0741 - val_acc: 0.6679\n",
            "Epoch 15/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9720 - acc: 0.6929 - val_loss: 1.0734 - val_acc: 0.6679\n",
            "Epoch 16/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9712 - acc: 0.6929 - val_loss: 1.0731 - val_acc: 0.6685\n",
            "Epoch 17/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9705 - acc: 0.6930 - val_loss: 1.0724 - val_acc: 0.6685\n",
            "Epoch 18/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9697 - acc: 0.6931 - val_loss: 1.0720 - val_acc: 0.6681\n",
            "Epoch 19/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9690 - acc: 0.6931 - val_loss: 1.0713 - val_acc: 0.6687\n",
            "Epoch 20/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9682 - acc: 0.6931 - val_loss: 1.0711 - val_acc: 0.6683\n",
            "Epoch 21/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9675 - acc: 0.6931 - val_loss: 1.0708 - val_acc: 0.6687\n",
            "Epoch 22/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9668 - acc: 0.6932 - val_loss: 1.0702 - val_acc: 0.6679\n",
            "Epoch 23/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.9661 - acc: 0.6932 - val_loss: 1.0697 - val_acc: 0.6687\n",
            "Epoch 24/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9653 - acc: 0.6933 - val_loss: 1.0693 - val_acc: 0.6681\n",
            "Epoch 25/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9646 - acc: 0.6933 - val_loss: 1.0692 - val_acc: 0.6687\n",
            "Epoch 26/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9638 - acc: 0.6934 - val_loss: 1.0678 - val_acc: 0.6686\n",
            "Epoch 27/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9629 - acc: 0.6934 - val_loss: 1.0668 - val_acc: 0.6688\n",
            "Epoch 28/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9616 - acc: 0.6934 - val_loss: 1.0645 - val_acc: 0.6688\n",
            "Epoch 29/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9605 - acc: 0.6935 - val_loss: 1.0632 - val_acc: 0.6685\n",
            "Epoch 30/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9595 - acc: 0.6935 - val_loss: 1.0621 - val_acc: 0.6690\n",
            "Epoch 31/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9586 - acc: 0.6936 - val_loss: 1.0617 - val_acc: 0.6687\n",
            "Epoch 32/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9577 - acc: 0.6937 - val_loss: 1.0608 - val_acc: 0.6688\n",
            "Epoch 33/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.9567 - acc: 0.6936 - val_loss: 1.0594 - val_acc: 0.6694\n",
            "Epoch 34/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9558 - acc: 0.6937 - val_loss: 1.0590 - val_acc: 0.6693\n",
            "Epoch 35/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9550 - acc: 0.6938 - val_loss: 1.0579 - val_acc: 0.6690\n",
            "Epoch 36/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9540 - acc: 0.6939 - val_loss: 1.0572 - val_acc: 0.6692\n",
            "Epoch 37/500\n",
            "8/8 [==============================] - 0s 66ms/step - loss: 0.9531 - acc: 0.6939 - val_loss: 1.0561 - val_acc: 0.6690\n",
            "Epoch 38/500\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.9521 - acc: 0.6940 - val_loss: 1.0553 - val_acc: 0.6691\n",
            "Epoch 39/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9511 - acc: 0.6940 - val_loss: 1.0547 - val_acc: 0.6694\n",
            "Epoch 40/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9501 - acc: 0.6941 - val_loss: 1.0536 - val_acc: 0.6693\n",
            "Epoch 41/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9491 - acc: 0.6941 - val_loss: 1.0526 - val_acc: 0.6693\n",
            "Epoch 42/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9480 - acc: 0.6942 - val_loss: 1.0518 - val_acc: 0.6692\n",
            "Epoch 43/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.9469 - acc: 0.6943 - val_loss: 1.0505 - val_acc: 0.6695\n",
            "Epoch 44/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9459 - acc: 0.6944 - val_loss: 1.0498 - val_acc: 0.6696\n",
            "Epoch 45/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.9449 - acc: 0.6944 - val_loss: 1.0484 - val_acc: 0.6699\n",
            "Epoch 46/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9438 - acc: 0.6945 - val_loss: 1.0480 - val_acc: 0.6693\n",
            "Epoch 47/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9427 - acc: 0.6945 - val_loss: 1.0472 - val_acc: 0.6693\n",
            "Epoch 48/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9417 - acc: 0.6946 - val_loss: 1.0460 - val_acc: 0.6698\n",
            "Epoch 49/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9406 - acc: 0.6947 - val_loss: 1.0453 - val_acc: 0.6696\n",
            "Epoch 50/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.9396 - acc: 0.6948 - val_loss: 1.0450 - val_acc: 0.6695\n",
            "Epoch 51/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9386 - acc: 0.6948 - val_loss: 1.0434 - val_acc: 0.6700\n",
            "Epoch 52/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9376 - acc: 0.6948 - val_loss: 1.0425 - val_acc: 0.6702\n",
            "Epoch 53/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9367 - acc: 0.6948 - val_loss: 1.0419 - val_acc: 0.6700\n",
            "Epoch 54/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9356 - acc: 0.6949 - val_loss: 1.0413 - val_acc: 0.6699\n",
            "Epoch 55/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9345 - acc: 0.6949 - val_loss: 1.0402 - val_acc: 0.6701\n",
            "Epoch 56/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9334 - acc: 0.6953 - val_loss: 1.0395 - val_acc: 0.6704\n",
            "Epoch 57/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9323 - acc: 0.6958 - val_loss: 1.0386 - val_acc: 0.6706\n",
            "Epoch 58/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9312 - acc: 0.6962 - val_loss: 1.0378 - val_acc: 0.6708\n",
            "Epoch 59/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9303 - acc: 0.6967 - val_loss: 1.0367 - val_acc: 0.6717\n",
            "Epoch 60/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9292 - acc: 0.6974 - val_loss: 1.0360 - val_acc: 0.6719\n",
            "Epoch 61/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9282 - acc: 0.6977 - val_loss: 1.0353 - val_acc: 0.6727\n",
            "Epoch 62/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9272 - acc: 0.6989 - val_loss: 1.0339 - val_acc: 0.6734\n",
            "Epoch 63/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.9262 - acc: 0.6994 - val_loss: 1.0337 - val_acc: 0.6745\n",
            "Epoch 64/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9252 - acc: 0.7002 - val_loss: 1.0326 - val_acc: 0.6752\n",
            "Epoch 65/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9241 - acc: 0.7009 - val_loss: 1.0318 - val_acc: 0.6758\n",
            "Epoch 66/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9232 - acc: 0.7019 - val_loss: 1.0312 - val_acc: 0.6760\n",
            "Epoch 67/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9222 - acc: 0.7026 - val_loss: 1.0305 - val_acc: 0.6772\n",
            "Epoch 68/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9212 - acc: 0.7032 - val_loss: 1.0295 - val_acc: 0.6780\n",
            "Epoch 69/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9203 - acc: 0.7044 - val_loss: 1.0290 - val_acc: 0.6786\n",
            "Epoch 70/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9193 - acc: 0.7049 - val_loss: 1.0279 - val_acc: 0.6792\n",
            "Epoch 71/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9184 - acc: 0.7061 - val_loss: 1.0271 - val_acc: 0.6802\n",
            "Epoch 72/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9173 - acc: 0.7064 - val_loss: 1.0263 - val_acc: 0.6812\n",
            "Epoch 73/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.9165 - acc: 0.7076 - val_loss: 1.0257 - val_acc: 0.6810\n",
            "Epoch 74/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9154 - acc: 0.7079 - val_loss: 1.0250 - val_acc: 0.6818\n",
            "Epoch 75/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.9144 - acc: 0.7084 - val_loss: 1.0242 - val_acc: 0.6829\n",
            "Epoch 76/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.9135 - acc: 0.7096 - val_loss: 1.0235 - val_acc: 0.6827\n",
            "Epoch 77/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9126 - acc: 0.7100 - val_loss: 1.0228 - val_acc: 0.6839\n",
            "Epoch 78/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9115 - acc: 0.7102 - val_loss: 1.0219 - val_acc: 0.6850\n",
            "Epoch 79/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9105 - acc: 0.7110 - val_loss: 1.0213 - val_acc: 0.6851\n",
            "Epoch 80/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.9096 - acc: 0.7113 - val_loss: 1.0202 - val_acc: 0.6851\n",
            "Epoch 81/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.9086 - acc: 0.7117 - val_loss: 1.0196 - val_acc: 0.6863\n",
            "Epoch 82/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9075 - acc: 0.7125 - val_loss: 1.0187 - val_acc: 0.6866\n",
            "Epoch 83/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.9065 - acc: 0.7130 - val_loss: 1.0184 - val_acc: 0.6870\n",
            "Epoch 84/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.9055 - acc: 0.7132 - val_loss: 1.0174 - val_acc: 0.6872\n",
            "Epoch 85/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9045 - acc: 0.7134 - val_loss: 1.0163 - val_acc: 0.6878\n",
            "Epoch 86/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9034 - acc: 0.7141 - val_loss: 1.0160 - val_acc: 0.6885\n",
            "Epoch 87/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.9024 - acc: 0.7144 - val_loss: 1.0152 - val_acc: 0.6883\n",
            "Epoch 88/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9013 - acc: 0.7150 - val_loss: 1.0142 - val_acc: 0.6888\n",
            "Epoch 89/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.9002 - acc: 0.7157 - val_loss: 1.0138 - val_acc: 0.6888\n",
            "Epoch 90/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8992 - acc: 0.7166 - val_loss: 1.0133 - val_acc: 0.6891\n",
            "Epoch 91/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8983 - acc: 0.7167 - val_loss: 1.0122 - val_acc: 0.6895\n",
            "Epoch 92/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8972 - acc: 0.7171 - val_loss: 1.0111 - val_acc: 0.6898\n",
            "Epoch 93/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8963 - acc: 0.7170 - val_loss: 1.0108 - val_acc: 0.6901\n",
            "Epoch 94/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8953 - acc: 0.7177 - val_loss: 1.0099 - val_acc: 0.6898\n",
            "Epoch 95/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8943 - acc: 0.7181 - val_loss: 1.0092 - val_acc: 0.6900\n",
            "Epoch 96/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8932 - acc: 0.7186 - val_loss: 1.0084 - val_acc: 0.6903\n",
            "Epoch 97/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8921 - acc: 0.7192 - val_loss: 1.0075 - val_acc: 0.6905\n",
            "Epoch 98/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8910 - acc: 0.7195 - val_loss: 1.0068 - val_acc: 0.6904\n",
            "Epoch 99/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8900 - acc: 0.7195 - val_loss: 1.0055 - val_acc: 0.6912\n",
            "Epoch 100/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8888 - acc: 0.7202 - val_loss: 1.0048 - val_acc: 0.6910\n",
            "Epoch 101/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8877 - acc: 0.7210 - val_loss: 1.0037 - val_acc: 0.6915\n",
            "Epoch 102/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8864 - acc: 0.7214 - val_loss: 1.0026 - val_acc: 0.6919\n",
            "Epoch 103/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.8853 - acc: 0.7224 - val_loss: 1.0020 - val_acc: 0.6923\n",
            "Epoch 104/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8840 - acc: 0.7228 - val_loss: 1.0005 - val_acc: 0.6926\n",
            "Epoch 105/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8827 - acc: 0.7235 - val_loss: 0.9993 - val_acc: 0.6934\n",
            "Epoch 106/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8814 - acc: 0.7240 - val_loss: 0.9981 - val_acc: 0.6939\n",
            "Epoch 107/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8800 - acc: 0.7246 - val_loss: 0.9975 - val_acc: 0.6936\n",
            "Epoch 108/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8786 - acc: 0.7252 - val_loss: 0.9960 - val_acc: 0.6942\n",
            "Epoch 109/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8770 - acc: 0.7264 - val_loss: 0.9952 - val_acc: 0.6943\n",
            "Epoch 110/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8754 - acc: 0.7271 - val_loss: 0.9941 - val_acc: 0.6950\n",
            "Epoch 111/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8739 - acc: 0.7277 - val_loss: 0.9931 - val_acc: 0.6952\n",
            "Epoch 112/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8724 - acc: 0.7282 - val_loss: 0.9921 - val_acc: 0.6958\n",
            "Epoch 113/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.8711 - acc: 0.7287 - val_loss: 0.9904 - val_acc: 0.6960\n",
            "Epoch 114/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8695 - acc: 0.7294 - val_loss: 0.9898 - val_acc: 0.6961\n",
            "Epoch 115/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8679 - acc: 0.7301 - val_loss: 0.9888 - val_acc: 0.6962\n",
            "Epoch 116/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8664 - acc: 0.7307 - val_loss: 0.9876 - val_acc: 0.6969\n",
            "Epoch 117/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8649 - acc: 0.7312 - val_loss: 0.9865 - val_acc: 0.6973\n",
            "Epoch 118/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8632 - acc: 0.7320 - val_loss: 0.9853 - val_acc: 0.6979\n",
            "Epoch 119/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.8617 - acc: 0.7325 - val_loss: 0.9842 - val_acc: 0.6982\n",
            "Epoch 120/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.8603 - acc: 0.7327 - val_loss: 0.9830 - val_acc: 0.6987\n",
            "Epoch 121/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8590 - acc: 0.7330 - val_loss: 0.9822 - val_acc: 0.6993\n",
            "Epoch 122/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8576 - acc: 0.7336 - val_loss: 0.9808 - val_acc: 0.6995\n",
            "Epoch 123/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.8562 - acc: 0.7338 - val_loss: 0.9799 - val_acc: 0.7000\n",
            "Epoch 124/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.8547 - acc: 0.7344 - val_loss: 0.9795 - val_acc: 0.7000\n",
            "Epoch 125/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8533 - acc: 0.7352 - val_loss: 0.9780 - val_acc: 0.7007\n",
            "Epoch 126/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8519 - acc: 0.7354 - val_loss: 0.9769 - val_acc: 0.7008\n",
            "Epoch 127/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.8506 - acc: 0.7357 - val_loss: 0.9767 - val_acc: 0.7008\n",
            "Epoch 128/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.8493 - acc: 0.7365 - val_loss: 0.9754 - val_acc: 0.7017\n",
            "Epoch 129/500\n",
            "8/8 [==============================] - 0s 44ms/step - loss: 0.8479 - acc: 0.7366 - val_loss: 0.9750 - val_acc: 0.7013\n",
            "Epoch 130/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.8467 - acc: 0.7374 - val_loss: 0.9739 - val_acc: 0.7017\n",
            "Epoch 131/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.8454 - acc: 0.7376 - val_loss: 0.9733 - val_acc: 0.7020\n",
            "Epoch 132/500\n",
            "8/8 [==============================] - 0s 38ms/step - loss: 0.8442 - acc: 0.7377 - val_loss: 0.9726 - val_acc: 0.7022\n",
            "Epoch 133/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8429 - acc: 0.7384 - val_loss: 0.9717 - val_acc: 0.7026\n",
            "Epoch 134/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8416 - acc: 0.7390 - val_loss: 0.9707 - val_acc: 0.7028\n",
            "Epoch 135/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8403 - acc: 0.7391 - val_loss: 0.9701 - val_acc: 0.7033\n",
            "Epoch 136/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.8392 - acc: 0.7393 - val_loss: 0.9690 - val_acc: 0.7037\n",
            "Epoch 137/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.8380 - acc: 0.7399 - val_loss: 0.9686 - val_acc: 0.7037\n",
            "Epoch 138/500\n",
            "8/8 [==============================] - 1s 79ms/step - loss: 0.8368 - acc: 0.7400 - val_loss: 0.9679 - val_acc: 0.7043\n",
            "Epoch 139/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8356 - acc: 0.7404 - val_loss: 0.9671 - val_acc: 0.7040\n",
            "Epoch 140/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8344 - acc: 0.7406 - val_loss: 0.9664 - val_acc: 0.7044\n",
            "Epoch 141/500\n",
            "8/8 [==============================] - 1s 77ms/step - loss: 0.8332 - acc: 0.7410 - val_loss: 0.9657 - val_acc: 0.7044\n",
            "Epoch 142/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.8321 - acc: 0.7410 - val_loss: 0.9659 - val_acc: 0.7045\n",
            "Epoch 143/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.8310 - acc: 0.7414 - val_loss: 0.9645 - val_acc: 0.7046\n",
            "Epoch 144/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8299 - acc: 0.7417 - val_loss: 0.9638 - val_acc: 0.7049\n",
            "Epoch 145/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.8287 - acc: 0.7419 - val_loss: 0.9635 - val_acc: 0.7049\n",
            "Epoch 146/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8276 - acc: 0.7418 - val_loss: 0.9634 - val_acc: 0.7049\n",
            "Epoch 147/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8266 - acc: 0.7420 - val_loss: 0.9623 - val_acc: 0.7049\n",
            "Epoch 148/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8256 - acc: 0.7421 - val_loss: 0.9622 - val_acc: 0.7051\n",
            "Epoch 149/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8245 - acc: 0.7425 - val_loss: 0.9617 - val_acc: 0.7045\n",
            "Epoch 150/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8235 - acc: 0.7428 - val_loss: 0.9613 - val_acc: 0.7046\n",
            "Epoch 151/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.8225 - acc: 0.7424 - val_loss: 0.9610 - val_acc: 0.7048\n",
            "Epoch 152/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8215 - acc: 0.7429 - val_loss: 0.9600 - val_acc: 0.7049\n",
            "Epoch 153/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8204 - acc: 0.7432 - val_loss: 0.9596 - val_acc: 0.7050\n",
            "Epoch 154/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8194 - acc: 0.7428 - val_loss: 0.9601 - val_acc: 0.7045\n",
            "Epoch 155/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8184 - acc: 0.7432 - val_loss: 0.9591 - val_acc: 0.7049\n",
            "Epoch 156/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8174 - acc: 0.7433 - val_loss: 0.9584 - val_acc: 0.7046\n",
            "Epoch 157/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8165 - acc: 0.7433 - val_loss: 0.9588 - val_acc: 0.7045\n",
            "Epoch 158/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.8156 - acc: 0.7436 - val_loss: 0.9580 - val_acc: 0.7045\n",
            "Epoch 159/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8146 - acc: 0.7441 - val_loss: 0.9573 - val_acc: 0.7044\n",
            "Epoch 160/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8136 - acc: 0.7437 - val_loss: 0.9571 - val_acc: 0.7042\n",
            "Epoch 161/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8127 - acc: 0.7437 - val_loss: 0.9577 - val_acc: 0.7040\n",
            "Epoch 162/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8118 - acc: 0.7439 - val_loss: 0.9566 - val_acc: 0.7039\n",
            "Epoch 163/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8109 - acc: 0.7440 - val_loss: 0.9563 - val_acc: 0.7043\n",
            "Epoch 164/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8100 - acc: 0.7440 - val_loss: 0.9560 - val_acc: 0.7042\n",
            "Epoch 165/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8092 - acc: 0.7439 - val_loss: 0.9560 - val_acc: 0.7040\n",
            "Epoch 166/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8083 - acc: 0.7443 - val_loss: 0.9557 - val_acc: 0.7043\n",
            "Epoch 167/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8074 - acc: 0.7441 - val_loss: 0.9549 - val_acc: 0.7041\n",
            "Epoch 168/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8065 - acc: 0.7442 - val_loss: 0.9554 - val_acc: 0.7037\n",
            "Epoch 169/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8056 - acc: 0.7443 - val_loss: 0.9546 - val_acc: 0.7041\n",
            "Epoch 170/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8047 - acc: 0.7448 - val_loss: 0.9541 - val_acc: 0.7041\n",
            "Epoch 171/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.8038 - acc: 0.7448 - val_loss: 0.9531 - val_acc: 0.7037\n",
            "Epoch 172/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8030 - acc: 0.7450 - val_loss: 0.9532 - val_acc: 0.7038\n",
            "Epoch 173/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.8023 - acc: 0.7450 - val_loss: 0.9532 - val_acc: 0.7036\n",
            "Epoch 174/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.8015 - acc: 0.7448 - val_loss: 0.9530 - val_acc: 0.7039\n",
            "Epoch 175/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.8006 - acc: 0.7451 - val_loss: 0.9527 - val_acc: 0.7039\n",
            "Epoch 176/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7998 - acc: 0.7453 - val_loss: 0.9515 - val_acc: 0.7041\n",
            "Epoch 177/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7990 - acc: 0.7455 - val_loss: 0.9520 - val_acc: 0.7040\n",
            "Epoch 178/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7982 - acc: 0.7455 - val_loss: 0.9515 - val_acc: 0.7042\n",
            "Epoch 179/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7975 - acc: 0.7452 - val_loss: 0.9509 - val_acc: 0.7042\n",
            "Epoch 180/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7967 - acc: 0.7454 - val_loss: 0.9505 - val_acc: 0.7041\n",
            "Epoch 181/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7958 - acc: 0.7452 - val_loss: 0.9508 - val_acc: 0.7042\n",
            "Epoch 182/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7952 - acc: 0.7459 - val_loss: 0.9503 - val_acc: 0.7040\n",
            "Epoch 183/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.7945 - acc: 0.7456 - val_loss: 0.9503 - val_acc: 0.7038\n",
            "Epoch 184/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7937 - acc: 0.7456 - val_loss: 0.9495 - val_acc: 0.7040\n",
            "Epoch 185/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7929 - acc: 0.7460 - val_loss: 0.9497 - val_acc: 0.7037\n",
            "Epoch 186/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7921 - acc: 0.7462 - val_loss: 0.9494 - val_acc: 0.7035\n",
            "Epoch 187/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7914 - acc: 0.7461 - val_loss: 0.9492 - val_acc: 0.7036\n",
            "Epoch 188/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7906 - acc: 0.7460 - val_loss: 0.9492 - val_acc: 0.7034\n",
            "Epoch 189/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7898 - acc: 0.7462 - val_loss: 0.9489 - val_acc: 0.7036\n",
            "Epoch 190/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7891 - acc: 0.7461 - val_loss: 0.9482 - val_acc: 0.7035\n",
            "Epoch 191/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7884 - acc: 0.7461 - val_loss: 0.9480 - val_acc: 0.7038\n",
            "Epoch 192/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7877 - acc: 0.7461 - val_loss: 0.9483 - val_acc: 0.7034\n",
            "Epoch 193/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.7870 - acc: 0.7463 - val_loss: 0.9483 - val_acc: 0.7039\n",
            "Epoch 194/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7862 - acc: 0.7463 - val_loss: 0.9474 - val_acc: 0.7038\n",
            "Epoch 195/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7855 - acc: 0.7463 - val_loss: 0.9477 - val_acc: 0.7035\n",
            "Epoch 196/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7848 - acc: 0.7467 - val_loss: 0.9471 - val_acc: 0.7034\n",
            "Epoch 197/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7840 - acc: 0.7468 - val_loss: 0.9471 - val_acc: 0.7037\n",
            "Epoch 198/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7833 - acc: 0.7467 - val_loss: 0.9468 - val_acc: 0.7039\n",
            "Epoch 199/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7826 - acc: 0.7468 - val_loss: 0.9464 - val_acc: 0.7037\n",
            "Epoch 200/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.7819 - acc: 0.7471 - val_loss: 0.9463 - val_acc: 0.7038\n",
            "Epoch 201/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7811 - acc: 0.7471 - val_loss: 0.9456 - val_acc: 0.7039\n",
            "Epoch 202/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7805 - acc: 0.7473 - val_loss: 0.9455 - val_acc: 0.7038\n",
            "Epoch 203/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7798 - acc: 0.7472 - val_loss: 0.9458 - val_acc: 0.7041\n",
            "Epoch 204/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7791 - acc: 0.7473 - val_loss: 0.9449 - val_acc: 0.7034\n",
            "Epoch 205/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7784 - acc: 0.7475 - val_loss: 0.9447 - val_acc: 0.7037\n",
            "Epoch 206/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7777 - acc: 0.7473 - val_loss: 0.9453 - val_acc: 0.7036\n",
            "Epoch 207/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7771 - acc: 0.7476 - val_loss: 0.9445 - val_acc: 0.7040\n",
            "Epoch 208/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7763 - acc: 0.7475 - val_loss: 0.9449 - val_acc: 0.7038\n",
            "Epoch 209/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7758 - acc: 0.7472 - val_loss: 0.9441 - val_acc: 0.7040\n",
            "Epoch 210/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7749 - acc: 0.7475 - val_loss: 0.9434 - val_acc: 0.7038\n",
            "Epoch 211/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7742 - acc: 0.7475 - val_loss: 0.9434 - val_acc: 0.7039\n",
            "Epoch 212/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7735 - acc: 0.7476 - val_loss: 0.9435 - val_acc: 0.7040\n",
            "Epoch 213/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7728 - acc: 0.7480 - val_loss: 0.9434 - val_acc: 0.7039\n",
            "Epoch 214/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7721 - acc: 0.7477 - val_loss: 0.9433 - val_acc: 0.7039\n",
            "Epoch 215/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7715 - acc: 0.7478 - val_loss: 0.9428 - val_acc: 0.7041\n",
            "Epoch 216/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7708 - acc: 0.7479 - val_loss: 0.9429 - val_acc: 0.7043\n",
            "Epoch 217/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7703 - acc: 0.7482 - val_loss: 0.9419 - val_acc: 0.7040\n",
            "Epoch 218/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.7697 - acc: 0.7481 - val_loss: 0.9425 - val_acc: 0.7040\n",
            "Epoch 219/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7690 - acc: 0.7480 - val_loss: 0.9426 - val_acc: 0.7041\n",
            "Epoch 220/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7685 - acc: 0.7481 - val_loss: 0.9417 - val_acc: 0.7044\n",
            "Epoch 221/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.7677 - acc: 0.7483 - val_loss: 0.9419 - val_acc: 0.7042\n",
            "Epoch 222/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7671 - acc: 0.7485 - val_loss: 0.9412 - val_acc: 0.7045\n",
            "Epoch 223/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7665 - acc: 0.7483 - val_loss: 0.9411 - val_acc: 0.7046\n",
            "Epoch 224/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7658 - acc: 0.7483 - val_loss: 0.9416 - val_acc: 0.7042\n",
            "Epoch 225/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7652 - acc: 0.7483 - val_loss: 0.9410 - val_acc: 0.7042\n",
            "Epoch 226/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7646 - acc: 0.7484 - val_loss: 0.9404 - val_acc: 0.7041\n",
            "Epoch 227/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7640 - acc: 0.7481 - val_loss: 0.9404 - val_acc: 0.7038\n",
            "Epoch 228/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7634 - acc: 0.7482 - val_loss: 0.9412 - val_acc: 0.7039\n",
            "Epoch 229/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7628 - acc: 0.7483 - val_loss: 0.9403 - val_acc: 0.7038\n",
            "Epoch 230/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7621 - acc: 0.7484 - val_loss: 0.9399 - val_acc: 0.7038\n",
            "Epoch 231/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7616 - acc: 0.7484 - val_loss: 0.9401 - val_acc: 0.7041\n",
            "Epoch 232/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7610 - acc: 0.7486 - val_loss: 0.9398 - val_acc: 0.7040\n",
            "Epoch 233/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7604 - acc: 0.7485 - val_loss: 0.9397 - val_acc: 0.7035\n",
            "Epoch 234/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7598 - acc: 0.7486 - val_loss: 0.9391 - val_acc: 0.7035\n",
            "Epoch 235/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7592 - acc: 0.7488 - val_loss: 0.9394 - val_acc: 0.7037\n",
            "Epoch 236/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7585 - acc: 0.7488 - val_loss: 0.9394 - val_acc: 0.7036\n",
            "Epoch 237/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7579 - acc: 0.7488 - val_loss: 0.9386 - val_acc: 0.7039\n",
            "Epoch 238/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7572 - acc: 0.7491 - val_loss: 0.9391 - val_acc: 0.7035\n",
            "Epoch 239/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7566 - acc: 0.7487 - val_loss: 0.9390 - val_acc: 0.7038\n",
            "Epoch 240/500\n",
            "8/8 [==============================] - 0s 28ms/step - loss: 0.7560 - acc: 0.7491 - val_loss: 0.9385 - val_acc: 0.7038\n",
            "Epoch 241/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7554 - acc: 0.7490 - val_loss: 0.9386 - val_acc: 0.7033\n",
            "Epoch 242/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7548 - acc: 0.7490 - val_loss: 0.9395 - val_acc: 0.7033\n",
            "Epoch 243/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7543 - acc: 0.7489 - val_loss: 0.9381 - val_acc: 0.7038\n",
            "Epoch 244/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.7538 - acc: 0.7491 - val_loss: 0.9383 - val_acc: 0.7033\n",
            "Epoch 245/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7531 - acc: 0.7491 - val_loss: 0.9383 - val_acc: 0.7036\n",
            "Epoch 246/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7526 - acc: 0.7490 - val_loss: 0.9385 - val_acc: 0.7037\n",
            "Epoch 247/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7521 - acc: 0.7492 - val_loss: 0.9381 - val_acc: 0.7034\n",
            "Epoch 248/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7515 - acc: 0.7492 - val_loss: 0.9385 - val_acc: 0.7037\n",
            "Epoch 249/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7508 - acc: 0.7492 - val_loss: 0.9384 - val_acc: 0.7032\n",
            "Epoch 250/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7502 - acc: 0.7495 - val_loss: 0.9376 - val_acc: 0.7035\n",
            "Epoch 251/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7497 - acc: 0.7495 - val_loss: 0.9370 - val_acc: 0.7037\n",
            "Epoch 252/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7491 - acc: 0.7496 - val_loss: 0.9373 - val_acc: 0.7034\n",
            "Epoch 253/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7484 - acc: 0.7496 - val_loss: 0.9369 - val_acc: 0.7031\n",
            "Epoch 254/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7478 - acc: 0.7499 - val_loss: 0.9367 - val_acc: 0.7033\n",
            "Epoch 255/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7472 - acc: 0.7498 - val_loss: 0.9366 - val_acc: 0.7036\n",
            "Epoch 256/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7467 - acc: 0.7496 - val_loss: 0.9369 - val_acc: 0.7035\n",
            "Epoch 257/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7461 - acc: 0.7498 - val_loss: 0.9368 - val_acc: 0.7033\n",
            "Epoch 258/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7456 - acc: 0.7499 - val_loss: 0.9361 - val_acc: 0.7036\n",
            "Epoch 259/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7450 - acc: 0.7497 - val_loss: 0.9364 - val_acc: 0.7030\n",
            "Epoch 260/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7444 - acc: 0.7498 - val_loss: 0.9361 - val_acc: 0.7028\n",
            "Epoch 261/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7439 - acc: 0.7499 - val_loss: 0.9354 - val_acc: 0.7032\n",
            "Epoch 262/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7433 - acc: 0.7499 - val_loss: 0.9362 - val_acc: 0.7032\n",
            "Epoch 263/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7429 - acc: 0.7498 - val_loss: 0.9361 - val_acc: 0.7031\n",
            "Epoch 264/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.7422 - acc: 0.7498 - val_loss: 0.9359 - val_acc: 0.7028\n",
            "Epoch 265/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7417 - acc: 0.7497 - val_loss: 0.9356 - val_acc: 0.7028\n",
            "Epoch 266/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7411 - acc: 0.7498 - val_loss: 0.9354 - val_acc: 0.7030\n",
            "Epoch 267/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7405 - acc: 0.7498 - val_loss: 0.9354 - val_acc: 0.7029\n",
            "Epoch 268/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7399 - acc: 0.7498 - val_loss: 0.9347 - val_acc: 0.7025\n",
            "Epoch 269/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7395 - acc: 0.7500 - val_loss: 0.9346 - val_acc: 0.7026\n",
            "Epoch 270/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7389 - acc: 0.7500 - val_loss: 0.9353 - val_acc: 0.7025\n",
            "Epoch 271/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7383 - acc: 0.7498 - val_loss: 0.9350 - val_acc: 0.7023\n",
            "Epoch 272/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7378 - acc: 0.7499 - val_loss: 0.9347 - val_acc: 0.7027\n",
            "Epoch 273/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7372 - acc: 0.7502 - val_loss: 0.9347 - val_acc: 0.7025\n",
            "Epoch 274/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7366 - acc: 0.7500 - val_loss: 0.9344 - val_acc: 0.7027\n",
            "Epoch 275/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7359 - acc: 0.7500 - val_loss: 0.9343 - val_acc: 0.7022\n",
            "Epoch 276/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7353 - acc: 0.7501 - val_loss: 0.9343 - val_acc: 0.7023\n",
            "Epoch 277/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7348 - acc: 0.7501 - val_loss: 0.9333 - val_acc: 0.7020\n",
            "Epoch 278/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7342 - acc: 0.7502 - val_loss: 0.9338 - val_acc: 0.7022\n",
            "Epoch 279/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7336 - acc: 0.7501 - val_loss: 0.9341 - val_acc: 0.7021\n",
            "Epoch 280/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7330 - acc: 0.7503 - val_loss: 0.9329 - val_acc: 0.7021\n",
            "Epoch 281/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7325 - acc: 0.7504 - val_loss: 0.9336 - val_acc: 0.7020\n",
            "Epoch 282/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7319 - acc: 0.7502 - val_loss: 0.9328 - val_acc: 0.7020\n",
            "Epoch 283/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7314 - acc: 0.7503 - val_loss: 0.9323 - val_acc: 0.7018\n",
            "Epoch 284/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.7309 - acc: 0.7504 - val_loss: 0.9325 - val_acc: 0.7019\n",
            "Epoch 285/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7303 - acc: 0.7505 - val_loss: 0.9319 - val_acc: 0.7020\n",
            "Epoch 286/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7299 - acc: 0.7506 - val_loss: 0.9324 - val_acc: 0.7020\n",
            "Epoch 287/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7292 - acc: 0.7505 - val_loss: 0.9317 - val_acc: 0.7021\n",
            "Epoch 288/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7285 - acc: 0.7505 - val_loss: 0.9314 - val_acc: 0.7017\n",
            "Epoch 289/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7280 - acc: 0.7505 - val_loss: 0.9314 - val_acc: 0.7013\n",
            "Epoch 290/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7274 - acc: 0.7507 - val_loss: 0.9304 - val_acc: 0.7020\n",
            "Epoch 291/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7269 - acc: 0.7507 - val_loss: 0.9302 - val_acc: 0.7016\n",
            "Epoch 292/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7262 - acc: 0.7509 - val_loss: 0.9310 - val_acc: 0.7014\n",
            "Epoch 293/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7257 - acc: 0.7509 - val_loss: 0.9301 - val_acc: 0.7018\n",
            "Epoch 294/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.7251 - acc: 0.7508 - val_loss: 0.9296 - val_acc: 0.7016\n",
            "Epoch 295/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7244 - acc: 0.7508 - val_loss: 0.9290 - val_acc: 0.7016\n",
            "Epoch 296/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7239 - acc: 0.7509 - val_loss: 0.9289 - val_acc: 0.7012\n",
            "Epoch 297/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7233 - acc: 0.7510 - val_loss: 0.9290 - val_acc: 0.7012\n",
            "Epoch 298/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7226 - acc: 0.7509 - val_loss: 0.9285 - val_acc: 0.7016\n",
            "Epoch 299/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7220 - acc: 0.7510 - val_loss: 0.9283 - val_acc: 0.7011\n",
            "Epoch 300/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7214 - acc: 0.7510 - val_loss: 0.9281 - val_acc: 0.7016\n",
            "Epoch 301/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7208 - acc: 0.7511 - val_loss: 0.9276 - val_acc: 0.7010\n",
            "Epoch 302/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7202 - acc: 0.7510 - val_loss: 0.9273 - val_acc: 0.7010\n",
            "Epoch 303/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7196 - acc: 0.7512 - val_loss: 0.9266 - val_acc: 0.7010\n",
            "Epoch 304/500\n",
            "8/8 [==============================] - 0s 39ms/step - loss: 0.7190 - acc: 0.7511 - val_loss: 0.9269 - val_acc: 0.7008\n",
            "Epoch 305/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7184 - acc: 0.7513 - val_loss: 0.9265 - val_acc: 0.7007\n",
            "Epoch 306/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.7177 - acc: 0.7514 - val_loss: 0.9262 - val_acc: 0.7006\n",
            "Epoch 307/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7170 - acc: 0.7513 - val_loss: 0.9252 - val_acc: 0.7006\n",
            "Epoch 308/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7164 - acc: 0.7514 - val_loss: 0.9249 - val_acc: 0.7009\n",
            "Epoch 309/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7158 - acc: 0.7512 - val_loss: 0.9245 - val_acc: 0.7007\n",
            "Epoch 310/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7151 - acc: 0.7514 - val_loss: 0.9241 - val_acc: 0.7002\n",
            "Epoch 311/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7144 - acc: 0.7513 - val_loss: 0.9240 - val_acc: 0.7006\n",
            "Epoch 312/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7138 - acc: 0.7516 - val_loss: 0.9230 - val_acc: 0.7001\n",
            "Epoch 313/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7131 - acc: 0.7518 - val_loss: 0.9230 - val_acc: 0.6999\n",
            "Epoch 314/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.7125 - acc: 0.7515 - val_loss: 0.9225 - val_acc: 0.7001\n",
            "Epoch 315/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7117 - acc: 0.7517 - val_loss: 0.9225 - val_acc: 0.6996\n",
            "Epoch 316/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7110 - acc: 0.7517 - val_loss: 0.9217 - val_acc: 0.7001\n",
            "Epoch 317/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7104 - acc: 0.7517 - val_loss: 0.9213 - val_acc: 0.7003\n",
            "Epoch 318/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.7096 - acc: 0.7518 - val_loss: 0.9211 - val_acc: 0.6994\n",
            "Epoch 319/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7089 - acc: 0.7519 - val_loss: 0.9200 - val_acc: 0.6999\n",
            "Epoch 320/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7082 - acc: 0.7523 - val_loss: 0.9199 - val_acc: 0.7001\n",
            "Epoch 321/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7075 - acc: 0.7524 - val_loss: 0.9199 - val_acc: 0.6997\n",
            "Epoch 322/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7067 - acc: 0.7524 - val_loss: 0.9194 - val_acc: 0.6995\n",
            "Epoch 323/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7061 - acc: 0.7524 - val_loss: 0.9183 - val_acc: 0.6995\n",
            "Epoch 324/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.7052 - acc: 0.7525 - val_loss: 0.9181 - val_acc: 0.6995\n",
            "Epoch 325/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7044 - acc: 0.7522 - val_loss: 0.9175 - val_acc: 0.6995\n",
            "Epoch 326/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7037 - acc: 0.7527 - val_loss: 0.9180 - val_acc: 0.6992\n",
            "Epoch 327/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.7030 - acc: 0.7529 - val_loss: 0.9166 - val_acc: 0.6999\n",
            "Epoch 328/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.7022 - acc: 0.7529 - val_loss: 0.9166 - val_acc: 0.6994\n",
            "Epoch 329/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7015 - acc: 0.7533 - val_loss: 0.9156 - val_acc: 0.6995\n",
            "Epoch 330/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.7008 - acc: 0.7530 - val_loss: 0.9148 - val_acc: 0.6990\n",
            "Epoch 331/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.7000 - acc: 0.7532 - val_loss: 0.9139 - val_acc: 0.6997\n",
            "Epoch 332/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6993 - acc: 0.7531 - val_loss: 0.9140 - val_acc: 0.6998\n",
            "Epoch 333/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6986 - acc: 0.7538 - val_loss: 0.9135 - val_acc: 0.6989\n",
            "Epoch 334/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6978 - acc: 0.7536 - val_loss: 0.9125 - val_acc: 0.6991\n",
            "Epoch 335/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.6969 - acc: 0.7535 - val_loss: 0.9118 - val_acc: 0.6995\n",
            "Epoch 336/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6959 - acc: 0.7535 - val_loss: 0.9115 - val_acc: 0.6995\n",
            "Epoch 337/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6952 - acc: 0.7540 - val_loss: 0.9104 - val_acc: 0.6993\n",
            "Epoch 338/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6943 - acc: 0.7536 - val_loss: 0.9107 - val_acc: 0.6995\n",
            "Epoch 339/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6934 - acc: 0.7540 - val_loss: 0.9086 - val_acc: 0.6994\n",
            "Epoch 340/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6924 - acc: 0.7538 - val_loss: 0.9081 - val_acc: 0.7000\n",
            "Epoch 341/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6915 - acc: 0.7544 - val_loss: 0.9071 - val_acc: 0.6997\n",
            "Epoch 342/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6904 - acc: 0.7548 - val_loss: 0.9070 - val_acc: 0.6994\n",
            "Epoch 343/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6894 - acc: 0.7542 - val_loss: 0.9065 - val_acc: 0.6995\n",
            "Epoch 344/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6885 - acc: 0.7547 - val_loss: 0.9058 - val_acc: 0.6992\n",
            "Epoch 345/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.6877 - acc: 0.7546 - val_loss: 0.9057 - val_acc: 0.6996\n",
            "Epoch 346/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6868 - acc: 0.7550 - val_loss: 0.9050 - val_acc: 0.6990\n",
            "Epoch 347/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6858 - acc: 0.7553 - val_loss: 0.9046 - val_acc: 0.6986\n",
            "Epoch 348/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6850 - acc: 0.7547 - val_loss: 0.9035 - val_acc: 0.6987\n",
            "Epoch 349/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6840 - acc: 0.7551 - val_loss: 0.9028 - val_acc: 0.6990\n",
            "Epoch 350/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6833 - acc: 0.7553 - val_loss: 0.9022 - val_acc: 0.6986\n",
            "Epoch 351/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6822 - acc: 0.7555 - val_loss: 0.9017 - val_acc: 0.6995\n",
            "Epoch 352/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6814 - acc: 0.7555 - val_loss: 0.9007 - val_acc: 0.6990\n",
            "Epoch 353/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6805 - acc: 0.7558 - val_loss: 0.9004 - val_acc: 0.6990\n",
            "Epoch 354/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6795 - acc: 0.7562 - val_loss: 0.8999 - val_acc: 0.6989\n",
            "Epoch 355/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6787 - acc: 0.7563 - val_loss: 0.8993 - val_acc: 0.6990\n",
            "Epoch 356/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6778 - acc: 0.7558 - val_loss: 0.8991 - val_acc: 0.6994\n",
            "Epoch 357/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6767 - acc: 0.7563 - val_loss: 0.8976 - val_acc: 0.6990\n",
            "Epoch 358/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6757 - acc: 0.7560 - val_loss: 0.8980 - val_acc: 0.6988\n",
            "Epoch 359/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6749 - acc: 0.7564 - val_loss: 0.8967 - val_acc: 0.6990\n",
            "Epoch 360/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6740 - acc: 0.7565 - val_loss: 0.8965 - val_acc: 0.6985\n",
            "Epoch 361/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6730 - acc: 0.7567 - val_loss: 0.8965 - val_acc: 0.6981\n",
            "Epoch 362/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6724 - acc: 0.7566 - val_loss: 0.8947 - val_acc: 0.6995\n",
            "Epoch 363/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6716 - acc: 0.7572 - val_loss: 0.8947 - val_acc: 0.7008\n",
            "Epoch 364/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6707 - acc: 0.7605 - val_loss: 0.8944 - val_acc: 0.7032\n",
            "Epoch 365/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.6695 - acc: 0.7636 - val_loss: 0.8940 - val_acc: 0.7056\n",
            "Epoch 366/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6687 - acc: 0.7653 - val_loss: 0.8936 - val_acc: 0.7064\n",
            "Epoch 367/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6678 - acc: 0.7671 - val_loss: 0.8927 - val_acc: 0.7075\n",
            "Epoch 368/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6668 - acc: 0.7682 - val_loss: 0.8926 - val_acc: 0.7084\n",
            "Epoch 369/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6660 - acc: 0.7694 - val_loss: 0.8922 - val_acc: 0.7095\n",
            "Epoch 370/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6651 - acc: 0.7705 - val_loss: 0.8911 - val_acc: 0.7091\n",
            "Epoch 371/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6644 - acc: 0.7717 - val_loss: 0.8908 - val_acc: 0.7102\n",
            "Epoch 372/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6636 - acc: 0.7726 - val_loss: 0.8906 - val_acc: 0.7113\n",
            "Epoch 373/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6627 - acc: 0.7735 - val_loss: 0.8896 - val_acc: 0.7119\n",
            "Epoch 374/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6618 - acc: 0.7742 - val_loss: 0.8891 - val_acc: 0.7119\n",
            "Epoch 375/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6608 - acc: 0.7746 - val_loss: 0.8894 - val_acc: 0.7117\n",
            "Epoch 376/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6599 - acc: 0.7754 - val_loss: 0.8889 - val_acc: 0.7121\n",
            "Epoch 377/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6591 - acc: 0.7761 - val_loss: 0.8886 - val_acc: 0.7126\n",
            "Epoch 378/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6583 - acc: 0.7765 - val_loss: 0.8882 - val_acc: 0.7127\n",
            "Epoch 379/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6574 - acc: 0.7768 - val_loss: 0.8874 - val_acc: 0.7138\n",
            "Epoch 380/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6566 - acc: 0.7782 - val_loss: 0.8875 - val_acc: 0.7134\n",
            "Epoch 381/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6560 - acc: 0.7779 - val_loss: 0.8871 - val_acc: 0.7133\n",
            "Epoch 382/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6551 - acc: 0.7785 - val_loss: 0.8869 - val_acc: 0.7124\n",
            "Epoch 383/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6544 - acc: 0.7789 - val_loss: 0.8862 - val_acc: 0.7143\n",
            "Epoch 384/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6536 - acc: 0.7798 - val_loss: 0.8854 - val_acc: 0.7143\n",
            "Epoch 385/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6527 - acc: 0.7800 - val_loss: 0.8855 - val_acc: 0.7140\n",
            "Epoch 386/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6519 - acc: 0.7799 - val_loss: 0.8857 - val_acc: 0.7146\n",
            "Epoch 387/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6511 - acc: 0.7808 - val_loss: 0.8852 - val_acc: 0.7141\n",
            "Epoch 388/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6503 - acc: 0.7810 - val_loss: 0.8845 - val_acc: 0.7148\n",
            "Epoch 389/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6494 - acc: 0.7814 - val_loss: 0.8844 - val_acc: 0.7152\n",
            "Epoch 390/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6486 - acc: 0.7821 - val_loss: 0.8843 - val_acc: 0.7151\n",
            "Epoch 391/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6479 - acc: 0.7824 - val_loss: 0.8838 - val_acc: 0.7147\n",
            "Epoch 392/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6471 - acc: 0.7820 - val_loss: 0.8836 - val_acc: 0.7150\n",
            "Epoch 393/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6464 - acc: 0.7831 - val_loss: 0.8835 - val_acc: 0.7161\n",
            "Epoch 394/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6457 - acc: 0.7836 - val_loss: 0.8827 - val_acc: 0.7154\n",
            "Epoch 395/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6449 - acc: 0.7832 - val_loss: 0.8834 - val_acc: 0.7154\n",
            "Epoch 396/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6441 - acc: 0.7840 - val_loss: 0.8821 - val_acc: 0.7159\n",
            "Epoch 397/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6434 - acc: 0.7837 - val_loss: 0.8823 - val_acc: 0.7149\n",
            "Epoch 398/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6427 - acc: 0.7844 - val_loss: 0.8819 - val_acc: 0.7157\n",
            "Epoch 399/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6420 - acc: 0.7844 - val_loss: 0.8815 - val_acc: 0.7163\n",
            "Epoch 400/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6415 - acc: 0.7852 - val_loss: 0.8820 - val_acc: 0.7147\n",
            "Epoch 401/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6408 - acc: 0.7850 - val_loss: 0.8815 - val_acc: 0.7153\n",
            "Epoch 402/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6400 - acc: 0.7851 - val_loss: 0.8810 - val_acc: 0.7158\n",
            "Epoch 403/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6392 - acc: 0.7856 - val_loss: 0.8812 - val_acc: 0.7170\n",
            "Epoch 404/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6386 - acc: 0.7860 - val_loss: 0.8803 - val_acc: 0.7155\n",
            "Epoch 405/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.6377 - acc: 0.7860 - val_loss: 0.8810 - val_acc: 0.7157\n",
            "Epoch 406/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6372 - acc: 0.7862 - val_loss: 0.8804 - val_acc: 0.7148\n",
            "Epoch 407/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6365 - acc: 0.7869 - val_loss: 0.8811 - val_acc: 0.7156\n",
            "Epoch 408/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6365 - acc: 0.7865 - val_loss: 0.8798 - val_acc: 0.7164\n",
            "Epoch 409/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6354 - acc: 0.7870 - val_loss: 0.8793 - val_acc: 0.7164\n",
            "Epoch 410/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6345 - acc: 0.7880 - val_loss: 0.8795 - val_acc: 0.7170\n",
            "Epoch 411/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6337 - acc: 0.7874 - val_loss: 0.8791 - val_acc: 0.7168\n",
            "Epoch 412/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6329 - acc: 0.7882 - val_loss: 0.8789 - val_acc: 0.7159\n",
            "Epoch 413/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6325 - acc: 0.7882 - val_loss: 0.8785 - val_acc: 0.7170\n",
            "Epoch 414/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6318 - acc: 0.7883 - val_loss: 0.8789 - val_acc: 0.7169\n",
            "Epoch 415/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6310 - acc: 0.7884 - val_loss: 0.8790 - val_acc: 0.7172\n",
            "Epoch 416/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6302 - acc: 0.7888 - val_loss: 0.8781 - val_acc: 0.7168\n",
            "Epoch 417/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6295 - acc: 0.7887 - val_loss: 0.8785 - val_acc: 0.7178\n",
            "Epoch 418/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6289 - acc: 0.7893 - val_loss: 0.8782 - val_acc: 0.7168\n",
            "Epoch 419/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6282 - acc: 0.7895 - val_loss: 0.8777 - val_acc: 0.7163\n",
            "Epoch 420/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6276 - acc: 0.7894 - val_loss: 0.8783 - val_acc: 0.7163\n",
            "Epoch 421/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6270 - acc: 0.7899 - val_loss: 0.8773 - val_acc: 0.7160\n",
            "Epoch 422/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6261 - acc: 0.7902 - val_loss: 0.8777 - val_acc: 0.7170\n",
            "Epoch 423/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6256 - acc: 0.7905 - val_loss: 0.8778 - val_acc: 0.7154\n",
            "Epoch 424/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6250 - acc: 0.7912 - val_loss: 0.8774 - val_acc: 0.7164\n",
            "Epoch 425/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6243 - acc: 0.7907 - val_loss: 0.8770 - val_acc: 0.7165\n",
            "Epoch 426/500\n",
            "8/8 [==============================] - 0s 41ms/step - loss: 0.6237 - acc: 0.7907 - val_loss: 0.8775 - val_acc: 0.7162\n",
            "Epoch 427/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6229 - acc: 0.7915 - val_loss: 0.8769 - val_acc: 0.7177\n",
            "Epoch 428/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6223 - acc: 0.7916 - val_loss: 0.8768 - val_acc: 0.7169\n",
            "Epoch 429/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6217 - acc: 0.7912 - val_loss: 0.8767 - val_acc: 0.7169\n",
            "Epoch 430/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6211 - acc: 0.7917 - val_loss: 0.8766 - val_acc: 0.7170\n",
            "Epoch 431/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6205 - acc: 0.7919 - val_loss: 0.8762 - val_acc: 0.7167\n",
            "Epoch 432/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6199 - acc: 0.7922 - val_loss: 0.8762 - val_acc: 0.7171\n",
            "Epoch 433/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6192 - acc: 0.7922 - val_loss: 0.8761 - val_acc: 0.7179\n",
            "Epoch 434/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6187 - acc: 0.7923 - val_loss: 0.8762 - val_acc: 0.7174\n",
            "Epoch 435/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6181 - acc: 0.7928 - val_loss: 0.8758 - val_acc: 0.7174\n",
            "Epoch 436/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6174 - acc: 0.7921 - val_loss: 0.8759 - val_acc: 0.7176\n",
            "Epoch 437/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6168 - acc: 0.7933 - val_loss: 0.8760 - val_acc: 0.7172\n",
            "Epoch 438/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6161 - acc: 0.7935 - val_loss: 0.8762 - val_acc: 0.7168\n",
            "Epoch 439/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6156 - acc: 0.7934 - val_loss: 0.8758 - val_acc: 0.7165\n",
            "Epoch 440/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6151 - acc: 0.7934 - val_loss: 0.8755 - val_acc: 0.7173\n",
            "Epoch 441/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.6144 - acc: 0.7939 - val_loss: 0.8758 - val_acc: 0.7176\n",
            "Epoch 442/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6139 - acc: 0.7936 - val_loss: 0.8756 - val_acc: 0.7175\n",
            "Epoch 443/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6135 - acc: 0.7939 - val_loss: 0.8762 - val_acc: 0.7165\n",
            "Epoch 444/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6129 - acc: 0.7939 - val_loss: 0.8755 - val_acc: 0.7164\n",
            "Epoch 445/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.6123 - acc: 0.7942 - val_loss: 0.8752 - val_acc: 0.7170\n",
            "Epoch 446/500\n",
            "8/8 [==============================] - 0s 43ms/step - loss: 0.6117 - acc: 0.7941 - val_loss: 0.8754 - val_acc: 0.7175\n",
            "Epoch 447/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6110 - acc: 0.7947 - val_loss: 0.8758 - val_acc: 0.7172\n",
            "Epoch 448/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6105 - acc: 0.7945 - val_loss: 0.8753 - val_acc: 0.7171\n",
            "Epoch 449/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6100 - acc: 0.7948 - val_loss: 0.8755 - val_acc: 0.7177\n",
            "Epoch 450/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6093 - acc: 0.7951 - val_loss: 0.8749 - val_acc: 0.7175\n",
            "Epoch 451/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6088 - acc: 0.7950 - val_loss: 0.8754 - val_acc: 0.7177\n",
            "Epoch 452/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6082 - acc: 0.7953 - val_loss: 0.8753 - val_acc: 0.7174\n",
            "Epoch 453/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6077 - acc: 0.7954 - val_loss: 0.8754 - val_acc: 0.7176\n",
            "Epoch 454/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6072 - acc: 0.7955 - val_loss: 0.8758 - val_acc: 0.7172\n",
            "Epoch 455/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6067 - acc: 0.7956 - val_loss: 0.8753 - val_acc: 0.7175\n",
            "Epoch 456/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6060 - acc: 0.7957 - val_loss: 0.8751 - val_acc: 0.7175\n",
            "Epoch 457/500\n",
            "8/8 [==============================] - 0s 36ms/step - loss: 0.6055 - acc: 0.7958 - val_loss: 0.8755 - val_acc: 0.7177\n",
            "Epoch 458/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.6050 - acc: 0.7958 - val_loss: 0.8753 - val_acc: 0.7173\n",
            "Epoch 459/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6045 - acc: 0.7958 - val_loss: 0.8755 - val_acc: 0.7176\n",
            "Epoch 460/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6039 - acc: 0.7960 - val_loss: 0.8757 - val_acc: 0.7178\n",
            "Epoch 461/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6035 - acc: 0.7960 - val_loss: 0.8757 - val_acc: 0.7176\n",
            "Epoch 462/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.6029 - acc: 0.7962 - val_loss: 0.8758 - val_acc: 0.7175\n",
            "Epoch 463/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6024 - acc: 0.7960 - val_loss: 0.8756 - val_acc: 0.7181\n",
            "Epoch 464/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.6019 - acc: 0.7966 - val_loss: 0.8750 - val_acc: 0.7174\n",
            "Epoch 465/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.6014 - acc: 0.7965 - val_loss: 0.8756 - val_acc: 0.7176\n",
            "Epoch 466/500\n",
            "8/8 [==============================] - 0s 42ms/step - loss: 0.6009 - acc: 0.7969 - val_loss: 0.8755 - val_acc: 0.7174\n",
            "Epoch 467/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6004 - acc: 0.7968 - val_loss: 0.8756 - val_acc: 0.7171\n",
            "Epoch 468/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.6000 - acc: 0.7970 - val_loss: 0.8760 - val_acc: 0.7170\n",
            "Epoch 469/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5994 - acc: 0.7970 - val_loss: 0.8756 - val_acc: 0.7174\n",
            "Epoch 470/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5989 - acc: 0.7972 - val_loss: 0.8755 - val_acc: 0.7179\n",
            "Epoch 471/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5985 - acc: 0.7973 - val_loss: 0.8760 - val_acc: 0.7174\n",
            "Epoch 472/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5980 - acc: 0.7975 - val_loss: 0.8760 - val_acc: 0.7178\n",
            "Epoch 473/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5975 - acc: 0.7977 - val_loss: 0.8762 - val_acc: 0.7175\n",
            "Epoch 474/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5970 - acc: 0.7975 - val_loss: 0.8759 - val_acc: 0.7174\n",
            "Epoch 475/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5966 - acc: 0.7976 - val_loss: 0.8758 - val_acc: 0.7174\n",
            "Epoch 476/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5961 - acc: 0.7973 - val_loss: 0.8758 - val_acc: 0.7175\n",
            "Epoch 477/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5955 - acc: 0.7978 - val_loss: 0.8761 - val_acc: 0.7172\n",
            "Epoch 478/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5950 - acc: 0.7977 - val_loss: 0.8766 - val_acc: 0.7174\n",
            "Epoch 479/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5945 - acc: 0.7980 - val_loss: 0.8766 - val_acc: 0.7173\n",
            "Epoch 480/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5942 - acc: 0.7977 - val_loss: 0.8762 - val_acc: 0.7167\n",
            "Epoch 481/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5938 - acc: 0.7979 - val_loss: 0.8768 - val_acc: 0.7176\n",
            "Epoch 482/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5933 - acc: 0.7981 - val_loss: 0.8768 - val_acc: 0.7171\n",
            "Epoch 483/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5927 - acc: 0.7985 - val_loss: 0.8770 - val_acc: 0.7171\n",
            "Epoch 484/500\n",
            "8/8 [==============================] - 0s 29ms/step - loss: 0.5922 - acc: 0.7984 - val_loss: 0.8763 - val_acc: 0.7171\n",
            "Epoch 485/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5917 - acc: 0.7985 - val_loss: 0.8773 - val_acc: 0.7172\n",
            "Epoch 486/500\n",
            "8/8 [==============================] - 0s 40ms/step - loss: 0.5911 - acc: 0.7987 - val_loss: 0.8779 - val_acc: 0.7172\n",
            "Epoch 487/500\n",
            "8/8 [==============================] - 0s 33ms/step - loss: 0.5907 - acc: 0.7987 - val_loss: 0.8776 - val_acc: 0.7172\n",
            "Epoch 488/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5902 - acc: 0.7987 - val_loss: 0.8773 - val_acc: 0.7167\n",
            "Epoch 489/500\n",
            "8/8 [==============================] - 0s 34ms/step - loss: 0.5899 - acc: 0.7989 - val_loss: 0.8776 - val_acc: 0.7171\n",
            "Epoch 490/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5894 - acc: 0.7987 - val_loss: 0.8775 - val_acc: 0.7169\n",
            "Epoch 491/500\n",
            "8/8 [==============================] - 0s 30ms/step - loss: 0.5890 - acc: 0.7987 - val_loss: 0.8784 - val_acc: 0.7169\n",
            "Epoch 492/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5886 - acc: 0.7987 - val_loss: 0.8773 - val_acc: 0.7165\n",
            "Epoch 493/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5881 - acc: 0.7991 - val_loss: 0.8779 - val_acc: 0.7174\n",
            "Epoch 494/500\n",
            "8/8 [==============================] - 0s 35ms/step - loss: 0.5876 - acc: 0.7989 - val_loss: 0.8780 - val_acc: 0.7167\n",
            "Epoch 495/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5871 - acc: 0.7993 - val_loss: 0.8779 - val_acc: 0.7171\n",
            "Epoch 496/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5867 - acc: 0.7994 - val_loss: 0.8782 - val_acc: 0.7169\n",
            "Epoch 497/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5864 - acc: 0.7992 - val_loss: 0.8779 - val_acc: 0.7171\n",
            "Epoch 498/500\n",
            "8/8 [==============================] - 0s 31ms/step - loss: 0.5859 - acc: 0.7989 - val_loss: 0.8788 - val_acc: 0.7170\n",
            "Epoch 499/500\n",
            "8/8 [==============================] - 0s 32ms/step - loss: 0.5854 - acc: 0.7995 - val_loss: 0.8783 - val_acc: 0.7171\n",
            "Epoch 500/500\n",
            "8/8 [==============================] - 0s 37ms/step - loss: 0.5849 - acc: 0.7997 - val_loss: 0.8785 - val_acc: 0.7171\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "from models import additionalDense\n",
        "\n",
        "optimizer = Adam(learning_rate=1e-3)\n",
        "\n",
        "checkpoint_path = os.path.join(weights_folder, \"additionalDense\", \"checkpoint.hdf5\")\n",
        "history_path = os.path.join(weights_folder, \"additionalDense\", \"history.npy\")\n",
        "\n",
        "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
        "hist_callback = MyHistory(history_path)\n",
        "\n",
        "model = additionalDense(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "model.compile(**compile_args, optimizer=optimizer)\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    model.load_weights(checkpoint_path)\n",
        "\n",
        "history = model.fit(x=x_train_pad,\n",
        "                    y=y_train_pad,\n",
        "                    batch_size=256,\n",
        "                    epochs=500,\n",
        "                    validation_data=(x_val_pad,\n",
        "                                     y_val_pad),\n",
        "                    callbacks=[checkpoint_callback, hist_callback])\n",
        "\n",
        "plot_history(history)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RzV6e3URgIpP"
      },
      "source": [
        "# Performance Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "yzMznPYxgIpP"
      },
      "outputs": [],
      "source": [
        "def flatten_data(list_of_lists):\n",
        "    return [element for sequence in list_of_lists for element in sequence[:padding_length]]\n",
        "\n",
        "def remove_punctuation(y, y_true=None):\n",
        "    if y_true is None:\n",
        "        y_true = y\n",
        "    return [tag for tag, true_tag in zip(y, y_true) if true_tag not in punctuation_tags]\n",
        "\n",
        "x_train_flattened = flatten_data(x_train)\n",
        "x_val_flattened = flatten_data(x_val)\n",
        "x_test_flattened = flatten_data(x_test)\n",
        "\n",
        "y_train_flattened = flatten_data(y_train)\n",
        "y_val_flattened = flatten_data(y_val)\n",
        "y_test_flattened = flatten_data(y_test)\n",
        "\n",
        "y_train_cleaned = remove_punctuation(y_train_flattened)\n",
        "y_val_cleaned = remove_punctuation(y_val_flattened)\n",
        "y_test_cleaned = remove_punctuation(y_test_flattened)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MByAoUW2gIpP"
      },
      "source": [
        "## Dummy Classifiers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "rZ4iAAn9gIpP"
      },
      "outputs": [],
      "source": [
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9ISyU58xgIpQ"
      },
      "outputs": [],
      "source": [
        "majority_classifier = DummyClassifier(strategy=\"prior\")\n",
        "stratified_classifier = DummyClassifier(strategy=\"stratified\")\n",
        "\n",
        "majority_classifier.fit(x_train_flattened, y_train_flattened);\n",
        "stratified_classifier.fit(x_train_flattened, y_train_flattened);"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDEOcuu5gIpR"
      },
      "source": [
        "## Trained models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Qa81q9VfgIpR"
      },
      "outputs": [],
      "source": [
        "def unpad_result(y_padded, y_true):\n",
        "    return [y[:len(yt)] for y, yt in zip(y_padded, y_true)]\n",
        "\n",
        "def get_model_prediction(model, x, y_true):\n",
        "    output = model.predict(x)\n",
        "    y_pred_model = tag_vocabulary[np.argmax(output, axis=-1)]\n",
        "    y_pred_unpadded = unpad_result(y_pred_model, y_true)\n",
        "    return flatten_data(y_pred_unpadded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "kvXR5AHvgIpS"
      },
      "outputs": [],
      "source": [
        "from models import baselineLSTM, GRUModel, additionalLSTM, additionalDense\n",
        "\n",
        "baseline = baselineLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "baseline.load_weights(os.path.join(weights_folder, \"baseline\", \"checkpoint.hdf5\"))\n",
        "\n",
        "gru = GRUModel(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "gru.load_weights(os.path.join(weights_folder, \"gru\", \"checkpoint.hdf5\"))\n",
        "\n",
        "additional_LSTM = additionalLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "additional_LSTM.load_weights(os.path.join(weights_folder, \"additionalLSTM\", \"checkpoint.hdf5\"))\n",
        "\n",
        "additional_dense = additionalDense(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
        "additional_dense.load_weights(os.path.join(weights_folder, \"additionalDense\", \"checkpoint.hdf5\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LL36bBB7gIpS"
      },
      "source": [
        "## Build dictionary with prediction info\n",
        "fill in this dictionary to get all the statistics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "4ASy9u50gIpS"
      },
      "outputs": [],
      "source": [
        "model_prediction_train = partial(get_model_prediction, x=x_train_pad, y_true=y_train)\n",
        "model_prediction_val = partial(get_model_prediction, x=x_val_pad, y_true=y_val)\n",
        "model_prediction_test = partial(get_model_prediction, x=x_test_pad, y_true=y_test)\n",
        "\n",
        "remove_punctuation_train = partial(remove_punctuation, y_true=y_train_flattened)\n",
        "remove_punctuation_val = partial(remove_punctuation, y_true=y_val_flattened)\n",
        "remove_punctuation_test = partial(remove_punctuation, y_true=y_test_flattened)\n",
        "\n",
        "prediction_data = [{\n",
        "    'model_label': 'maj',\n",
        "    'y_pred_train': remove_punctuation_train(majority_classifier.predict(x_train_flattened)),\n",
        "    'y_pred_val': remove_punctuation_val(majority_classifier.predict(x_val_flattened)),\n",
        "    'y_pred_test': remove_punctuation_test(majority_classifier.predict(x_test_flattened))\n",
        "    }, {\n",
        "    'model_label': 'stratified',\n",
        "    'y_pred_train': remove_punctuation_train(stratified_classifier.predict(x_train_flattened)),\n",
        "    'y_pred_val': remove_punctuation_val(stratified_classifier.predict(x_val_flattened)),\n",
        "    'y_pred_test': remove_punctuation_test(stratified_classifier.predict(x_test_flattened))\n",
        "    }, {\n",
        "    'model_label': 'baseline',\n",
        "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=baseline)),\n",
        "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=baseline)),\n",
        "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=baseline))\n",
        "    }, {\n",
        "    'model_label': 'gru',\n",
        "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=gru)),\n",
        "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=gru)),\n",
        "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=gru))\n",
        "    }, {\n",
        "    'model_label': 'additionalDense',\n",
        "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=additional_dense)),\n",
        "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=additional_dense)),\n",
        "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=additional_dense))\n",
        "    }, {\n",
        "    'model_label': 'additionalLSTM',\n",
        "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=additional_LSTM)),\n",
        "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=additional_LSTM)),\n",
        "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=additional_LSTM))\n",
        "    }\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "41bJ4WUbgIpT"
      },
      "source": [
        "## Show analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SQhZ2jCgIpT"
      },
      "source": [
        "Compute F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eUmOgOT0gIpT",
        "outputId": "bd7b8a0b-db1a-41d4-b94a-1e490a3927f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "maj train, weighted F1 macro: 0.04\n",
            "maj val, weighted F1 macro: 0.05\n",
            "maj test, weighted F1 macro: 0.05\n",
            "stratified train, weighted F1 macro: 0.08\n",
            "stratified val, weighted F1 macro: 0.08\n",
            "stratified test, weighted F1 macro: 0.08\n",
            "baseline train, weighted F1 macro: 0.73\n",
            "baseline val, weighted F1 macro: 0.70\n",
            "baseline test, weighted F1 macro: 0.74\n",
            "gru train, weighted F1 macro: 0.69\n",
            "gru val, weighted F1 macro: 0.67\n",
            "gru test, weighted F1 macro: 0.70\n",
            "additionalDense train, weighted F1 macro: 0.52\n",
            "additionalDense val, weighted F1 macro: 0.37\n",
            "additionalDense test, weighted F1 macro: 0.39\n",
            "additionalLSTM train, weighted F1 macro: 0.78\n",
            "additionalLSTM val, weighted F1 macro: 0.74\n",
            "additionalLSTM test, weighted F1 macro: 0.78\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def analyze(y_true, y_pred, output_mode=0, model_label=None):\n",
        "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
        "    f1 = report['weighted avg']['f1-score']\n",
        "    if output_mode >= 1:\n",
        "        print(f\"{model_label}, weighted F1 macro: {f1:.2f}\")\n",
        "\n",
        "    if output_mode >= 2:\n",
        "        print(\"Confusion matrix\")\n",
        "        ConfusionMatrixDisplay.from_predictions(y_true, y_pred, cmap='Blues')\n",
        "        plt.show()\n",
        "    return confusion_matrix(y_true, y_pred), f1\n",
        "\n",
        "output_mode = 1\n",
        "for data in prediction_data:\n",
        "    for y, label in zip([y_train_cleaned, y_val_cleaned, y_test_cleaned], ['train', 'val', 'test']):\n",
        "        res = analyze(y, data[f'y_pred_{label}'], output_mode=output_mode, model_label=f\"{data['model_label']} {label}\")\n",
        "        data[f'cm_{label}'], data[f'f1_{label}'] = res\n",
        "\n",
        "f1_train = [data['f1_train'] for data in prediction_data]\n",
        "f1_val = [data['f1_val'] for data in prediction_data]\n",
        "f1_test = [data['f1_test'] for data in prediction_data]\n",
        "\n",
        "model_labels = [data['model_label'] for data in prediction_data]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozwpTpmRgIpU"
      },
      "source": [
        "Bar plot of F1 score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 604
        },
        "id": "ar7ojAUggIpU",
        "outputId": "e8c97b68-c555-4e71-afdc-d3325fa73dfb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1280x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "w, h, dpi = 1280, 720, 100\n",
        "fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
        "\n",
        "ax.bar(model_labels, height=f1_test, width=0.8)\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.13 ('tensorflow')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "716c34c06793e5cf93c7b330bdfcb45c40eb89e5efd6d32b0d2191c531a6c3c3"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}