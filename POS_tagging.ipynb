{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "import gensim\n",
    "import gensim.downloader as gloader\n",
    "\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from collections import OrderedDict\n",
    "from typing import List, Callable, Dict\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\")\n",
    "\n",
    "if not os.path.exists(dataset_folder):\n",
    "    os.makedirs(dataset_folder)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
    "\n",
    "dataset_path = os.path.join(dataset_folder, \"data.zip\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "    print(\"Successful download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe created.                                \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Pierre Vinken , 61 years old , will join the b...</td>\n",
       "      <td>(NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Mr. Vinken is chairman of Elsevier N.V. , the ...</td>\n",
       "      <td>(NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Rudolph Agnew , 55 years old and former chairm...</td>\n",
       "      <td>(NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>`` There 's no question that some of those wor...</td>\n",
       "      <td>(``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Workers described `` clouds of blue dust '' th...</td>\n",
       "      <td>(NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>198</td>\n",
       "      <td>A line-item veto is a procedure that would all...</td>\n",
       "      <td>(DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>198</td>\n",
       "      <td>Sen. Kennedy said in a separate statement that...</td>\n",
       "      <td>(NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>199</td>\n",
       "      <td>Trinity Industries Inc. said it reached a prel...</td>\n",
       "      <td>(NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>199</td>\n",
       "      <td>Terms were n't disclosed .</td>\n",
       "      <td>(NNS, VBD, RB, VBN, .)</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>199</td>\n",
       "      <td>Trinity said it plans to begin delivery in the...</td>\n",
       "      <td>(NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3914 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id                                               text  \\\n",
       "0           1  Pierre Vinken , 61 years old , will join the b...   \n",
       "1           1  Mr. Vinken is chairman of Elsevier N.V. , the ...   \n",
       "2           2  Rudolph Agnew , 55 years old and former chairm...   \n",
       "3           3  `` There 's no question that some of those wor...   \n",
       "4           3  Workers described `` clouds of blue dust '' th...   \n",
       "...       ...                                                ...   \n",
       "3909      198  A line-item veto is a procedure that would all...   \n",
       "3910      198  Sen. Kennedy said in a separate statement that...   \n",
       "3911      199  Trinity Industries Inc. said it reached a prel...   \n",
       "3912      199                         Terms were n't disclosed .   \n",
       "3913      199  Trinity said it plans to begin delivery in the...   \n",
       "\n",
       "                                                   tags  split  \n",
       "0     (NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  train  \n",
       "1     (NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  train  \n",
       "2     (NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  train  \n",
       "3     (``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...  train  \n",
       "4     (NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...  train  \n",
       "...                                                 ...    ...  \n",
       "3909  (DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...   test  \n",
       "3910  (NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...   test  \n",
       "3911  (NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...   test  \n",
       "3912                             (NNS, VBD, RB, VBN, .)   test  \n",
       "3913  (NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...   test  \n",
       "\n",
       "[3914 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_range = (1, 101)\n",
    "val_range = (101, 151)\n",
    "test_range = (151, 200)\n",
    "\n",
    "split_sentences = True\n",
    "\n",
    "dataframe_rows = []\n",
    "with ZipFile(dataset_path, 'r') as myzip:\n",
    "    for i, filename in enumerate(myzip.namelist()[1:]):\n",
    "        print(\"Extracting\", filename, end='\\r')\n",
    "\n",
    "        with myzip.open(filename) as myfile:\n",
    "            file_id = int(filename.split('.')[0][-4:])\n",
    "\n",
    "            split = 'train'\n",
    "            if file_id in range(*val_range):\n",
    "                split = 'val'\n",
    "            elif file_id in range(*test_range):\n",
    "                split = 'test'\n",
    "\n",
    "            content_string = myfile.read().decode('utf-8')\n",
    "            if split_sentences:\n",
    "                sentences = content_string.split('\\n\\n')\n",
    "            else:\n",
    "                sentences = [content_string]\n",
    "\n",
    "            for sentence in sentences:\n",
    "                content = sentence.split('\\n')\n",
    "                content = [line.split('\\t') for line in content if len(line.split('\\t')) == 3]\n",
    "\n",
    "                words, tags, _ = zip(*content)\n",
    "\n",
    "                dataframe_rows.append({'file_id': file_id,\n",
    "                                       'text': ' '.join(words),\n",
    "                                       'tags': tags,\n",
    "                                       'split': split\n",
    "                                       })\n",
    "\n",
    "df = pd.DataFrame(dataframe_rows).sort_values('file_id').reset_index(drop=True)\n",
    "print(\"Dataframe created.\".ljust(50))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>text</th>\n",
       "      <th>tags</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>pierre vinken , 61 years old , will join the b...</td>\n",
       "      <td>(NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>mr. vinken is chairman of elsevier n.v. , the ...</td>\n",
       "      <td>(NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rudolph agnew , 55 years old and former chairm...</td>\n",
       "      <td>(NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>`` there 's no question that some of those wor...</td>\n",
       "      <td>(``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>workers described `` clouds of blue dust '' th...</td>\n",
       "      <td>(NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3909</th>\n",
       "      <td>198</td>\n",
       "      <td>a line-item veto is a procedure that would all...</td>\n",
       "      <td>(DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3910</th>\n",
       "      <td>198</td>\n",
       "      <td>sen. kennedy said in a separate statement that...</td>\n",
       "      <td>(NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>199</td>\n",
       "      <td>trinity industries inc. said it reached a prel...</td>\n",
       "      <td>(NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3912</th>\n",
       "      <td>199</td>\n",
       "      <td>terms were n't disclosed .</td>\n",
       "      <td>(NNS, VBD, RB, VBN, .)</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3913</th>\n",
       "      <td>199</td>\n",
       "      <td>trinity said it plans to begin delivery in the...</td>\n",
       "      <td>(NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3914 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id                                               text  \\\n",
       "0           1  pierre vinken , 61 years old , will join the b...   \n",
       "1           1  mr. vinken is chairman of elsevier n.v. , the ...   \n",
       "2           2  rudolph agnew , 55 years old and former chairm...   \n",
       "3           3  `` there 's no question that some of those wor...   \n",
       "4           3  workers described `` clouds of blue dust '' th...   \n",
       "...       ...                                                ...   \n",
       "3909      198  a line-item veto is a procedure that would all...   \n",
       "3910      198  sen. kennedy said in a separate statement that...   \n",
       "3911      199  trinity industries inc. said it reached a prel...   \n",
       "3912      199                         terms were n't disclosed .   \n",
       "3913      199  trinity said it plans to begin delivery in the...   \n",
       "\n",
       "                                                   tags  split  \n",
       "0     (NNP, NNP, ,, CD, NNS, JJ, ,, MD, VB, DT, NN, ...  train  \n",
       "1     (NNP, NNP, VBZ, NN, IN, NNP, NNP, ,, DT, NNP, ...  train  \n",
       "2     (NNP, NNP, ,, CD, NNS, JJ, CC, JJ, NN, IN, NNP...  train  \n",
       "3     (``, EX, VBZ, DT, NN, IN, DT, IN, DT, NNS, CC,...  train  \n",
       "4     (NNS, VBD, ``, NNS, IN, JJ, NN, '', WDT, VBD, ...  train  \n",
       "...                                                 ...    ...  \n",
       "3909  (DT, JJ, NN, VBZ, DT, NN, WDT, MD, VB, DT, NN,...   test  \n",
       "3910  (NNP, NNP, VBD, IN, DT, JJ, NN, IN, PRP, VBZ, ...   test  \n",
       "3911  (NNP, NNPS, NNP, VBD, PRP, VBD, DT, JJ, NN, TO...   test  \n",
       "3912                             (NNS, VBD, RB, VBN, .)   test  \n",
       "3913  (NNP, VBD, PRP, VBZ, TO, VB, NN, IN, DT, JJ, N...   test  \n",
       "\n",
       "[3914 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'] = df['text'].apply(lambda x: x.lower())\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset splits statistics: \n",
      "Train data: (1963,)\n",
      "Validation data: (1299,)\n",
      "Test data: (652,)\n"
     ]
    }
   ],
   "source": [
    "train_data = df[df['split'] == 'train']\n",
    "val_data = df[df['split'] == 'val']\n",
    "test_data = df[df['split'] == 'test']\n",
    "\n",
    "x_train = train_data['text'].values\n",
    "y_train = train_data['tags'].values\n",
    "\n",
    "x_val = val_data['text'].values\n",
    "y_val = val_data['tags'].values\n",
    "\n",
    "x_test = test_data['text'].values\n",
    "y_test = test_data['tags'].values\n",
    "\n",
    "print('Dataset splits statistics: ')\n",
    "print(f'Train data: {x_train.shape}')\n",
    "print(f'Validation data: {x_val.shape}')\n",
    "print(f'Test data: {x_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply GloVe embeddings and Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oov_embedding(word, embedding_model, size):\n",
    "    \"\"\"For now just a random vector, can be changed to a more sophisticated method.\"\"\"\n",
    "    return np.random.uniform(low=-0.05, high=0.05, size=size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe embedding.\n"
     ]
    }
   ],
   "source": [
    "from utils.kerasTokenizer import load_embedding_model, check_OOV_terms\n",
    "\n",
    "print(\"Loading GloVe embedding.\")\n",
    "my_embedding_dimension = 50\n",
    "my_embedding_model = load_embedding_model('glove', my_embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GLOVE vocabulary (V1) size:  400166\n",
      "Creating V2 using training set (V1 + OOV1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V2 size:  400166\n",
      "Creating V3 using validation set (V2 + OOV2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V3 size:  400166\n",
      "Creating V4 using validation set (V3 + OOV3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "V4 size:  400166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"GLOVE vocabulary (V1) size: \", len(my_embedding_model))\n",
    "\n",
    "x_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='[UNK]')\n",
    "\n",
    "print(\"Creating V2 using training set (V1 + OOV1)\")\n",
    "x_tokenizer.fit_on_texts(x_train)\n",
    "for word in tqdm(check_OOV_terms(my_embedding_model, x_tokenizer.word_index.keys())):\n",
    "    embedding_vector = get_oov_embedding(word=word, embedding_model=my_embedding_model, size=my_embedding_dimension)\n",
    "    my_embedding_model.__setitem__(word, embedding_vector)\n",
    "\n",
    "print(\"V2 size: \", len(my_embedding_model))\n",
    "\n",
    "print(\"Creating V3 using validation set (V2 + OOV2)\")\n",
    "x_tokenizer.fit_on_texts(x_val)\n",
    "for word in tqdm(check_OOV_terms(my_embedding_model, x_tokenizer.word_index.keys())):\n",
    "    embedding_vector = get_oov_embedding(word=word, embedding_model=my_embedding_model, size=my_embedding_dimension)\n",
    "    my_embedding_model.__setitem__(word, embedding_vector)\n",
    "\n",
    "print(\"V3 size: \", len(my_embedding_model))\n",
    "\n",
    "print(\"Creating V4 using validation set (V3 + OOV3)\")\n",
    "x_tokenizer.fit_on_texts(x_test)\n",
    "for word in tqdm(check_OOV_terms(my_embedding_model, x_tokenizer.word_index.keys())):\n",
    "    embedding_vector = get_oov_embedding(word=word, embedding_model=my_embedding_model, size=my_embedding_dimension)\n",
    "    my_embedding_model.__setitem__(word, embedding_vector)\n",
    "\n",
    "print(\"V4 size: \", len(my_embedding_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# small variant, using x_tokenizer for indexing\n",
    "embedding_matrix = np.zeros((len(x_tokenizer.word_index), my_embedding_dimension))\n",
    "for i, word in enumerate(x_tokenizer.word_index.keys()):\n",
    "    embedding_matrix[i] = my_embedding_model.get_vector(word)\n",
    "\n",
    "\n",
    "# large variant, using embedding model for indexing\n",
    "# embedding_matrix = np.zeros((len(my_embedding_model), my_embedding_dimension))\n",
    "# for word, i in my_embedding_model.key_to_index.items():\n",
    "#     embedding_matrix[i] = my_embedding_model.get_vector(word)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['NNP', ',', 'CD', 'NNS', 'JJ', 'MD', 'VB', 'DT', 'NN', 'IN', '.',\n",
       "       'VBZ', 'VBG', 'CC', 'VBD', 'VBN', '``', 'EX', \"''\", 'WDT', 'RB',\n",
       "       'RP', 'TO', 'WRB', 'RBR', 'VBP', 'JJR', 'WP', 'JJS', 'PRP', ':',\n",
       "       'POS', 'PRP$', '$', 'NNPS', 'WP$', '-LRB-', '-RRB-', 'PDT', 'RBS',\n",
       "       'FW', 'UH', 'SYM', 'LS', '#'], dtype=object)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_s = ' '.join([' '.join(y) for y in df['tags']])\n",
    "pd.DataFrame(tags_s.split())[0].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token='[UNK]', filters='!\"%&()*+/;<=>?@[\\\\]^_{|}~\\t\\n', lower=False)\n",
    "y_tokenizer.fit_on_texts([' '.join(y) for y in df['tags']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['[UNK]', 'NN', 'IN', 'NNP', 'DT', 'NNS', 'JJ', ',', '.', 'CD', 'VBD', 'RB', 'VB', 'CC', 'TO', 'VBN', 'VBZ', 'PRP', 'VBG', 'VBP', 'MD', 'POS', 'PRP$', '$', '``', \"''\", ':', 'WDT', 'JJR', 'NNPS', 'WP', 'RP', 'JJS', 'WRB', 'RBR', '-RRB-', '-LRB-', 'EX', 'RBS', 'PDT', '#', 'WP$', 'LS', 'FW', 'UH', 'SYM'])\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "print(y_tokenizer.word_index.keys())\n",
    "print(len(y_tokenizer.word_index.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxlen = tf.keras.preprocessing.sequence.pad_sequences(x_tokenizer.texts_to_sequences(df['text']), padding=\"post\")[0].size\n",
    "\n",
    "x_train_pad = tf.keras.preprocessing.sequence.pad_sequences(x_tokenizer.texts_to_sequences(x_train), maxlen=maxlen,padding=\"post\")\n",
    "x_val_pad = tf.keras.preprocessing.sequence.pad_sequences(x_tokenizer.texts_to_sequences(x_val), maxlen=maxlen,padding=\"post\")\n",
    "x_test_pad = tf.keras.preprocessing.sequence.pad_sequences(x_tokenizer.texts_to_sequences(x_test), maxlen=maxlen,padding=\"post\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('NLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98b49351e707f46dcf9d0b031f5f36bb2db9d317180255edde60df3fbbef7ab4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
