{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and execute in Colab Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # execute this cell when loading the notebook for the first time\n",
    "# ! pip install gensim==4.2.0\n",
    "# ! pip install keras==2.8.0\n",
    "\n",
    "# ! git clone https://github.com/michele98/POS_tagging\n",
    "\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')\n",
    "\n",
    "# drive_folder = '/content/drive/MyDrive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # execute this cell each time the runtime is restarted\n",
    "\n",
    "# %cd -0\n",
    "# %cd POS_tagging\n",
    "\n",
    "# import os\n",
    "# os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import urllib.request\n",
    "\n",
    "from zipfile import ZipFile\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "#os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\")\n",
    "\n",
    "if not os.path.exists(dataset_folder):\n",
    "    os.makedirs(dataset_folder)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
    "\n",
    "dataset_path = os.path.join(dataset_folder, \"data.zip\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "    print(\"Successful download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = (1, 101)\n",
    "val_range = (101, 151)\n",
    "test_range = (151, 200)\n",
    "\n",
    "split_sentences = True\n",
    "\n",
    "dataframe_rows = []\n",
    "with ZipFile(dataset_path, 'r') as myzip:\n",
    "    for i, filename in enumerate(myzip.namelist()[1:]):\n",
    "        print(\"Extracting\", filename, end='\\r')\n",
    "\n",
    "        with myzip.open(filename) as myfile:\n",
    "            file_id = int(filename.split('.')[0][-4:])\n",
    "\n",
    "            split = 'train'\n",
    "            if file_id in range(*val_range):\n",
    "                split = 'val'\n",
    "            elif file_id in range(*test_range):\n",
    "                split = 'test'\n",
    "\n",
    "            content_string = myfile.read().decode('utf-8')\n",
    "            if split_sentences:\n",
    "                sentences = content_string.split('\\n\\n')\n",
    "            else:\n",
    "                sentences = [content_string]\n",
    "\n",
    "            for sentence in sentences:\n",
    "                content = sentence.split('\\n')\n",
    "                content = [line.split('\\t') for line in content if len(line.split('\\t')) == 3]\n",
    "\n",
    "                words, tags, _ = zip(*content)\n",
    "\n",
    "                dataframe_rows.append({'file_id': file_id,\n",
    "                                       'text': words,\n",
    "                                       'tags': tags,\n",
    "                                       'split': split\n",
    "                                       })\n",
    "\n",
    "df = pd.DataFrame(dataframe_rows).sort_values('file_id').reset_index(drop=True)\n",
    "print(\"Dataframe created.\".ljust(50))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda l: [element.lower() for element in l])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df['split'] == 'train']\n",
    "val_data = df[df['split'] == 'val']\n",
    "test_data = df[df['split'] == 'test']\n",
    "\n",
    "x_train = train_data['text'].values\n",
    "y_train = train_data['tags'].values\n",
    "\n",
    "x_val = val_data['text'].values\n",
    "y_val = val_data['tags'].values\n",
    "\n",
    "x_test = test_data['text'].values\n",
    "y_test = test_data['tags'].values\n",
    "\n",
    "print('Dataset splits statistics: ')\n",
    "print(f'Train data: {x_train.shape}')\n",
    "print(f'Validation data: {x_val.shape}')\n",
    "print(f'Test data: {x_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add OOV words to GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import load_embedding_model, add_OOV_embeddings\n",
    "\n",
    "print(\"Loading GloVe embedding.\")\n",
    "my_embedding_dimension = 50\n",
    "my_embedding_model = load_embedding_model('glove', my_embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GLOVE vocabulary size: \", len(my_embedding_model))\n",
    "\n",
    "unknown_token = '[UNK]'\n",
    "padding_token = ''\n",
    "\n",
    "print(f\"Add unknown token {unknown_token} and padding token {padding_token}\")\n",
    "add_OOV_embeddings(my_embedding_model, [unknown_token, padding_token], my_embedding_dimension)\n",
    "print(\"V1 size: \", len(my_embedding_model))\n",
    "\n",
    "print(\"\\nCreating V2 using training set (V1 + OOV1)\")\n",
    "add_OOV_embeddings(my_embedding_model, x_train, my_embedding_dimension)\n",
    "print(\"V2 size: \", len(my_embedding_model))\n",
    "\n",
    "print(\"\\nCreating V3 using validation set (V2 + OOV2)\")\n",
    "add_OOV_embeddings(my_embedding_model, x_val, my_embedding_dimension)\n",
    "print(\"V3 size: \", len(my_embedding_model))\n",
    "\n",
    "print(\"\\nCreating V4 using validation set (V3 + OOV3)\")\n",
    "add_OOV_embeddings(my_embedding_model, x_test, my_embedding_dimension)\n",
    "print(\"V4 size: \", len(my_embedding_model))\n",
    "\n",
    "# build vocabulary for x\n",
    "dataset_vocabulary = np.unique([word for sentence in df['text'] for word in sentence])\n",
    "dataset_vocabulary = np.concatenate([[unknown_token], dataset_vocabulary])\n",
    "\n",
    "# build vocabulary for y\n",
    "tags_s = ' '.join([' '.join(y) for y in df['tags']])\n",
    "tag_vocabulary = pd.DataFrame(tags_s.split())[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Tags and define punctuation tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mmh, there are some interesting looking tags. Let's build a DataFrame with some sentence examples to see what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {}\n",
    "\n",
    "for tag in tag_vocabulary:\n",
    "    i = df.loc[np.array([tag in t for t in df['tags']])].index[0]\n",
    "    s1 = df['text'][i]\n",
    "    t1 = df['tags'][i]\n",
    "    d[f'{tag} (w)'] = np.pad(s1, (0,90-len(s1)))\n",
    "    d[f'{tag} (t)'] = np.pad(t1, (0,90-len(t1)))\n",
    "\n",
    "with open('phrase_examples.csv', 'w') as f:\n",
    "    f.write(pd.DataFrame(d).to_csv())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After examining the resulting file, we know what the punctuation tags are. Let's put them in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_tags = [',',\n",
    "                    '.',\n",
    "                    '``',\n",
    "                    \"''\",\n",
    "                    ':',\n",
    "                    '-LRB-',\n",
    "                    '-RRB-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_length = int(df['tags'].apply(lambda x: len(x)).quantile(0.95))\n",
    "print(\"The padding length is\", padding_length)\n",
    "\n",
    "dataset_dict = {k: i for i, k in enumerate(dataset_vocabulary)}\n",
    "\n",
    "def tokenize_x(x):\n",
    "    return [[dataset_dict[word] for word in phrase] for phrase in x]\n",
    "\n",
    "x_train_tokenized = tokenize_x(x_train)\n",
    "x_val_tokenized = tokenize_x(x_val)\n",
    "x_test_tokenized = tokenize_x(x_test)\n",
    "\n",
    "x_train_pad = tf.keras.preprocessing.sequence.pad_sequences(x_train_tokenized, maxlen=padding_length, padding=\"post\")\n",
    "x_val_pad = tf.keras.preprocessing.sequence.pad_sequences(x_val_tokenized, maxlen=padding_length, padding=\"post\")\n",
    "x_test_pad = tf.keras.preprocessing.sequence.pad_sequences(x_test_tokenized, maxlen=padding_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = {k: i for i, k in enumerate(tag_vocabulary)}\n",
    "\n",
    "def tokenize_y(y):\n",
    "    return [[tag_dict[tag] for tag in phrase] for phrase in y]\n",
    "\n",
    "y_train_tokenized = tokenize_y(y_train)\n",
    "y_val_tokenized = tokenize_y(y_val)\n",
    "y_test_tokenized = tokenize_y(y_test)\n",
    "\n",
    "y_train_pad = tf.keras.preprocessing.sequence.pad_sequences(y_train_tokenized, maxlen=padding_length, padding=\"post\")\n",
    "y_val_pad = tf.keras.preprocessing.sequence.pad_sequences(y_val_tokenized, maxlen=padding_length, padding=\"post\")\n",
    "y_test_pad = tf.keras.preprocessing.sequence.pad_sequences(y_test_tokenized, maxlen=padding_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from functools import partial\n",
    "\n",
    "from utils.training_utils import MyHistory, plot_history\n",
    "from models import embedding_layer\n",
    "\n",
    "embedding_func = partial(embedding_layer,\n",
    "                         vocabulary=dataset_vocabulary,\n",
    "                         embedding_model=my_embedding_model,\n",
    "                         embedding_dimension=my_embedding_dimension)\n",
    "\n",
    "try:\n",
    "    weights_folder = os.path.join(drive_folder, \"weights\")\n",
    "except NameError as e:\n",
    "    weights_folder = \"weights\"\n",
    "\n",
    "checkpoint_partial = partial(ModelCheckpoint, monitor=\"val_loss\", mode=\"auto\")#, save_format=\"tf\")\n",
    "compile_args = dict(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "input_shape = (padding_length, my_embedding_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import baselineLSTM\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "checkpoint_path = os.path.join(weights_folder, \"baseline\", \"checkpoint.hdf5\")\n",
    "history_path = os.path.join(weights_folder, \"baseline\", \"history.npy\")\n",
    "\n",
    "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
    "hist_callback = MyHistory(history_path)\n",
    "\n",
    "model = baselineLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "model.compile(**compile_args, optimizer=optimizer)\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "history = model.fit(x=x_train_pad,\n",
    "                    y=y_train_pad,\n",
    "                    batch_size=32,\n",
    "                    epochs=2,\n",
    "                    validation_data=(x_val_pad,\n",
    "                                     y_val_pad),\n",
    "                    callbacks=[checkpoint_callback, hist_callback])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GRUModel\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "checkpoint_path = os.path.join(weights_folder, \"gru\", \"checkpoint.hdf5\")\n",
    "history_path = os.path.join(weights_folder, \"gru\", \"history.npy\")\n",
    "\n",
    "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
    "hist_callback = MyHistory(history_path)\n",
    "\n",
    "model = GRUModel(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "model.compile(**compile_args, optimizer=optimizer)\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "history = model.fit(x=x_train_pad,\n",
    "                    y=y_train_pad,\n",
    "                    batch_size=32,\n",
    "                    epochs=2,\n",
    "                    validation_data=(x_val_pad,\n",
    "                                     y_val_pad),\n",
    "                    callbacks=[checkpoint_callback, hist_callback])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import additionalLSTM\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "checkpoint_path = os.path.join(weights_folder, \"additionalLSTM\", \"checkpoint.hdf5\")\n",
    "history_path = os.path.join(weights_folder, \"additionalLSTM\", \"history.npy\")\n",
    "\n",
    "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
    "hist_callback = MyHistory(history_path)\n",
    "\n",
    "model = additionalLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "model.compile(**compile_args, optimizer=optimizer)\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "history = model.fit(x=x_train_pad,\n",
    "                    y=y_train_pad,\n",
    "                    batch_size=32,\n",
    "                    epochs=2,\n",
    "                    validation_data=(x_val_pad,\n",
    "                                     y_val_pad),\n",
    "                    callbacks=[checkpoint_callback, hist_callback])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import additionalDense\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "checkpoint_path = os.path.join(weights_folder, \"additionalDense\", \"checkpoint.hdf5\")\n",
    "history_path = os.path.join(weights_folder, \"additionalDense\", \"history.npy\")\n",
    "\n",
    "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
    "hist_callback = MyHistory(history_path)\n",
    "\n",
    "model = additionalDense(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "model.compile(**compile_args, optimizer=optimizer)\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "history = model.fit(x=x_train_pad,\n",
    "                    y=y_train_pad,\n",
    "                    batch_size=32,\n",
    "                    epochs=2,\n",
    "                    validation_data=(x_val_pad,\n",
    "                                     y_val_pad),\n",
    "                    callbacks=[checkpoint_callback, hist_callback])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_data(list_of_lists):\n",
    "    return [element for sequence in list_of_lists for element in sequence[:padding_length]]\n",
    "\n",
    "def remove_punctuation(y, y_true=None):\n",
    "    if y_true is None:\n",
    "        y_true = y\n",
    "    return [tag for tag, true_tag in zip(y, y_true) if true_tag not in punctuation_tags]\n",
    "\n",
    "x_train_flattened = flatten_data(x_train)\n",
    "x_val_flattened = flatten_data(x_val)\n",
    "x_test_flattened = flatten_data(x_test)\n",
    "\n",
    "y_train_flattened = flatten_data(y_train)\n",
    "y_val_flattened = flatten_data(y_val)\n",
    "y_test_flattened = flatten_data(y_test)\n",
    "\n",
    "y_train_cleaned = remove_punctuation(y_train_flattened)\n",
    "y_val_cleaned = remove_punctuation(y_val_flattened)\n",
    "y_test_cleaned = remove_punctuation(y_test_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_classifier = DummyClassifier(strategy=\"prior\")\n",
    "stratified_classifier = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "majority_classifier.fit(x_train_flattened, y_train_flattened);\n",
    "stratified_classifier.fit(x_train_flattened, y_train_flattened);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpad_result(y_padded, y_true):\n",
    "    return [y[:len(yt)] for y, yt in zip(y_padded, y_true)]\n",
    "\n",
    "def get_model_prediction(model, x, y_true):\n",
    "    output = model.predict(x)\n",
    "    y_pred_model = tag_vocabulary[np.argmax(output, axis=-1)]\n",
    "    y_pred_unpadded = unpad_result(y_pred_model, y_true)\n",
    "    return flatten_data(y_pred_unpadded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import baselineLSTM, GRUModel, additionalLSTM, additionalDense\n",
    "\n",
    "baseline = baselineLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "baseline.load_weights(os.path.join(weights_folder, \"baseline\", \"checkpoint.hdf5\"))\n",
    "\n",
    "gru = GRUModel(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "gru.load_weights(os.path.join(weights_folder, \"gru\", \"checkpoint.hdf5\"))\n",
    "\n",
    "additional_LSTM = additionalLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "additional_LSTM.load_weights(os.path.join(weights_folder, \"additionalLSTM\", \"checkpoint.hdf5\"))\n",
    "\n",
    "additional_dense = additionalDense(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "additional_dense.load_weights(os.path.join(weights_folder, \"additionalDense\", \"checkpoint.hdf5\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dictionary with prediction info\n",
    "fill in this dictionary to get all the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction_train = partial(get_model_prediction, x=x_train_pad, y_true=y_train)\n",
    "model_prediction_val = partial(get_model_prediction, x=x_val_pad, y_true=y_val)\n",
    "model_prediction_test = partial(get_model_prediction, x=x_test_pad, y_true=y_test)\n",
    "\n",
    "remove_punctuation_train = partial(remove_punctuation, y_true=y_train_flattened)\n",
    "remove_punctuation_val = partial(remove_punctuation, y_true=y_val_flattened)\n",
    "remove_punctuation_test = partial(remove_punctuation, y_true=y_test_flattened)\n",
    "\n",
    "prediction_data = [{\n",
    "    'model_label': 'maj',\n",
    "    'y_pred_train': remove_punctuation_train(majority_classifier.predict(x_train_flattened)),\n",
    "    'y_pred_val': remove_punctuation_val(majority_classifier.predict(x_val_flattened)),\n",
    "    'y_pred_test': remove_punctuation_test(majority_classifier.predict(x_test_flattened))\n",
    "    }, {\n",
    "    'model_label': 'stratified',\n",
    "    'y_pred_train': remove_punctuation_train(stratified_classifier.predict(x_train_flattened)),\n",
    "    'y_pred_val': remove_punctuation_val(stratified_classifier.predict(x_val_flattened)),\n",
    "    'y_pred_test': remove_punctuation_test(stratified_classifier.predict(x_test_flattened))\n",
    "    }, {\n",
    "    'model_label': 'baseline',\n",
    "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=baseline)),\n",
    "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=baseline)),\n",
    "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=baseline))\n",
    "    }, {\n",
    "    'model_label': 'gru',\n",
    "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=gru)),\n",
    "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=gru)),\n",
    "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=gru))\n",
    "    }, {\n",
    "    'model_label': 'additionalDense',\n",
    "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=additional_dense)),\n",
    "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=additional_dense)),\n",
    "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=additional_dense))\n",
    "    }, {\n",
    "    'model_label': 'additionalLSTM',\n",
    "    'y_pred_train': remove_punctuation_train(model_prediction_train(model=additional_LSTM)),\n",
    "    'y_pred_val': remove_punctuation_val(model_prediction_val(model=additional_LSTM)),\n",
    "    'y_pred_test': remove_punctuation_test(model_prediction_test(model=additional_LSTM))\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze(y_true, y_pred, output_mode=0, model_label=None):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    if output_mode >= 1:\n",
    "        print(f\"{model_label}, weighted F1 macro: {f1:.2f}\")\n",
    "\n",
    "    if output_mode >= 2:\n",
    "        print(\"Confusion matrix\")\n",
    "        ConfusionMatrixDisplay.from_predictions(y_true, y_pred, cmap='Blues')\n",
    "        plt.show()\n",
    "    return confusion_matrix(y_true, y_pred), f1\n",
    "\n",
    "output_mode = 1\n",
    "for data in prediction_data:\n",
    "    for y, label in zip([y_train_cleaned, y_val_cleaned, y_test_cleaned], ['train', 'val', 'test']):\n",
    "        res = analyze(y, data[f'y_pred_{label}'], output_mode=output_mode, model_label=f\"{data['model_label']} {label}\")\n",
    "        data[f'cm_{label}'], data[f'f1_{label}'] = res\n",
    "\n",
    "f1_train = [data['f1_train'] for data in prediction_data]\n",
    "f1_val = [data['f1_val'] for data in prediction_data]\n",
    "f1_test = [data['f1_test'] for data in prediction_data]\n",
    "\n",
    "model_labels = [data['model_label'] for data in prediction_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plot of F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h, dpi = 1280, 720, 100\n",
    "fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "ax.bar(model_labels, height=f1_test, width=0.8)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tensorflow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "716c34c06793e5cf93c7b330bdfcb45c40eb89e5efd6d32b0d2191c531a6c3c3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
