{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment and execute in Colab Notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! pip install gensim==4.2.0\n",
    "# ! pip install keras==2.8.0\n",
    "\n",
    "# ! git clone https://github.com/michele98/POS_tagging\n",
    "\n",
    "# %cd -0\n",
    "# %cd POS_tagging\n",
    "\n",
    "# from google.colab import drive\n",
    "# drive.mount('content/drive')\n",
    "\n",
    "# drive_folder = 'content/drive/MyDrive'\n",
    "\n",
    "# os.environ['TF_DETERMINISTIC_OPS'] = '1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import urllib.request\n",
    "import gensim\n",
    "import gensim.downloader as gloader\n",
    "\n",
    "\n",
    "from zipfile import ZipFile\n",
    "from collections import OrderedDict\n",
    "from typing import List, Callable, Dict\n",
    "from tqdm import tqdm\n",
    "\n",
    "random_seed = 42\n",
    "np.random.seed(random_seed)\n",
    "tf.random.set_seed(random_seed)\n",
    "#os.environ['TF_DETERMINISTIC_OPS'] = '1'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join(os.getcwd(), \"Datasets\", \"Original\")\n",
    "\n",
    "if not os.path.exists(dataset_folder):\n",
    "    os.makedirs(dataset_folder)\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/packages/corpora/dependency_treebank.zip\"\n",
    "\n",
    "dataset_path = os.path.join(dataset_folder, \"data.zip\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    urllib.request.urlretrieve(url, dataset_path)\n",
    "    print(\"Successful download\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_range = (1, 101)\n",
    "val_range = (101, 151)\n",
    "test_range = (151, 200)\n",
    "\n",
    "split_sentences = True\n",
    "\n",
    "dataframe_rows = []\n",
    "with ZipFile(dataset_path, 'r') as myzip:\n",
    "    for i, filename in enumerate(myzip.namelist()[1:]):\n",
    "        print(\"Extracting\", filename, end='\\r')\n",
    "\n",
    "        with myzip.open(filename) as myfile:\n",
    "            file_id = int(filename.split('.')[0][-4:])\n",
    "\n",
    "            split = 'train'\n",
    "            if file_id in range(*val_range):\n",
    "                split = 'val'\n",
    "            elif file_id in range(*test_range):\n",
    "                split = 'test'\n",
    "\n",
    "            content_string = myfile.read().decode('utf-8')\n",
    "            if split_sentences:\n",
    "                sentences = content_string.split('\\n\\n')\n",
    "            else:\n",
    "                sentences = [content_string]\n",
    "\n",
    "            for sentence in sentences:\n",
    "                content = sentence.split('\\n')\n",
    "                content = [line.split('\\t') for line in content if len(line.split('\\t')) == 3]\n",
    "\n",
    "                words, tags, _ = zip(*content)\n",
    "\n",
    "                dataframe_rows.append({'file_id': file_id,\n",
    "                                       'text': words,\n",
    "                                       'tags': tags,\n",
    "                                       'split': split\n",
    "                                       })\n",
    "\n",
    "df = pd.DataFrame(dataframe_rows).sort_values('file_id').reset_index(drop=True)\n",
    "print(\"Dataframe created.\".ljust(50))\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'] = df['text'].apply(lambda l: [element.lower() for element in l])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = df[df['split'] == 'train']\n",
    "val_data = df[df['split'] == 'val']\n",
    "test_data = df[df['split'] == 'test']\n",
    "\n",
    "x_train = train_data['text'].values\n",
    "y_train = train_data['tags'].values\n",
    "\n",
    "x_val = val_data['text'].values\n",
    "y_val = val_data['tags'].values\n",
    "\n",
    "x_test = test_data['text'].values\n",
    "y_test = test_data['tags'].values\n",
    "\n",
    "print('Dataset splits statistics: ')\n",
    "print(f'Train data: {x_train.shape}')\n",
    "print(f'Validation data: {x_val.shape}')\n",
    "print(f'Test data: {x_test.shape}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add OOV words to GloVe embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.preprocessing import load_embedding_model, check_OOV_terms, get_OOV_embedding, add_OOV_embeddings\n",
    "\n",
    "print(\"Loading GloVe embedding.\")\n",
    "my_embedding_dimension = 50\n",
    "my_embedding_model = load_embedding_model('glove', my_embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"GLOVE vocabulary size: \", len(my_embedding_model))\n",
    "\n",
    "unknown_token = '[UNK]'\n",
    "padding_token = ''\n",
    "\n",
    "print(f\"Add unknown token {unknown_token} and padding token {padding_token}\")\n",
    "add_OOV_embeddings(my_embedding_model, [unknown_token, padding_token], my_embedding_dimension)\n",
    "print(\"V1 size: \", len(my_embedding_model))\n",
    "\n",
    "print(\"\\nCreating V2 using training set (V1 + OOV1)\")\n",
    "add_OOV_embeddings(my_embedding_model, x_train, my_embedding_dimension)\n",
    "print(\"V2 size: \", len(my_embedding_model))\n",
    "\n",
    "print(\"\\nCreating V3 using validation set (V2 + OOV2)\")\n",
    "add_OOV_embeddings(my_embedding_model, x_val, my_embedding_dimension)\n",
    "print(\"V3 size: \", len(my_embedding_model))\n",
    "\n",
    "print(\"\\nCreating V4 using validation set (V3 + OOV3)\")\n",
    "add_OOV_embeddings(my_embedding_model, x_test, my_embedding_dimension)\n",
    "print(\"V4 size: \", len(my_embedding_model))\n",
    "\n",
    "# build vocabulary for x\n",
    "dataset_vocabulary = np.unique([word for sentence in df['text'] for word in sentence])\n",
    "dataset_vocabulary = np.concatenate([[unknown_token], dataset_vocabulary])\n",
    "\n",
    "# build vocabulary for y\n",
    "tags_s = ' '.join([' '.join(y) for y in df['tags']])\n",
    "tag_vocabulary = pd.DataFrame(tags_s.split())[0].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "padding_length = int(df['tags'].apply(lambda x: len(x)).quantile(0.95))\n",
    "print(\"The padding length is\", padding_length)\n",
    "\n",
    "dataset_dict = {k: i for i, k in enumerate(dataset_vocabulary)}\n",
    "\n",
    "def tokenize_x(x):\n",
    "    return [[dataset_dict[word] for word in phrase] for phrase in x]\n",
    "\n",
    "x_train_tokenized = tokenize_x(x_train)\n",
    "x_val_tokenized = tokenize_x(x_val)\n",
    "x_test_tokenized = tokenize_x(x_test)\n",
    "\n",
    "x_train_pad = tf.keras.preprocessing.sequence.pad_sequences(x_train_tokenized, maxlen=padding_length, padding=\"post\")\n",
    "x_val_pad = tf.keras.preprocessing.sequence.pad_sequences(x_val_tokenized, maxlen=padding_length, padding=\"post\")\n",
    "x_test_pad = tf.keras.preprocessing.sequence.pad_sequences(x_test_tokenized, maxlen=padding_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_dict = {k: i for i, k in enumerate(tag_vocabulary)}\n",
    "\n",
    "def tokenize_y(y):\n",
    "    return [[tag_dict[tag] for tag in phrase] for phrase in y]\n",
    "\n",
    "y_train_tokenized = tokenize_y(y_train)\n",
    "y_val_tokenized = tokenize_y(y_val)\n",
    "y_test_tokenized = tokenize_y(y_test)\n",
    "\n",
    "y_train_pad = tf.keras.preprocessing.sequence.pad_sequences(y_train_tokenized, maxlen=padding_length, padding=\"post\")\n",
    "y_val_pad = tf.keras.preprocessing.sequence.pad_sequences(y_val_tokenized, maxlen=padding_length, padding=\"post\")\n",
    "y_test_pad = tf.keras.preprocessing.sequence.pad_sequences(y_test_tokenized, maxlen=padding_length, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizer_v2.adam import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from functools import partial\n",
    "\n",
    "from utils.training_utils import MyHistory, plot_history\n",
    "from models import embedding_layer\n",
    "\n",
    "embedding_func = partial(embedding_layer,\n",
    "                         vocabulary=dataset_vocabulary,\n",
    "                         embedding_model=my_embedding_model,\n",
    "                         embedding_dimension=my_embedding_dimension)\n",
    "\n",
    "try:\n",
    "    weights_folder = os.path.join(drive_folder, \"weights\")\n",
    "except NameError as e:\n",
    "    weights_folder = \"weights\"\n",
    "\n",
    "checkpoint_partial = partial(ModelCheckpoint, monitor=\"val_loss\", mode=\"auto\")#, save_format=\"tf\")\n",
    "compile_args = dict(loss=\"sparse_categorical_crossentropy\", metrics=[\"acc\"])\n",
    "\n",
    "input_shape = (padding_length, my_embedding_dimension)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import baselineLSTM\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "checkpoint_path = os.path.join(weights_folder, \"baseline\", \"checkpoint.hdf5\")\n",
    "history_path = os.path.join(weights_folder, \"baseline\", \"history.npy\")\n",
    "\n",
    "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
    "hist_callback = MyHistory(history_path)\n",
    "\n",
    "model = baselineLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "model.compile(**compile_args, optimizer=optimizer)\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "history = model.fit(x=x_train_pad,\n",
    "                    y=y_train_pad,\n",
    "                    batch_size=32,\n",
    "                    epochs=2,\n",
    "                    validation_data=(x_val_pad,\n",
    "                                     y_val_pad),\n",
    "                    callbacks=[checkpoint_callback, hist_callback])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import GRUModel\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "checkpoint_path = os.path.join(weights_folder, \"gru\", \"checkpoint.hdf5\")\n",
    "history_path = os.path.join(weights_folder, \"gru\", \"history.npy\")\n",
    "\n",
    "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
    "hist_callback = MyHistory(history_path)\n",
    "\n",
    "model = GRUModel(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "model.compile(**compile_args, optimizer=optimizer)\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "history = model.fit(x=x_train_pad,\n",
    "                    y=y_train_pad,\n",
    "                    batch_size=32,\n",
    "                    epochs=2,\n",
    "                    validation_data=(x_val_pad,\n",
    "                                     y_val_pad),\n",
    "                    callbacks=[checkpoint_callback, hist_callback])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional LSTM layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import additionalLSTM\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "checkpoint_path = os.path.join(weights_folder, \"additionalLSTM\", \"checkpoint.hdf5\")\n",
    "history_path = os.path.join(weights_folder, \"additionalLSTM\", \"history.npy\")\n",
    "\n",
    "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
    "hist_callback = MyHistory(history_path)\n",
    "\n",
    "model = additionalLSTM(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "model.compile(**compile_args, optimizer=optimizer)\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "history = model.fit(x=x_train_pad,\n",
    "                    y=y_train_pad,\n",
    "                    batch_size=32,\n",
    "                    epochs=2,\n",
    "                    validation_data=(x_val_pad,\n",
    "                                     y_val_pad),\n",
    "                    callbacks=[checkpoint_callback, hist_callback])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import additionalDense\n",
    "\n",
    "optimizer = Adam(learning_rate=1e-4)\n",
    "\n",
    "checkpoint_path = os.path.join(weights_folder, \"additionalDense\", \"checkpoint.hdf5\")\n",
    "history_path = os.path.join(weights_folder, \"additionalDense\", \"history.npy\")\n",
    "\n",
    "checkpoint_callback = checkpoint_partial(filepath = checkpoint_path)\n",
    "hist_callback = MyHistory(history_path)\n",
    "\n",
    "model = additionalDense(num_classes=len(tag_vocabulary), input_shape=(padding_length,), embedding_func=embedding_func)\n",
    "model.compile(**compile_args, optimizer=optimizer)\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    model.load_weights(checkpoint_path)\n",
    "\n",
    "history = model.fit(x=x_train_pad,\n",
    "                    y=y_train_pad,\n",
    "                    batch_size=32,\n",
    "                    epochs=2,\n",
    "                    validation_data=(x_val_pad,\n",
    "                                     y_val_pad),\n",
    "                    callbacks=[checkpoint_callback, hist_callback])\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "majority_classifier = DummyClassifier(strategy=\"prior\")\n",
    "stratified_classifier = DummyClassifier(strategy=\"stratified\")\n",
    "\n",
    "majority_classifier.fit(x_train, y_train)\n",
    "stratified_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_pred_train_maj = majority_classifier.predict(x_train)\n",
    "y_pred_test_maj = majority_classifier.predict(x_test)\n",
    "y_pred_train_st = stratified_classifier.predict(x_train)\n",
    "y_pred_test_st = stratified_classifier.predict(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be filled when the models are trained"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build dictionary with prediction info\n",
    "fill in this dictionary to get all the statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = [{\n",
    "    'model_label': 'maj',\n",
    "    'y_pred_train': majority_classifier.predict(x_train),\n",
    "    'y_pred_val': majority_classifier.predict(x_val),\n",
    "    'y_pred_test': majority_classifier.predict(x_test)\n",
    "    }, {\n",
    "    'model_label': 'st',\n",
    "    'y_pred_train': stratified_classifier.predict(x_train),\n",
    "    'y_pred_val': stratified_classifier.predict(x_val),\n",
    "    'y_pred_test': majority_classifier.predict(x_test)\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def analyze(y_true, y_pred, output_mode=0, model_label=None):\n",
    "    report = classification_report(y_true, y_pred, output_dict=True, zero_division=0)\n",
    "    f1 = report['weighted avg']['f1-score']\n",
    "    if output_mode >= 1:\n",
    "        print(f\"{model_label}, weighted F1 macro: {report['weighted avg']['f1-score']:.2f}\")\n",
    "\n",
    "    if output_mode >= 2:\n",
    "        print(\"Confusion matrix\")\n",
    "        ConfusionMatrixDisplay.from_predictions(y_true, y_pred, cmap='Blues')\n",
    "        plt.show()\n",
    "    return f1\n",
    "\n",
    "output_mode=2\n",
    "for data in prediction_data:\n",
    "    data['f1_train'] = analyze(y_train, data['y_pred_train'], output_mode=output_mode, model_label=f\"{data['model_label']} train\")\n",
    "    data['f1_val'] = analyze(y_val, data['y_pred_val'], output_mode=output_mode, model_label=f\"{data['model_label']} validation\")\n",
    "    data['f1_test'] = analyze(y_test, data['y_pred_test'], output_mode=output_mode, model_label=f\"{data['model_label']} test\")\n",
    "\n",
    "f1_train = [data['f1_train'] for data in prediction_data]\n",
    "f1_val = [data['f1_val'] for data in prediction_data]\n",
    "f1_test = [data['f1_test'] for data in prediction_data]\n",
    "\n",
    "model_labels = [data['model_label'] for data in prediction_data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bar plot of F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h, dpi = 1280, 720, 100\n",
    "fig, ax = plt.subplots(figsize=(w/dpi, h/dpi), dpi=dpi)\n",
    "\n",
    "ax.bar(model_labels, height=f1_train, width=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = [0, 1, 2, 3, 4, 5]\n",
    "y_train = ['a', 'b', 'a', 'a', 'b', 'c']\n",
    "x_val = x_train\n",
    "y_val = y_train\n",
    "x_test = x_train\n",
    "y_test = y_train"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1c08d4570aaef249f3fd04259e9a09190d11e113d8f5b1be7a5240f9e414bbd5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
